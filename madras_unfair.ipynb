{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('falsb': conda)",
   "metadata": {
    "interpreter": {
     "hash": "34ca74ed6235dfc7dda926bb3adb31e801e3d02679121d5b444ee035e270bd57"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from util.dataset import Dataset as madras_Dataset\n",
    "from util import read_data as rd\n",
    "from tensorflow.keras import layers\n",
    "from madras_laftr import trainer, tester\n",
    "from madras_laftr.models import *\n",
    "from util.results import ResultLogger\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.data import Dataset\n",
    "from util import metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 1000\n",
    "learning_rate = 0.001\n",
    "opt = Adam(learning_rate=learning_rate)\n",
    "CLASS_COEFF = 1.\n",
    "FAIR_COEFF = 1.\n",
    "RECON_COEFF = 0.\n",
    "hidden_layer_specs = {'clas':[8] , 'enc':[8] , 'dec':[8] , 'adv':[8]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'adult'\n",
    "\n",
    "data_info = rd.return_data_info(data_name)\n",
    "npzfile = rd.return_npz(data_name)\n",
    "\n",
    "data = madras_Dataset(npzfile=npzfile, name=data_name, a0_name=data_info['a0_name'], a1_name=data_info['a1_name'], \n",
    "                use_a=data_info['use_a'], seed=data_info['seed'], batch_size=batch_size)\n",
    "\n",
    "data_shapes = list(data.get_shapes())\n",
    "#print(data_shapes)\n",
    "\n",
    "xdim = data_shapes[0][1]\n",
    "ydim = data_shapes[1][1]\n",
    "adim = data_shapes[2][1]\n",
    "zdim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 113), (None, 1), (None, 1)), types: (tf.float64, tf.float32, tf.float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_data = Dataset.from_tensor_slices((data.x_train, data.y_train, data.a_train))\n",
    "train_data = train_data.batch(batch_size)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = Dataset.from_tensor_slices((data.x_valid, data.y_valid, data.a_valid))\n",
    "valid_data = valid_data.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unfair(unfair_clas, X, Y, optimizer, learning_rate=0.001):\n",
    "    \n",
    "    with tf.GradientTape() as tape0:\n",
    "        \n",
    "        unfair_clas(X, Y) #to compute the foward\n",
    "        current_loss = unfair_clas.loss #current loss\n",
    "        #print('pre enc-clas-dec {}'.format(loss2min))\n",
    "    \n",
    "    grads = tape0.gradient(current_loss, unfair_clas.variables)\n",
    "    #print(grads[-1])\n",
    "    optimizer.apply_gradients(zip(grads, unfair_clas.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unfair_loop(unfair_clas, train_dataset, epochs, optmizer):\n",
    "    \n",
    "    print(\"> Epoch | Class Loss | Class Acc\")\n",
    "\n",
    "    losses = []\n",
    "    accs = []\n",
    "    dps = []\n",
    "    dis = []\n",
    "    \n",
    "    for epoch in range(0, epochs):\n",
    "        epoch_acc = []\n",
    "        dp = []\n",
    "        di = []\n",
    "        \n",
    "        for X, Y, A in train_dataset:\n",
    "            \n",
    "            train_unfair(unfair_clas, X, Y, optmizer)\n",
    "\n",
    "            epoch_acc.append(metrics.accuracy(Y, tf.math.round(unfair_clas.Y_hat)))\n",
    "\n",
    "            dp.append(metrics.DP(tf.math.round(unfair_clas.Y_hat).numpy(), A))\n",
    "            di.append(metrics.DI(Y.numpy(), tf.math.round(unfair_clas.Y_hat).numpy(), A))\n",
    "\n",
    "        losses.append(unfair_clas.loss)\n",
    "        accs.append(tf.math.reduce_mean(epoch_acc))\n",
    "\n",
    "        dps.append(tf.math.reduce_mean(dp))\n",
    "        dis.append(tf.math.reduce_mean(di))\n",
    "    \n",
    "        print(\"> {} | {} | {}\".format(\n",
    "            epoch+1, \n",
    "            tf.math.reduce_mean(losses[-1]),\n",
    "            accs[-1]))\n",
    "\n",
    "    return tf.math.reduce_mean(losses[-1]), accs[-1], dps, dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, valid_data):\n",
    "    losses = {'clas':[], 'dec':[], 'adv':[], 'model':[]}\n",
    "    accs = {'clas':[], 'dec':[], 'adv':[]}\n",
    "    \n",
    "    for X, Y, A in valid_data:\n",
    "        \n",
    "        model(X, Y)\n",
    "        \n",
    "        losses['model'].append(model.loss)\n",
    "        accs['clas'].append(metrics.accuracy(Y, tf.math.round(model.Y_hat)))\n",
    "    \n",
    "    print(\"> Model Loss | Class Loss | Adv Loss | Dec Loss | Class Acc | Adv Acc | Dec Acc\")\n",
    "    print(\"> {} | {} | {} | {} | {} | {} | {}\".format(\n",
    "            tf.math.reduce_mean(losses['model'][-1]),\n",
    "            tf.math.reduce_mean(losses['clas']),\n",
    "            tf.math.reduce_mean(losses['adv']), \n",
    "            tf.math.reduce_mean(losses['dec']), \n",
    "            tf.math.reduce_mean(accs['clas']),\n",
    "            tf.math.reduce_mean(accs['adv']), \n",
    "            tf.math.reduce_mean(accs['dec'])))\n",
    "\n",
    "    return losses, accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfairmlp = UnfairMLP(xdim, zdim, ydim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Epoch | Class Loss | Class Acc\n",
      "/home/luiz/ufpb/mestrado/code/falsb/util/metrics.py:79: RuntimeWarning: invalid value encountered in float_scalars\n",
      "  return FN(Y, Ypred) / pos(Y)\n",
      "> 1 | 1.3505558967590332 | 0.789290450928382\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=1.3505559>,\n",
       " <tf.Tensor: shape=(), dtype=float64, numpy=0.789290450928382>,\n",
       " [<tf.Tensor: shape=(), dtype=float32, numpy=0.13864583>],\n",
       " [<tf.Tensor: shape=(), dtype=float64, numpy=nan>])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "train_unfair_loop(unfairmlp, train_data, 1, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Model Loss | Class Loss | Adv Loss | Dec Loss | Class Acc | Adv Acc | Dec Acc\n> 0.8018909692764282 | nan | nan | nan | 0.789561170212766 | nan | nan\n"
     ]
    }
   ],
   "source": [
    "loss, acc = validation(unfairmlp, valid_data)"
   ]
  }
 ]
}