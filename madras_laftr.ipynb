{
 "cells": [
  {
   "source": [
    "## Import libs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from util.dataset import Dataset\n",
    "from util import read_data as rd\n",
    "from tensorflow.keras import layers\n",
    "from madras_laftr import trainer, tester\n",
    "from madras_laftr.models import *\n",
    "from util.results import ResultLogger\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.data import Dataset\n",
    "from util import metrics"
   ]
  },
  {
   "source": [
    "## Preliminaries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "opt = Adam(learning_rate=learning_rate)\n",
    "class_coeff = 1.0\n",
    "fair_coeff = 1.0\n",
    "recon_coeff = 0.0\n",
    "hidden_layer_specs = {'clas':[8] , 'enc':[8] , 'dec':[8] , 'adv':[8]}"
   ]
  },
  {
   "source": [
    "## Load data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_name = 'adult'\n",
    "\n",
    "data_info = rd.return_data_info(data_name)\n",
    "npzfile = rd.return_npz(data_name)\n",
    "\n",
    "data = Dataset(npzfile=npzfile, name=data_name, a0_name=data_info['a0_name'], a1_name=data_info['a1_name'], \n",
    "                use_a=data_info['use_a'], seed=data_info['seed'], batch_size=batch_size)\n",
    "\n",
    "data_shapes = list(data.get_shapes())\n",
    "#print(data_shapes)\n",
    "\n",
    "xdim = data_shapes[0][1]\n",
    "ydim = data_shapes[1][1]\n",
    "adim = data_shapes[2][1]\n",
    "zdim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 113), (None, 1), (None, 1)), types: (tf.float64, tf.float32, tf.float32)>"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "train_data = Dataset.from_tensor_slices((data.x_train, data.y_train, data.a_train))\n",
    "train_data = train_data.batch(batch_size)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = Dataset.from_tensor_slices((data.x_valid, data.y_valid, data.a_valid))\n",
    "valid_data = valid_data.batch(batch_size)"
   ]
  },
  {
   "source": [
    "## Train loop"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X, Y, A, optimizer, learning_rate=0.001):\n",
    "    \n",
    "    '''training enc-clas-dec'''\n",
    "   \n",
    "    enc_clas_dec = model.enc.variables + model.clas.variables + model.dec.variables\n",
    "    adv = model.adv.variables\n",
    "   \n",
    "    with tf.GradientTape() as tape0, tf.GradientTape() as tape1:\n",
    "        \n",
    "        tape0.watch(enc_clas_dec)\n",
    "        tape1.watch(adv)\n",
    "\n",
    "        model(X, Y, A) #to compute the foward\n",
    "        current_loss = model.loss\n",
    "    \n",
    "    grads = tape0.gradient(current_loss, enc_clas_dec)\n",
    "    optimizer.apply_gradients(zip(grads, enc_clas_dec))\n",
    "\n",
    "    grads_adv = tape1.gradient(current_loss, adv)\n",
    "    optimizer.apply_gradients(zip(grads_adv, adv))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, train_dataset, epochs, optmizer):\n",
    "    \n",
    "    print(\"> Epoch | Model Loss | Class Loss | Adv Loss | Dec Loss | Class Acc | Adv Acc | Dec Acc\")\n",
    "\n",
    "    losses = {'clas':[], 'dec':[], 'adv':[], 'model':[]}\n",
    "    accs = {'clas':[], 'dec':[], 'adv':[]}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for X, Y, A in train_dataset:\n",
    "            \n",
    "            train(model, X, Y, A, optmizer)\n",
    "\n",
    "            losses['model'].append(model.loss)\n",
    "            losses['clas'].append(model.class_loss)\n",
    "            losses['dec'].append(model.recon_loss)\n",
    "            losses['adv'].append(model.adv_loss)\n",
    "            \n",
    "            accs['clas'].append(metrics.accuracy(Y, model.Y_hat))\n",
    "            accs['dec'].append(metrics.accuracy(X, model.X_hat))\n",
    "            accs['adv'].append(metrics.accuracy(A, model.A_hat))\n",
    "\n",
    "    \n",
    "        print(\"> {} | {} | {} | {} | {} | {} | {} | {}\".format(\n",
    "            epoch+1, \n",
    "            losses['model'][-1], \n",
    "            tf.reduce_mean(losses['clas'][-1]), \n",
    "            tf.reduce_mean(losses['dec'][-1]), \n",
    "            tf.reduce_mean(losses['adv'][-1]),\n",
    "            accs['clas'][-1], \n",
    "            accs['dec'][-1], \n",
    "            accs['adv'][-1]))"
   ]
  },
  {
   "source": [
    "## Validation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, valid_data):\n",
    "    losses = {'clas':[], 'dec':[], 'adv':[], 'model':[]}\n",
    "    accs = {'clas':[], 'dec':[], 'adv':[]}\n",
    "    \n",
    "    for X, Y, A in valid_data:\n",
    "        \n",
    "        model(X, Y, A)\n",
    "        \n",
    "        losses['model'].append(model.loss)\n",
    "        losses['clas'].append(model.class_loss)\n",
    "        losses['dec'].append(model.recon_loss)\n",
    "        losses['adv'].append(model.adv_loss)\n",
    "            \n",
    "        accs['clas'].append(metrics.accuracy(Y, model.Y_hat))\n",
    "        accs['dec'].append(metrics.accuracy(X, model.X_hat))\n",
    "        accs['adv'].append(metrics.accuracy(A, model.A_hat))\n",
    "\n",
    "    \n",
    "    print(\"> Model Loss | Class Loss | Adv Loss | Dec Loss | Class Acc | Adv Acc | Dec Acc\")\n",
    "    print(\"> {} | {} | {} | {} | {} | {} | {}\".format(\n",
    "            losses['model'][-1], \n",
    "            tf.reduce_mean(losses['clas'][-1]), \n",
    "            tf.reduce_mean(losses['dec'][-1]), \n",
    "            tf.reduce_mean(losses['adv'][-1]),\n",
    "            accs['clas'][-1], \n",
    "            accs['dec'][-1], \n",
    "            accs['adv'][-1]))\n",
    "\n",
    "    return losses, accs"
   ]
  },
  {
   "source": [
    "## Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### For DP"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DemParGan(xdim, ydim, adim, zdim, hidden_layer_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch | Model Loss | Class Loss | Adv Loss | Dec Loss | Class Acc | Adv Acc | Dec Acc\n",
      "> 1 | 0.4501360356807709 | 1.3504080772399902 | 44069.859375 | 2.7300333976745605 | 0.71875 | -107.703125 | 0.5625\n",
      "> 2 | 0.444221168756485 | 1.3326635360717773 | 44073.90625 | 2.6915078163146973 | 0.734375 | -107.421875 | 0.5625\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, train_data, 2, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "> Model Loss | Class Loss | Adv Loss | Dec Loss | Class Acc | Adv Acc | Dec Acc\n> 0.2625291347503662 | 0.7875874042510986 | 54112.0859375 | 3.5792055130004883 | 0.84375 | -131.328125 | 0.546875\n"
     ]
    }
   ],
   "source": [
    "valid_losses, valid_accs = validation(model, valid_data)"
   ]
  },
  {
   "source": [
    "### For EqOdds"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### For EqOpp"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pegar s√≥ y=0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('falsb': conda)",
   "metadata": {
    "interpreter": {
     "hash": "34ca74ed6235dfc7dda926bb3adb31e801e3d02679121d5b444ee035e270bd57"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}