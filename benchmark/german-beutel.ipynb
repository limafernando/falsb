{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing file \n",
    "### where we evaluate BEUTEL's models using the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad\n",
    "\n",
    "\n",
    "from util.load_data import load_data\n",
    "from util.evaluation import *\n",
    "from models.beutel.models import *\n",
    "from models.beutel.learning import train_loop as beutel_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FAIR_COEFFS = [1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_seeds = [13, 29, 42, 55, 73]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'german'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, a = load_data(data_name)\n",
    "raw_data = (x, y, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = x.shape[1]\n",
    "ydim = y.shape[1]\n",
    "adim = a.shape[1]\n",
    "zdim = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"model_name\", \"cv_seed\",\"fair_coeff\", \"clas_acc\", \"dp\", \"deqodds\", \"deqopp\", \"trade_dp\", \"trade_deqodds\", \"trade_deqopp\", \"TN_a0\", \"FP_a0\", \"FN_a0\", \"TP_a0\", \"TN_a1\", \"FP_a1\", \"FN_a1\", \"TP_a1\"\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loop\n",
    "#### Each model is evalueted 5 times\n",
    "#### In the end of each iteration we save the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEUTEL for DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch | Model Loss | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6253901124000549 | 0.5316413044929504 | 0.7191388607025146 | 0.6622023809523809 | 0.6800595238095238\n",
      "> 2 | 0.6217646598815918 | 0.5315810441970825 | 0.7119483351707458 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 3 | 0.6186708807945251 | 0.5318962335586548 | 0.7054455280303955 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 4 | 0.6161513328552246 | 0.5324298143386841 | 0.6998728513717651 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 5 | 0.6141088008880615 | 0.5330852270126343 | 0.6951323747634888 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 6 | 0.6124470233917236 | 0.5337932109832764 | 0.6911007761955261 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 7 | 0.6110860109329224 | 0.534504771232605 | 0.6876673102378845 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 8 | 0.6099621057510376 | 0.5351870059967041 | 0.6847372651100159 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 9 | 0.6090251207351685 | 0.5358191728591919 | 0.6822310090065002 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 10 | 0.6082359552383423 | 0.5363901257514954 | 0.680081844329834 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 11 | 0.6075648069381714 | 0.536895215511322 | 0.6782342195510864 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 12 | 0.6069881916046143 | 0.5373344421386719 | 0.6766420006752014 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 13 | 0.6064886450767517 | 0.5377107858657837 | 0.675266444683075 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 14 | 0.6060523986816406 | 0.538029134273529 | 0.6740756034851074 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 15 | 0.6056687831878662 | 0.5382949709892273 | 0.6730424761772156 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 16 | 0.6053295731544495 | 0.5385144948959351 | 0.6721446514129639 | 0.6785714285714286 | 0.6964285714285714\n",
      "> 17 | 0.6050283312797546 | 0.5386936068534851 | 0.6713630557060242 | 0.6741071428571429 | 0.6979166666666666\n",
      "> 18 | 0.6047598123550415 | 0.5388379096984863 | 0.6706816554069519 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 19 | 0.6045198440551758 | 0.5389527678489685 | 0.6700868606567383 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 20 | 0.6043049097061157 | 0.5390426516532898 | 0.6695671081542969 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 21 | 0.6041121482849121 | 0.539111852645874 | 0.6691124439239502 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 22 | 0.6039391160011292 | 0.5391638875007629 | 0.6687142848968506 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 23 | 0.6037837266921997 | 0.5392019152641296 | 0.668365478515625 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 24 | 0.6036441326141357 | 0.5392285585403442 | 0.6680595874786377 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 25 | 0.6035186648368835 | 0.539246141910553 | 0.6677912473678589 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 26 | 0.6034060120582581 | 0.5392563939094543 | 0.6675556302070618 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 27 | 0.6033048629760742 | 0.539260983467102 | 0.6673486232757568 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 28 | 0.6032140254974365 | 0.5392612218856812 | 0.6671667695045471 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 29 | 0.6031324863433838 | 0.5392581224441528 | 0.6670069694519043 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 30 | 0.6030594110488892 | 0.539252519607544 | 0.6668663024902344 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 31 | 0.6029938459396362 | 0.5392451286315918 | 0.6667425632476807 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 32 | 0.6029351949691772 | 0.5392366647720337 | 0.6666337251663208 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 33 | 0.6028825640678406 | 0.5392273664474487 | 0.6665377616882324 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 34 | 0.6028355360031128 | 0.5392176508903503 | 0.6664533615112305 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 35 | 0.6027933359146118 | 0.5392077565193176 | 0.6663789749145508 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 36 | 0.6027556657791138 | 0.5391979813575745 | 0.6663134098052979 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 37 | 0.6027220487594604 | 0.5391885042190552 | 0.6662555932998657 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 38 | 0.6026919484138489 | 0.539179265499115 | 0.666204571723938 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 39 | 0.6026650667190552 | 0.5391704440116882 | 0.6661596298217773 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 40 | 0.6026410460472107 | 0.5391620993614197 | 0.6661199331283569 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 41 | 0.6026196479797363 | 0.5391542911529541 | 0.6660849452018738 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 42 | 0.6026004552841187 | 0.5391470193862915 | 0.6660540103912354 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 43 | 0.6025834083557129 | 0.5391402244567871 | 0.6660267114639282 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 44 | 0.6025682687759399 | 0.5391339063644409 | 0.6660025715827942 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 45 | 0.6025546789169312 | 0.5391280651092529 | 0.6659812927246094 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 46 | 0.602542519569397 | 0.5391228199005127 | 0.6659623980522156 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 47 | 0.6025317907333374 | 0.5391178131103516 | 0.6659457087516785 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 48 | 0.6025221347808838 | 0.5391134023666382 | 0.665930986404419 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 49 | 0.6025136709213257 | 0.5391093492507935 | 0.6659179925918579 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 50 | 0.6025060415267944 | 0.5391056537628174 | 0.6659064292907715 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 51 | 0.60249924659729 | 0.53910231590271 | 0.6658961772918701 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 52 | 0.602493166923523 | 0.5390992164611816 | 0.665887176990509 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 53 | 0.6024877429008484 | 0.539096474647522 | 0.6658791303634644 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 54 | 0.6024830341339111 | 0.5390939712524414 | 0.6658719778060913 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 55 | 0.6024787425994873 | 0.5390917062759399 | 0.6658656597137451 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 56 | 0.6024749279022217 | 0.5390897393226624 | 0.665860116481781 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 57 | 0.6024715304374695 | 0.5390879511833191 | 0.6658551096916199 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 58 | 0.6024684906005859 | 0.5390862822532654 | 0.6658506989479065 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 59 | 0.6024658679962158 | 0.539084792137146 | 0.6658468246459961 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 60 | 0.60246342420578 | 0.5390834808349609 | 0.6658433079719543 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 61 | 0.6024612784385681 | 0.5390822887420654 | 0.665840208530426 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 62 | 0.6024593710899353 | 0.5390812754631042 | 0.6658374071121216 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 63 | 0.6024576425552368 | 0.5390802621841431 | 0.6658350229263306 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 64 | 0.6024560928344727 | 0.5390794277191162 | 0.6658328175544739 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 65 | 0.6024547815322876 | 0.5390787124633789 | 0.6658308506011963 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 66 | 0.6024535894393921 | 0.5390780568122864 | 0.6658291220664978 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 67 | 0.6024525165557861 | 0.5390774011611938 | 0.6658275127410889 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 68 | 0.6024515628814697 | 0.5390769243240356 | 0.6658262014389038 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 69 | 0.6024506688117981 | 0.5390764474868774 | 0.6658249497413635 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 70 | 0.602449893951416 | 0.5390759706497192 | 0.6658238172531128 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 71 | 0.6024492383003235 | 0.5390756130218506 | 0.6658228039741516 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 72 | 0.602448582649231 | 0.5390752553939819 | 0.66582190990448 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 73 | 0.602448046207428 | 0.5390750169754028 | 0.6658210754394531 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 74 | 0.602447509765625 | 0.539074718952179 | 0.6658203601837158 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 75 | 0.6024471521377563 | 0.5390745401382446 | 0.6658197641372681 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 76 | 0.6024467349052429 | 0.5390743017196655 | 0.6658191680908203 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 77 | 0.6024463772773743 | 0.539074182510376 | 0.6658185720443726 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 78 | 0.6024460792541504 | 0.5390739440917969 | 0.6658180952072144 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 79 | 0.6024457216262817 | 0.5390738248825073 | 0.6658177375793457 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 80 | 0.6024454832077026 | 0.5390737056732178 | 0.6658172607421875 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 81 | 0.6024452447891235 | 0.5390735864639282 | 0.6658169627189636 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 82 | 0.6024450659751892 | 0.5390734672546387 | 0.665816605091095 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 83 | 0.6024448871612549 | 0.5390734076499939 | 0.6658163070678711 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 84 | 0.6024446487426758 | 0.5390733480453491 | 0.6658160090446472 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 85 | 0.6024445295333862 | 0.5390732884407043 | 0.6658157110214233 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 86 | 0.6024444103240967 | 0.5390731692314148 | 0.665815532207489 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 87 | 0.6024442315101624 | 0.5390731692314148 | 0.6658153533935547 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 88 | 0.6024441719055176 | 0.53907310962677 | 0.6658151149749756 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 89 | 0.602444052696228 | 0.53907310962677 | 0.665814995765686 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 90 | 0.6024439334869385 | 0.5390730500221252 | 0.6658148169517517 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 91 | 0.6024438142776489 | 0.5390730500221252 | 0.6658146977424622 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 92 | 0.6024437546730042 | 0.5390729904174805 | 0.6658145189285278 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 93 | 0.6024436950683594 | 0.5390730500221252 | 0.6658143997192383 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 94 | 0.6024435758590698 | 0.5390729904174805 | 0.6658142805099487 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 95 | 0.6024435758590698 | 0.5390729904174805 | 0.6658141613006592 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 96 | 0.6024434566497803 | 0.5390729904174805 | 0.6658140420913696 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 97 | 0.6024434566497803 | 0.5390729904174805 | 0.6658139228820801 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 98 | 0.6024433374404907 | 0.5390729904174805 | 0.6658138036727905 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 99 | 0.6024433374404907 | 0.5390729904174805 | 0.6658137440681458 | 0.6770833333333334 | 0.7008928571428571\n",
      "> 100 | 0.602443277835846 | 0.5390729904174805 | 0.6658136248588562 | 0.6770833333333334 | 0.7008928571428571\n",
      "> Evaluation\n",
      "> Class Acc = 0.7118055820465088\n",
      "> Adv Acc = 0.7118055820465088\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.9990129470825195 | 0.9911059243604541 | 0.9962864723056555\n",
      "> Confusion Matrix \n",
      "TN: 2.0 | FP: 76.0 \n",
      "FN: 7.0 | TP: 203.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 1.0 | FP: 28.0 \n",
      "FN: 2.0 | TP: 63.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 1.0 | FP: 48.0 \n",
      "FN: 5.0 | TP: 140.0\n",
      "> Epoch | Model Loss | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.5533115863800049 | 0.5367910861968994 | 0.5698320269584656 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 2 | 0.5538812279701233 | 0.5375783443450928 | 0.5701841115951538 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 3 | 0.5543956160545349 | 0.53835129737854 | 0.5704400539398193 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 4 | 0.5549863576889038 | 0.5391978025436401 | 0.5707747936248779 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 5 | 0.5556234121322632 | 0.5400780439376831 | 0.5711687207221985 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 6 | 0.5562718510627747 | 0.5409530997276306 | 0.5715905427932739 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 7 | 0.5569058656692505 | 0.5417953133583069 | 0.5720163583755493 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 8 | 0.5575085878372192 | 0.542587399482727 | 0.5724297761917114 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 9 | 0.5580698847770691 | 0.5433194637298584 | 0.5728203058242798 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 10 | 0.5585842132568359 | 0.5439866781234741 | 0.5731819272041321 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 11 | 0.5590499639511108 | 0.5445883274078369 | 0.5735116004943848 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 12 | 0.5594674348831177 | 0.54512619972229 | 0.5738086104393005 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 13 | 0.5598384737968445 | 0.5456035137176514 | 0.5740735530853271 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 14 | 0.5601662397384644 | 0.5460245609283447 | 0.574307918548584 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 15 | 0.5604540109634399 | 0.5463940501213074 | 0.5745140910148621 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 16 | 0.5607056617736816 | 0.5467169284820557 | 0.5746943354606628 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 17 | 0.5609246492385864 | 0.5469980239868164 | 0.5748512148857117 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 18 | 0.5611146092414856 | 0.5472419857978821 | 0.5749872922897339 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 19 | 0.5612789392471313 | 0.5474531650543213 | 0.5751047134399414 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 20 | 0.5614206790924072 | 0.5476354360580444 | 0.5752060413360596 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 21 | 0.5615427494049072 | 0.5477924346923828 | 0.5752930641174316 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 22 | 0.5616475343704224 | 0.5479274392127991 | 0.5753676891326904 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 23 | 0.5617374181747437 | 0.5480433106422424 | 0.5754315853118896 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 24 | 0.5618143677711487 | 0.5481426119804382 | 0.5754861831665039 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 25 | 0.5618801116943359 | 0.5482275485992432 | 0.5755326747894287 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 26 | 0.5619362592697144 | 0.5483001470565796 | 0.5755723714828491 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 27 | 0.5619840621948242 | 0.5483620762825012 | 0.575606107711792 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 28 | 0.5620248317718506 | 0.5484148859977722 | 0.575634777545929 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 29 | 0.5620594620704651 | 0.5484598278999329 | 0.5756591558456421 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 30 | 0.5620889067649841 | 0.5484980344772339 | 0.5756797790527344 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 31 | 0.562113881111145 | 0.5485305190086365 | 0.5756971836090088 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 32 | 0.5621349811553955 | 0.5485580563545227 | 0.5757119655609131 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 33 | 0.5621529817581177 | 0.5485813617706299 | 0.5757244825363159 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 34 | 0.5621681213378906 | 0.5486011505126953 | 0.5757350921630859 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 35 | 0.5621809363365173 | 0.5486178398132324 | 0.5757439732551575 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 36 | 0.5621917247772217 | 0.5486319661140442 | 0.5757514834403992 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 37 | 0.5622008442878723 | 0.548643946647644 | 0.5757578015327454 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 38 | 0.5622085332870483 | 0.5486539602279663 | 0.5757631063461304 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 39 | 0.5622150301933289 | 0.5486624240875244 | 0.5757675766944885 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 40 | 0.5622204542160034 | 0.5486695766448975 | 0.5757713317871094 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 41 | 0.5622249841690063 | 0.548675537109375 | 0.5757744312286377 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 42 | 0.562228798866272 | 0.5486805438995361 | 0.5757770538330078 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 43 | 0.5622320175170898 | 0.5486847162246704 | 0.5757792592048645 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 44 | 0.56223464012146 | 0.5486882328987122 | 0.5757811069488525 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 45 | 0.5622368454933167 | 0.5486911535263062 | 0.5757825970649719 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 46 | 0.5622386932373047 | 0.5486935973167419 | 0.5757838487625122 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 47 | 0.5622402429580688 | 0.5486956238746643 | 0.5757849216461182 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 48 | 0.5622414946556091 | 0.5486972332000732 | 0.575785756111145 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 49 | 0.5622425675392151 | 0.5486986637115479 | 0.5757864713668823 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 50 | 0.5622434616088867 | 0.5486998558044434 | 0.5757870674133301 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 51 | 0.562244176864624 | 0.5487008094787598 | 0.5757875442504883 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 52 | 0.562244713306427 | 0.5487015247344971 | 0.5757879018783569 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 53 | 0.5622451901435852 | 0.5487021803855896 | 0.5757881999015808 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 54 | 0.5622456073760986 | 0.5487027168273926 | 0.5757884979248047 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 55 | 0.5622458457946777 | 0.5487030744552612 | 0.5757886171340942 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 56 | 0.5622461438179016 | 0.5487034916877747 | 0.5757887959480286 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 57 | 0.5622463226318359 | 0.5487037897109985 | 0.5757888555526733 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 58 | 0.5622464418411255 | 0.5487039685249329 | 0.5757889747619629 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 59 | 0.562246561050415 | 0.5487041473388672 | 0.5757890343666077 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 60 | 0.5622466802597046 | 0.5487042665481567 | 0.5757890343666077 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 61 | 0.5622467398643494 | 0.5487043857574463 | 0.5757890939712524 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 62 | 0.5622467994689941 | 0.5487045049667358 | 0.5757890939712524 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 63 | 0.5622468590736389 | 0.5487045645713806 | 0.5757891535758972 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 64 | 0.5622467994689941 | 0.5487046241760254 | 0.5757890939712524 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 65 | 0.5622468590736389 | 0.5487046241760254 | 0.5757890939712524 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 66 | 0.5622468590736389 | 0.5487046241760254 | 0.5757890939712524 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 67 | 0.5622468590736389 | 0.5487046837806702 | 0.5757890343666077 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 68 | 0.5622468590736389 | 0.5487046837806702 | 0.5757890343666077 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 69 | 0.5622468590736389 | 0.5487046837806702 | 0.5757889747619629 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 70 | 0.5622468590736389 | 0.5487046837806702 | 0.5757889747619629 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 71 | 0.5622468590736389 | 0.5487047433853149 | 0.5757889747619629 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 72 | 0.5622467994689941 | 0.5487047433853149 | 0.5757889151573181 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 73 | 0.5622467994689941 | 0.5487047433853149 | 0.5757889151573181 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 74 | 0.5622467994689941 | 0.5487047433853149 | 0.5757889151573181 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 75 | 0.5622467398643494 | 0.5487047433853149 | 0.5757888555526733 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 76 | 0.5622467994689941 | 0.5487047433853149 | 0.5757888555526733 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 77 | 0.5622467994689941 | 0.5487047433853149 | 0.5757887959480286 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 78 | 0.5622466802597046 | 0.5487047433853149 | 0.5757887363433838 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 79 | 0.5622466802597046 | 0.5487047433853149 | 0.5757887363433838 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 80 | 0.5622467994689941 | 0.5487047433853149 | 0.5757887363433838 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 81 | 0.5622466802597046 | 0.5487047433853149 | 0.575788676738739 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 82 | 0.5622467398643494 | 0.5487047433853149 | 0.575788676738739 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 83 | 0.5622466802597046 | 0.5487047433853149 | 0.5757886171340942 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 84 | 0.5622467398643494 | 0.5487047433853149 | 0.5757886171340942 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 85 | 0.5622466802597046 | 0.5487047433853149 | 0.5757886171340942 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 86 | 0.5622466802597046 | 0.5487048029899597 | 0.5757886171340942 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 87 | 0.5622466206550598 | 0.5487047433853149 | 0.5757885575294495 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 88 | 0.5622466802597046 | 0.5487047433853149 | 0.5757884979248047 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 89 | 0.5622466802597046 | 0.5487047433853149 | 0.5757884979248047 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 90 | 0.5622466802597046 | 0.5487048029899597 | 0.5757884979248047 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 91 | 0.5622466206550598 | 0.5487048029899597 | 0.5757884383201599 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 92 | 0.562246561050415 | 0.5487048625946045 | 0.5757883787155151 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 93 | 0.5622466206550598 | 0.5487048029899597 | 0.5757883787155151 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 94 | 0.562246561050415 | 0.5487048625946045 | 0.5757883191108704 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 95 | 0.562246561050415 | 0.5487048625946045 | 0.5757883787155151 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 96 | 0.562246561050415 | 0.5487048625946045 | 0.5757882595062256 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 97 | 0.562246561050415 | 0.5487048625946045 | 0.5757882595062256 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 98 | 0.562246561050415 | 0.5487048625946045 | 0.5757882595062256 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 99 | 0.562246561050415 | 0.5487048625946045 | 0.5757882595062256 | 0.7113095238095238 | 0.6919642857142857\n",
      "> 100 | 0.562246561050415 | 0.5487048029899597 | 0.5757881999015808 | 0.7113095238095238 | 0.6919642857142857\n",
      "> Evaluation\n",
      "> Class Acc = 0.6736111044883728\n",
      "> Adv Acc = 0.6736111044883728\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 1.0 | 1.0 | 1.0\n",
      "> Confusion Matrix \n",
      "TN: 0.0 | FP: 94.0 \n",
      "FN: 0.0 | TP: 194.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 0.0 | FP: 38.0 \n",
      "FN: 0.0 | TP: 50.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 0.0 | FP: 56.0 \n",
      "FN: 0.0 | TP: 144.0\n",
      "> Epoch | Model Loss | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6963679790496826 | 0.6848211884498596 | 0.7079147696495056 | 0.6860119047619048 | 0.6622023809523809\n",
      "> 2 | 0.6844192147254944 | 0.6742833852767944 | 0.6945550441741943 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 3 | 0.673778235912323 | 0.6647833585739136 | 0.682773232460022 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 4 | 0.6646170020103455 | 0.656591534614563 | 0.6726424694061279 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 5 | 0.6567789316177368 | 0.6495774388313293 | 0.6639804840087891 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 6 | 0.6500824689865112 | 0.6435778141021729 | 0.6565872430801392 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 7 | 0.6443624496459961 | 0.6384443044662476 | 0.6502804756164551 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 8 | 0.639474630355835 | 0.6340487003326416 | 0.6449006199836731 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 9 | 0.6352954506874084 | 0.6302812099456787 | 0.640309751033783 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 10 | 0.6317191123962402 | 0.6270484924316406 | 0.6363897323608398 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 11 | 0.628655731678009 | 0.6242716312408447 | 0.6330398321151733 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 12 | 0.6260290145874023 | 0.6218833923339844 | 0.6301745772361755 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 13 | 0.6237742900848389 | 0.6198273301124573 | 0.6277213096618652 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 14 | 0.6218369603157043 | 0.6180551052093506 | 0.6256188154220581 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 15 | 0.620170533657074 | 0.6165261268615723 | 0.6238149404525757 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 16 | 0.618735671043396 | 0.6152056455612183 | 0.6222658157348633 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 17 | 0.6174991130828857 | 0.6140642166137695 | 0.620934009552002 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 18 | 0.6164324283599854 | 0.6130768656730652 | 0.6197880506515503 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 19 | 0.615511417388916 | 0.6122220158576965 | 0.618800938129425 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 20 | 0.6147156953811646 | 0.6114813685417175 | 0.6179499626159668 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 21 | 0.6140275001525879 | 0.6108392477035522 | 0.6172157526016235 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 22 | 0.6134319305419922 | 0.610282301902771 | 0.6165816783905029 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 23 | 0.6129161715507507 | 0.609798789024353 | 0.6160336136817932 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 24 | 0.6124692559242249 | 0.6093789339065552 | 0.6155596375465393 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 25 | 0.6120816469192505 | 0.6090140342712402 | 0.6151493191719055 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 26 | 0.6117453575134277 | 0.6086968183517456 | 0.6147938966751099 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 27 | 0.6114534139633179 | 0.6084209680557251 | 0.6144858598709106 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 28 | 0.6111997365951538 | 0.6081808805465698 | 0.6142185926437378 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 29 | 0.6109792590141296 | 0.6079717874526978 | 0.6139866709709167 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 30 | 0.6107875108718872 | 0.6077897548675537 | 0.6137852072715759 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 31 | 0.6106206178665161 | 0.6076311469078064 | 0.6136101484298706 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 32 | 0.6104754209518433 | 0.6074928045272827 | 0.6134578585624695 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 33 | 0.6103488206863403 | 0.6073722243309021 | 0.6133254170417786 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 34 | 0.6102385520935059 | 0.6072670221328735 | 0.6132100820541382 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 35 | 0.6101423501968384 | 0.6071751713752747 | 0.6131095886230469 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 36 | 0.6100584268569946 | 0.607094943523407 | 0.613021969795227 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 37 | 0.6099852323532104 | 0.6070248484611511 | 0.6129456162452698 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 38 | 0.6099213361740112 | 0.6069636344909668 | 0.6128789782524109 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 39 | 0.6098654270172119 | 0.6069101095199585 | 0.6128208041191101 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 40 | 0.6098166108131409 | 0.606863260269165 | 0.6127699613571167 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 41 | 0.6097738742828369 | 0.6068222522735596 | 0.6127256155014038 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 42 | 0.6097365617752075 | 0.6067863702774048 | 0.6126867532730103 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 43 | 0.6097038984298706 | 0.6067548990249634 | 0.6126527786254883 | 0.7038690476190477 | 0.6860119047619048\n",
      "> 44 | 0.6096752285957336 | 0.6067273616790771 | 0.6126230955123901 | 0.7023809523809523 | 0.6845238095238095\n",
      "> 45 | 0.6096501350402832 | 0.6067032217979431 | 0.6125971078872681 | 0.7023809523809523 | 0.6845238095238095\n",
      "> 46 | 0.6096282005310059 | 0.6066820621490479 | 0.6125743389129639 | 0.7008928571428571 | 0.6830357142857143\n",
      "> 47 | 0.6096089482307434 | 0.6066635251045227 | 0.6125543117523193 | 0.6994047619047619 | 0.6845238095238095\n",
      "> 48 | 0.6095919609069824 | 0.606647253036499 | 0.6125367879867554 | 0.6994047619047619 | 0.6845238095238095\n",
      "> 49 | 0.6095771789550781 | 0.6066328287124634 | 0.6125214695930481 | 0.6994047619047619 | 0.6845238095238095\n",
      "> 50 | 0.6095641851425171 | 0.6066203117370605 | 0.6125079989433289 | 0.6979166666666666 | 0.6830357142857143\n",
      "> 51 | 0.6095527410507202 | 0.6066092252731323 | 0.6124961972236633 | 0.6979166666666666 | 0.6830357142857143\n",
      "> 52 | 0.6095426678657532 | 0.6065995693206787 | 0.6124857664108276 | 0.6979166666666666 | 0.6830357142857143\n",
      "> 53 | 0.6095338463783264 | 0.606590986251831 | 0.6124767065048218 | 0.6964285714285714 | 0.6815476190476191\n",
      "> 54 | 0.6095260381698608 | 0.6065834760665894 | 0.6124686598777771 | 0.6964285714285714 | 0.6815476190476191\n",
      "> 55 | 0.6095192432403564 | 0.6065769195556641 | 0.6124616265296936 | 0.6949404761904762 | 0.6800595238095238\n",
      "> 56 | 0.6095132827758789 | 0.6065710783004761 | 0.612455427646637 | 0.6949404761904762 | 0.6800595238095238\n",
      "> 57 | 0.6095079183578491 | 0.6065658926963806 | 0.6124500036239624 | 0.6949404761904762 | 0.6800595238095238\n",
      "> 58 | 0.6095032691955566 | 0.6065614223480225 | 0.6124451756477356 | 0.6949404761904762 | 0.6800595238095238\n",
      "> 59 | 0.6094992160797119 | 0.6065573692321777 | 0.6124409437179565 | 0.6949404761904762 | 0.6800595238095238\n",
      "> 60 | 0.6094955801963806 | 0.606553852558136 | 0.6124372482299805 | 0.6949404761904762 | 0.6800595238095238\n",
      "> 61 | 0.6094924211502075 | 0.6065506935119629 | 0.6124340295791626 | 0.6949404761904762 | 0.6800595238095238\n",
      "> 62 | 0.6094896197319031 | 0.6065479516983032 | 0.6124311685562134 | 0.6949404761904762 | 0.6800595238095238\n",
      "> 63 | 0.6094870567321777 | 0.6065455675125122 | 0.6124286651611328 | 0.6964285714285714 | 0.6785714285714286\n",
      "> 64 | 0.6094849109649658 | 0.6065434217453003 | 0.6124264001846313 | 0.6964285714285714 | 0.6785714285714286\n",
      "> 65 | 0.609483003616333 | 0.6065415143966675 | 0.6124244332313538 | 0.6964285714285714 | 0.6785714285714286\n",
      "> 66 | 0.6094813346862793 | 0.6065398454666138 | 0.6124227046966553 | 0.6964285714285714 | 0.6785714285714286\n",
      "> 67 | 0.6094797849655151 | 0.6065384149551392 | 0.6124212145805359 | 0.6964285714285714 | 0.6785714285714286\n",
      "> 68 | 0.6094784736633301 | 0.6065371036529541 | 0.612419843673706 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 69 | 0.6094772815704346 | 0.6065359115600586 | 0.6124187707901001 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 70 | 0.6094763278961182 | 0.6065348982810974 | 0.6124176979064941 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 71 | 0.6094753742218018 | 0.606533944606781 | 0.6124168038368225 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 72 | 0.6094745397567749 | 0.6065331697463989 | 0.6124159693717957 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 73 | 0.6094738245010376 | 0.6065324544906616 | 0.6124153137207031 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 74 | 0.6094732284545898 | 0.6065317988395691 | 0.6124147176742554 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 75 | 0.6094726920127869 | 0.6065312623977661 | 0.6124141216278076 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 76 | 0.6094722151756287 | 0.6065307855606079 | 0.6124136447906494 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 77 | 0.6094717979431152 | 0.6065303087234497 | 0.612413227558136 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 78 | 0.6094714403152466 | 0.606529951095581 | 0.6124128699302673 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 79 | 0.6094710826873779 | 0.6065295934677124 | 0.6124125719070435 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 80 | 0.609470784664154 | 0.6065292358398438 | 0.6124122738838196 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 81 | 0.6094704866409302 | 0.6065289974212646 | 0.6124120354652405 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 82 | 0.6094702482223511 | 0.6065287590026855 | 0.6124118566513062 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 83 | 0.6094701290130615 | 0.6065285205841064 | 0.612411618232727 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 84 | 0.6094698905944824 | 0.6065283417701721 | 0.6124114990234375 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 85 | 0.6094697713851929 | 0.6065281629562378 | 0.6124113202095032 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 86 | 0.6094696521759033 | 0.6065280437469482 | 0.6124112606048584 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 87 | 0.609469473361969 | 0.6065278649330139 | 0.6124111413955688 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 88 | 0.6094694137573242 | 0.6065278053283691 | 0.6124110221862793 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 89 | 0.6094692945480347 | 0.6065276861190796 | 0.6124109029769897 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 90 | 0.6094692349433899 | 0.6065276265144348 | 0.6124109029769897 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 91 | 0.6094691753387451 | 0.6065274477005005 | 0.6124109029769897 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 92 | 0.6094691157341003 | 0.6065274477005005 | 0.6124107837677002 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 93 | 0.6094690561294556 | 0.6065273284912109 | 0.6124107837677002 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 94 | 0.6094689965248108 | 0.6065273284912109 | 0.6124106645584106 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 95 | 0.6094690561294556 | 0.6065272092819214 | 0.6124107241630554 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 96 | 0.609468936920166 | 0.6065272092819214 | 0.6124107241630554 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 97 | 0.609468936920166 | 0.6065271496772766 | 0.6124107241630554 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 98 | 0.609468936920166 | 0.6065271496772766 | 0.6124106645584106 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 99 | 0.6094688773155212 | 0.6065270900726318 | 0.6124107241630554 | 0.6949404761904762 | 0.6770833333333334\n",
      "> 100 | 0.609468936920166 | 0.6065270304679871 | 0.6124107241630554 | 0.6949404761904762 | 0.6770833333333334\n",
      "> Evaluation\n",
      "> Class Acc = 0.7013888955116272\n",
      "> Adv Acc = 0.7013888955116272\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 1.0 | 1.0 | 1.0\n",
      "> Confusion Matrix \n",
      "TN: 0.0 | FP: 86.0 \n",
      "FN: 0.0 | TP: 202.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 0.0 | FP: 28.0 \n",
      "FN: 0.0 | TP: 57.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 0.0 | FP: 58.0 \n",
      "FN: 0.0 | TP: 145.0\n",
      "> Epoch | Model Loss | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6142507791519165 | 0.5679628849029541 | 0.6605386734008789 | 0.6979166666666666 | 0.6964285714285714\n",
      "> 2 | 0.6140986680984497 | 0.5708432197570801 | 0.6573541164398193 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 3 | 0.6139235496520996 | 0.5734449028968811 | 0.6544023156166077 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 4 | 0.613936185836792 | 0.5759152173995972 | 0.6519571542739868 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 5 | 0.6141085624694824 | 0.5782433748245239 | 0.6499736905097961 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 6 | 0.6143937110900879 | 0.5804101228713989 | 0.6483772993087769 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 7 | 0.6147514581680298 | 0.5824037790298462 | 0.6470991373062134 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 8 | 0.6151503324508667 | 0.5842201709747314 | 0.6460803747177124 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 9 | 0.6155667304992676 | 0.5858615636825562 | 0.645271897315979 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 10 | 0.6159839630126953 | 0.5873347520828247 | 0.6446331739425659 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 11 | 0.6163899898529053 | 0.5886491537094116 | 0.6441308259963989 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 12 | 0.6167771816253662 | 0.5898163318634033 | 0.6437380313873291 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 13 | 0.6171407699584961 | 0.5908487439155579 | 0.6434327960014343 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 14 | 0.61747807264328 | 0.5917587876319885 | 0.6431974172592163 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 15 | 0.6177881956100464 | 0.592558741569519 | 0.6430176496505737 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 16 | 0.6180710792541504 | 0.5932602882385254 | 0.6428818702697754 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 17 | 0.6183277368545532 | 0.5938743948936462 | 0.6427810192108154 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 18 | 0.6185593605041504 | 0.5944110751152039 | 0.6427075862884521 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 19 | 0.6187675595283508 | 0.5948793888092041 | 0.6426556706428528 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 20 | 0.6189541816711426 | 0.5952877998352051 | 0.6426205635070801 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 21 | 0.6191209554672241 | 0.5956435203552246 | 0.6425984501838684 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 22 | 0.6192696690559387 | 0.595953106880188 | 0.6425862312316895 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 23 | 0.6194020509719849 | 0.5962224006652832 | 0.642581582069397 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 24 | 0.6195195913314819 | 0.5964565873146057 | 0.6425826549530029 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 25 | 0.6196238994598389 | 0.5966601371765137 | 0.6425877213478088 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 26 | 0.6197164058685303 | 0.5968369841575623 | 0.6425958871841431 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 27 | 0.6197983026504517 | 0.596990704536438 | 0.6426059007644653 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 28 | 0.6198707818984985 | 0.5971241593360901 | 0.6426173448562622 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 29 | 0.6199347972869873 | 0.5972400903701782 | 0.6426295042037964 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 30 | 0.6199913620948792 | 0.5973408222198486 | 0.6426419019699097 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 31 | 0.6200413703918457 | 0.5974283218383789 | 0.6426543593406677 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 32 | 0.6200853586196899 | 0.5975042581558228 | 0.6426665782928467 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 33 | 0.620124340057373 | 0.5975703001022339 | 0.6426783204078674 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 34 | 0.6201586127281189 | 0.5976276397705078 | 0.64268958568573 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 35 | 0.6201888918876648 | 0.59767746925354 | 0.6427003145217896 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 36 | 0.6202155351638794 | 0.5977208018302917 | 0.642710268497467 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 37 | 0.6202390193939209 | 0.597758412361145 | 0.6427196264266968 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 38 | 0.6202597618103027 | 0.5977911949157715 | 0.6427282691001892 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 39 | 0.620278000831604 | 0.5978196263313293 | 0.6427363157272339 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 40 | 0.6202940344810486 | 0.5978443622589111 | 0.642743706703186 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 41 | 0.6203081607818604 | 0.597865879535675 | 0.6427504420280457 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 42 | 0.6203205585479736 | 0.5978845953941345 | 0.6427565813064575 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 43 | 0.6203315854072571 | 0.597900927066803 | 0.6427622437477112 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 44 | 0.6203413009643555 | 0.5979151129722595 | 0.6427674293518066 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 45 | 0.6203497648239136 | 0.5979275703430176 | 0.6427719593048096 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 46 | 0.6203572154045105 | 0.5979382395744324 | 0.6427761912345886 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 47 | 0.6203638315200806 | 0.5979475975036621 | 0.6427799463272095 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 48 | 0.6203696131706238 | 0.5979558229446411 | 0.6427834033966064 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 49 | 0.6203746795654297 | 0.5979629158973694 | 0.6427865028381348 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 50 | 0.6203792095184326 | 0.597969114780426 | 0.6427893042564392 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 51 | 0.6203831434249878 | 0.5979745388031006 | 0.642791748046875 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 52 | 0.6203866004943848 | 0.5979792475700378 | 0.6427940130233765 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 53 | 0.6203896999359131 | 0.5979833602905273 | 0.6427960395812988 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 54 | 0.6203923225402832 | 0.5979869365692139 | 0.6427978277206421 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 55 | 0.6203947067260742 | 0.597990095615387 | 0.6427993774414062 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 56 | 0.6203967928886414 | 0.5979928374290466 | 0.6428008079528809 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 57 | 0.6203987002372742 | 0.5979952216148376 | 0.6428021192550659 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 58 | 0.6204003095626831 | 0.5979973077774048 | 0.6428031921386719 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 59 | 0.6204017400741577 | 0.5979992151260376 | 0.6428042650222778 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 60 | 0.6204029321670532 | 0.5980007648468018 | 0.6428050994873047 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 61 | 0.6204040050506592 | 0.5980021953582764 | 0.6428059339523315 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 62 | 0.6204049587249756 | 0.5980033874511719 | 0.6428066492080688 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 63 | 0.6204057931900024 | 0.5980044007301331 | 0.6428072452545166 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 64 | 0.6204065680503845 | 0.5980052947998047 | 0.6428078413009644 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 65 | 0.6204072833061218 | 0.5980062484741211 | 0.6428083181381226 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 66 | 0.6204078197479248 | 0.5980069637298584 | 0.642808735370636 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 67 | 0.6204083561897278 | 0.5980075597763062 | 0.6428091526031494 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 68 | 0.6204087734222412 | 0.5980080366134644 | 0.6428093910217285 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 69 | 0.6204091310501099 | 0.5980086326599121 | 0.6428096890449524 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 70 | 0.6204094886779785 | 0.5980089902877808 | 0.6428099870681763 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 71 | 0.6204097867012024 | 0.5980093479156494 | 0.6428101658821106 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 72 | 0.6204100847244263 | 0.5980097055435181 | 0.6428104043006897 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 73 | 0.6204102635383606 | 0.5980100035667419 | 0.642810583114624 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 74 | 0.6204104423522949 | 0.5980101823806763 | 0.6428107619285583 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 75 | 0.6204106211662292 | 0.5980104207992554 | 0.6428108811378479 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 76 | 0.6204107999801636 | 0.5980106592178345 | 0.6428110003471375 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 77 | 0.6204109191894531 | 0.5980108380317688 | 0.6428110599517822 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 78 | 0.6204110383987427 | 0.5980109572410583 | 0.6428111791610718 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 79 | 0.6204111576080322 | 0.5980111360549927 | 0.6428112387657166 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 80 | 0.6204112768173218 | 0.5980112552642822 | 0.6428112983703613 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 81 | 0.6204112768173218 | 0.598011314868927 | 0.6428112983703613 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 82 | 0.6204113960266113 | 0.5980113744735718 | 0.6428114175796509 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 83 | 0.6204115152359009 | 0.5980114936828613 | 0.6428114175796509 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 84 | 0.6204115152359009 | 0.5980115532875061 | 0.6428114771842957 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 85 | 0.6204115152359009 | 0.5980116128921509 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 86 | 0.6204116344451904 | 0.5980116128921509 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 87 | 0.6204116344451904 | 0.5980116724967957 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 88 | 0.6204116344451904 | 0.5980117321014404 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 89 | 0.6204116344451904 | 0.5980117321014404 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 90 | 0.6204116344451904 | 0.5980117321014404 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 91 | 0.6204116940498352 | 0.59801185131073 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 92 | 0.6204116940498352 | 0.59801185131073 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 93 | 0.62041175365448 | 0.59801185131073 | 0.6428115963935852 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 94 | 0.62041175365448 | 0.59801185131073 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 95 | 0.62041175365448 | 0.5980119109153748 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 96 | 0.62041175365448 | 0.5980119705200195 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 97 | 0.62041175365448 | 0.5980119109153748 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 98 | 0.62041175365448 | 0.5980119705200195 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 99 | 0.62041175365448 | 0.5980119705200195 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> 100 | 0.62041175365448 | 0.5980119705200195 | 0.6428115367889404 | 0.7008928571428571 | 0.6934523809523809\n",
      "> Evaluation\n",
      "> Class Acc = 0.6979166865348816\n",
      "> Adv Acc = 0.6979166865348816\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 1.0 | 1.0 | 1.0\n",
      "> Confusion Matrix \n",
      "TN: 0.0 | FP: 87.0 \n",
      "FN: 0.0 | TP: 201.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 0.0 | FP: 29.0 \n",
      "FN: 0.0 | TP: 62.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 0.0 | FP: 58.0 \n",
      "FN: 0.0 | TP: 139.0\n",
      "> Epoch | Model Loss | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6414509415626526 | 0.5972651243209839 | 0.6856368184089661 | 0.6681547619047619 | 0.6622023809523809\n",
      "> 2 | 0.6372319459915161 | 0.5940244793891907 | 0.6804394721984863 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 3 | 0.6335663795471191 | 0.5911955833435059 | 0.6759370565414429 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 4 | 0.6305828094482422 | 0.5889449715614319 | 0.6722207069396973 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 5 | 0.6281856894493103 | 0.5871827602386475 | 0.6691886186599731 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 6 | 0.6262682676315308 | 0.5858107805252075 | 0.6667256951332092 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 7 | 0.6247386336326599 | 0.5847474336624146 | 0.6647297739982605 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 8 | 0.6235207915306091 | 0.5839272141456604 | 0.6631143689155579 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 9 | 0.6225528717041016 | 0.5832979679107666 | 0.6618078947067261 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 10 | 0.6217849254608154 | 0.5828182697296143 | 0.6607515811920166 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 11 | 0.6211766004562378 | 0.5824553966522217 | 0.6598976850509644 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 12 | 0.6206957101821899 | 0.5821837186813354 | 0.6592077016830444 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 13 | 0.6203166246414185 | 0.5819830298423767 | 0.658650279045105 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 14 | 0.6200188994407654 | 0.58183753490448 | 0.6582002639770508 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 15 | 0.6197859048843384 | 0.5817346572875977 | 0.6578372120857239 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 16 | 0.6196048259735107 | 0.5816649198532104 | 0.6575448513031006 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 17 | 0.619465172290802 | 0.5816205739974976 | 0.6573097705841064 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 18 | 0.6193585395812988 | 0.5815956592559814 | 0.6571213603019714 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 19 | 0.6192782521247864 | 0.5815856456756592 | 0.6569708585739136 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 20 | 0.6192190051078796 | 0.5815868377685547 | 0.6568512916564941 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 21 | 0.6191765069961548 | 0.5815963745117188 | 0.6567567586898804 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 22 | 0.6191472411155701 | 0.5816119909286499 | 0.6566826105117798 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 23 | 0.6191285252571106 | 0.5816318988800049 | 0.6566250920295715 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 24 | 0.6191179752349854 | 0.5816548466682434 | 0.6565810441970825 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 25 | 0.6191138029098511 | 0.5816797018051147 | 0.6565479636192322 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 26 | 0.6191145777702332 | 0.5817055702209473 | 0.6565235257148743 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 27 | 0.6191191077232361 | 0.581731915473938 | 0.6565062403678894 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 28 | 0.6191264390945435 | 0.5817582011222839 | 0.6564946174621582 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 29 | 0.6191357970237732 | 0.5817841291427612 | 0.6564874649047852 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 30 | 0.6191465854644775 | 0.5818092823028564 | 0.6564838886260986 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 31 | 0.6191582679748535 | 0.5818334817886353 | 0.6564830541610718 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 32 | 0.6191705465316772 | 0.5818567276000977 | 0.6564843654632568 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 33 | 0.6191830635070801 | 0.5818789005279541 | 0.656487226486206 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 34 | 0.6191955804824829 | 0.5818997621536255 | 0.6564913988113403 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 35 | 0.6192079782485962 | 0.5819194912910461 | 0.6564964056015015 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 36 | 0.619219958782196 | 0.5819379687309265 | 0.6565018892288208 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 37 | 0.6192315816879272 | 0.5819553136825562 | 0.6565079092979431 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 38 | 0.6192427277565002 | 0.5819714069366455 | 0.656514048576355 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 39 | 0.619253396987915 | 0.5819864273071289 | 0.6565202474594116 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 40 | 0.6192633509635925 | 0.5820003747940063 | 0.6565264463424683 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 41 | 0.6192728281021118 | 0.5820132493972778 | 0.6565324664115906 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 42 | 0.6192817091941833 | 0.5820251703262329 | 0.6565383672714233 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 43 | 0.6192899942398071 | 0.5820361375808716 | 0.6565439701080322 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 44 | 0.6192977428436279 | 0.5820462107658386 | 0.656549334526062 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 45 | 0.6193049550056458 | 0.5820555686950684 | 0.6565544009208679 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 46 | 0.6193116307258606 | 0.5820640325546265 | 0.65655916929245 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 47 | 0.6193177700042725 | 0.5820719003677368 | 0.6565636992454529 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 48 | 0.6193234920501709 | 0.5820790529251099 | 0.6565678715705872 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 49 | 0.6193286776542664 | 0.5820855498313904 | 0.6565717458724976 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 50 | 0.6193335056304932 | 0.5820915699005127 | 0.6565754413604736 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 51 | 0.6193379163742065 | 0.5820969343185425 | 0.656578779220581 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 52 | 0.6193418502807617 | 0.5821019411087036 | 0.6565817594528198 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 53 | 0.6193456053733826 | 0.5821065306663513 | 0.6565846800804138 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 54 | 0.61934894323349 | 0.5821106433868408 | 0.6565872430801392 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 55 | 0.6193519830703735 | 0.5821143388748169 | 0.6565896272659302 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 56 | 0.6193548440933228 | 0.5821177959442139 | 0.6565917730331421 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 57 | 0.6193573474884033 | 0.5821208953857422 | 0.6565937399864197 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 58 | 0.6193596124649048 | 0.5821236968040466 | 0.6565955877304077 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 59 | 0.6193617582321167 | 0.582126259803772 | 0.6565971374511719 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 60 | 0.61936354637146 | 0.5821285247802734 | 0.6565986275672913 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 61 | 0.6193652749061584 | 0.5821306109428406 | 0.6565999388694763 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 62 | 0.6193667650222778 | 0.5821324586868286 | 0.6566011309623718 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 63 | 0.6193681955337524 | 0.5821341872215271 | 0.6566022634506226 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 64 | 0.6193695068359375 | 0.5821357369422913 | 0.656603217124939 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 65 | 0.6193705797195435 | 0.5821371078491211 | 0.6566040515899658 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 66 | 0.6193716526031494 | 0.5821384191513062 | 0.6566048264503479 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 67 | 0.6193724870681763 | 0.5821394920349121 | 0.6566054821014404 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 68 | 0.6193733215332031 | 0.5821405053138733 | 0.6566060781478882 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 69 | 0.6193740963935852 | 0.5821415185928345 | 0.6566066741943359 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 70 | 0.619374692440033 | 0.5821422338485718 | 0.6566071510314941 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 71 | 0.6193753480911255 | 0.5821430683135986 | 0.6566075086593628 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 72 | 0.6193757653236389 | 0.5821436643600464 | 0.6566078662872314 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 73 | 0.6193763017654419 | 0.5821442604064941 | 0.6566082239151001 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 74 | 0.6193766593933105 | 0.5821448564529419 | 0.656608521938324 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 75 | 0.6193770170211792 | 0.5821453332901001 | 0.6566087007522583 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 76 | 0.6193773746490479 | 0.5821457505226135 | 0.6566088795661926 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 77 | 0.619377613067627 | 0.5821461081504822 | 0.656609058380127 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 78 | 0.619377851486206 | 0.582146406173706 | 0.6566091775894165 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 79 | 0.6193780303001404 | 0.5821467638015747 | 0.656609296798706 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 80 | 0.6193782091140747 | 0.5821470618247986 | 0.6566093564033508 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 81 | 0.619378387928009 | 0.5821473598480225 | 0.6566095352172852 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 82 | 0.6193785667419434 | 0.5821475386619568 | 0.6566095352172852 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 83 | 0.6193786859512329 | 0.5821477174758911 | 0.6566095352172852 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 84 | 0.6193787455558777 | 0.5821479558944702 | 0.6566095352172852 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 85 | 0.6193788051605225 | 0.5821480751037598 | 0.6566095948219299 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 86 | 0.619378924369812 | 0.5821481943130493 | 0.6566096544265747 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 87 | 0.6193789839744568 | 0.5821483135223389 | 0.6566096544265747 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 88 | 0.6193790435791016 | 0.5821484327316284 | 0.6566095948219299 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 89 | 0.6193790435791016 | 0.582148551940918 | 0.6566096544265747 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 90 | 0.6193791627883911 | 0.5821486711502075 | 0.6566095352172852 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 91 | 0.6193791627883911 | 0.5821487903594971 | 0.6566095352172852 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 92 | 0.6193791627883911 | 0.5821488499641418 | 0.6566095352172852 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 93 | 0.6193791627883911 | 0.5821489095687866 | 0.6566094160079956 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 94 | 0.6193791627883911 | 0.5821489095687866 | 0.6566094160079956 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 95 | 0.6193791627883911 | 0.5821489691734314 | 0.656609296798706 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 96 | 0.6193791627883911 | 0.5821490287780762 | 0.656609296798706 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 97 | 0.6193791031837463 | 0.5821490287780762 | 0.6566091775894165 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 98 | 0.6193791031837463 | 0.5821490287780762 | 0.6566091775894165 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 99 | 0.6193790435791016 | 0.5821490287780762 | 0.656609058380127 | 0.6919642857142857 | 0.6860119047619048\n",
      "> 100 | 0.6193790435791016 | 0.582149088382721 | 0.6566089987754822 | 0.6919642857142857 | 0.6860119047619048\n",
      "> Evaluation\n",
      "> Class Acc = 0.7083333134651184\n",
      "> Adv Acc = 0.7083333134651184\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 1.0 | 1.0 | 1.0\n",
      "> Confusion Matrix \n",
      "TN: 0.0 | FP: 84.0 \n",
      "FN: 0.0 | TP: 204.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 0.0 | FP: 34.0 \n",
      "FN: 0.0 | TP: 55.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 0.0 | FP: 50.0 \n",
      "FN: 0.0 | TP: 149.0\n"
     ]
    }
   ],
   "source": [
    "fairdef = 'DemPar'\n",
    "\n",
    "for cv_seed in cv_seeds:\n",
    "    x_train, x_test, y_train, y_test, a_train, a_test = train_test_split(\n",
    "        x, y, a, test_size=0.3, random_state=cv_seed)\n",
    "\n",
    "    train_data = Dataset.from_tensor_slices((x_train, y_train, a_train))\n",
    "    train_data = train_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    test_data = Dataset.from_tensor_slices((x_test, y_test, a_test))\n",
    "    test_data = test_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    for FAIR_COEFF in FAIR_COEFFS:\n",
    "\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    \n",
    "        model = Beutel(xdim, ydim, adim, zdim, FAIR_COEFF, fairdef)\n",
    "\n",
    "        ret = beutel_train(model, raw_data, train_data, epochs, opt)\n",
    "\n",
    "        Y, A, Y_hat, A_hat = fair_evaluation(model, test_data)\n",
    "        clas_acc, dp, deqodds, deqopp, confusion_matrix, metrics_a0, metrics_a1 = compute_metrics(Y, A, Y_hat, A_hat, adim)\n",
    "\n",
    "        fair_metrics = (dp, deqodds, deqopp)\n",
    "        tradeoff = []\n",
    "        for fair_metric in fair_metrics:\n",
    "            tradeoff.append(compute_tradeoff(clas_acc, fair_metric))\n",
    "\n",
    "        result = ['BEUTEL4DP', cv_seed, FAIR_COEFF, clas_acc, dp, deqodds, deqopp, tradeoff[0], tradeoff[1], tradeoff[2]] + metrics_a0 + metrics_a1\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "        del(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BEUTEL for Eq Opp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fairdef = 'EqOpp'\n",
    "\n",
    "# for FAIR_COEFF in FAIR_COEFFS:\n",
    "#     for i in range(test_loop):\n",
    "\n",
    "#         opt = Adam(learning_rate=learning_rate)\n",
    "\n",
    "#         model = Beutel(xdim, ydim, adim, zdim, hidden_layer_specs, fairdef)\n",
    "\n",
    "#         ret = beutel_train(model, raw_data, train_data, epochs, opt)\n",
    "\n",
    "#         Y, A, Y_hat, A_hat = fair_evaluation(model, valid_data)\n",
    "#         clas_acc, dp, deqodds, deqopp, confusion_matrix, metrics_a0, metrics_a1 = compute_metrics(Y, A, Y_hat, A_hat, adim)\n",
    "\n",
    "#         fair_metrics = (dp, deqodds, deqopp)\n",
    "#         tradeoff = []\n",
    "#         for fair_metric in fair_metrics:\n",
    "#             tradeoff.append(compute_tradeoff(clas_acc, fair_metric))\n",
    "\n",
    "#         result = ['BEUTEL4EqOpp', FAIR_COEFF, clas_acc, dp, deqodds, deqopp, tradeoff[0], tradeoff[1], tradeoff[2]] + metrics_a0 + metrics_a1\n",
    "\n",
    "#         # results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving into DF then CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>cv_seed</th>\n",
       "      <th>fair_coeff</th>\n",
       "      <th>clas_acc</th>\n",
       "      <th>dp</th>\n",
       "      <th>deqodds</th>\n",
       "      <th>deqopp</th>\n",
       "      <th>trade_dp</th>\n",
       "      <th>trade_deqodds</th>\n",
       "      <th>trade_deqopp</th>\n",
       "      <th>TN_a0</th>\n",
       "      <th>FP_a0</th>\n",
       "      <th>FN_a0</th>\n",
       "      <th>TP_a0</th>\n",
       "      <th>TN_a1</th>\n",
       "      <th>FP_a1</th>\n",
       "      <th>FN_a1</th>\n",
       "      <th>TP_a1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BEUTEL4DP</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711806</td>\n",
       "      <td>0.999013</td>\n",
       "      <td>0.991106</td>\n",
       "      <td>0.996286</td>\n",
       "      <td>0.831301</td>\n",
       "      <td>0.828551</td>\n",
       "      <td>0.830356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BEUTEL4DP</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.673611</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>144.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BEUTEL4DP</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.701389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BEUTEL4DP</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.822086</td>\n",
       "      <td>0.822086</td>\n",
       "      <td>0.822086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BEUTEL4DP</td>\n",
       "      <td>73</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name  cv_seed  fair_coeff  clas_acc        dp   deqodds    deqopp  \\\n",
       "0  BEUTEL4DP       13         1.0  0.711806  0.999013  0.991106  0.996286   \n",
       "1  BEUTEL4DP       29         1.0  0.673611  1.000000  1.000000  1.000000   \n",
       "2  BEUTEL4DP       42         1.0  0.701389  1.000000  1.000000  1.000000   \n",
       "3  BEUTEL4DP       55         1.0  0.697917  1.000000  1.000000  1.000000   \n",
       "4  BEUTEL4DP       73         1.0  0.708333  1.000000  1.000000  1.000000   \n",
       "\n",
       "   trade_dp  trade_deqodds  trade_deqopp  TN_a0  FP_a0  FN_a0  TP_a0  TN_a1  \\\n",
       "0  0.831301       0.828551      0.830356    1.0   28.0    2.0   63.0    1.0   \n",
       "1  0.804979       0.804979      0.804979    0.0   38.0    0.0   50.0    0.0   \n",
       "2  0.824490       0.824490      0.824490    0.0   28.0    0.0   57.0    0.0   \n",
       "3  0.822086       0.822086      0.822086    0.0   29.0    0.0   62.0    0.0   \n",
       "4  0.829268       0.829268      0.829268    0.0   34.0    0.0   55.0    0.0   \n",
       "\n",
       "   FP_a1  FN_a1  TP_a1  \n",
       "0   48.0    5.0  140.0  \n",
       "1   56.0    0.0  144.0  \n",
       "2   58.0    0.0  145.0  \n",
       "3   58.0    0.0  139.0  \n",
       "4   50.0    0.0  149.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(results, columns=header)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f'{data_name}-result/beutel-{epochs}.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41359ec383f887151a607ad1e28cb7dbc05f61385692c63e2bb2f343bf03f280"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('falsb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
