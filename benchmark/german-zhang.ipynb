{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing file \n",
    "### where we evaluate Zhang's models using the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "\n",
    "from util.load_data import load_data\n",
    "from util.evaluation import *\n",
    "from models.zhang.models import FairLogisticRegression\n",
    "from models.zhang.learning import train_loop as zhang_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_seeds = [13, 29, 42, 55, 73]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'german'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, a = load_data(data_name)\n",
    "raw_data = (x, y, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = x.shape[1]\n",
    "ydim = y.shape[1]\n",
    "adim = a.shape[1]\n",
    "zdim = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"model_name\", \"cv_seed\", \"clas_acc\", \"dp\", \"deqodds\", \"deqopp\", \"trade_dp\", \"trade_deqodds\", \"trade_deqopp\", \"TN_a0\", \"FP_a0\", \"FN_a0\", \"TP_a0\", \"TN_a1\", \"FP_a1\", \"FN_a1\", \"TP_a1\"\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loop\n",
    "#### Each model is evalueted 5 times\n",
    "#### In the end of each iteration we save the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhang for DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.5918705463409424 | 1.0379714965820312 | 0.6734375 | 0.2984375\n",
      "> 2 | 0.5884881615638733 | 1.027639389038086 | 0.6734375 | 0.2984375\n",
      "> 3 | 0.5849838256835938 | 1.017638921737671 | 0.6734375 | 0.2984375\n",
      "> 4 | 0.5815937519073486 | 1.0079704523086548 | 0.6734375 | 0.2984375\n",
      "> 5 | 0.578369140625 | 0.998611330986023 | 0.6734375 | 0.2984375\n",
      "> 6 | 0.5752931237220764 | 0.9895269870758057 | 0.6734375 | 0.2984375\n",
      "> 7 | 0.5723352432250977 | 0.9806817770004272 | 0.6734375 | 0.2984375\n",
      "> 8 | 0.5694695711135864 | 0.9720444679260254 | 0.6734375 | 0.2984375\n",
      "> 9 | 0.5666785836219788 | 0.9635899662971497 | 0.6734375 | 0.2984375\n",
      "> 10 | 0.563951849937439 | 0.9552992582321167 | 0.6734375 | 0.2984375\n",
      "> 11 | 0.561284065246582 | 0.9471579790115356 | 0.6734375 | 0.2984375\n",
      "> 12 | 0.5586731433868408 | 0.9391556978225708 | 0.6734375 | 0.2984375\n",
      "> 13 | 0.5561193227767944 | 0.9312848448753357 | 0.6734375 | 0.2984375\n",
      "> 14 | 0.5536235570907593 | 0.9235402941703796 | 0.6734375 | 0.2984375\n",
      "> 15 | 0.5511870980262756 | 0.9159184694290161 | 0.6734375 | 0.2984375\n",
      "> 16 | 0.5488111972808838 | 0.9084171056747437 | 0.6734375 | 0.2984375\n",
      "> 17 | 0.5464968681335449 | 0.9010347723960876 | 0.675 | 0.2984375\n",
      "> 18 | 0.5442447066307068 | 0.8937704563140869 | 0.675 | 0.2984375\n",
      "> 19 | 0.5420548915863037 | 0.886623740196228 | 0.6765625 | 0.2984375\n",
      "> 20 | 0.539927065372467 | 0.8795943260192871 | 0.68125 | 0.2984375\n",
      "> 21 | 0.537860631942749 | 0.8726819157600403 | 0.6875 | 0.2984375\n",
      "> 22 | 0.5358548164367676 | 0.8658864498138428 | 0.6921875 | 0.2984375\n",
      "> 23 | 0.5339083671569824 | 0.8592076897621155 | 0.6953125 | 0.2984375\n",
      "> 24 | 0.532019853591919 | 0.8526453375816345 | 0.7 | 0.2984375\n",
      "> 25 | 0.530187726020813 | 0.8461990356445312 | 0.7046875 | 0.2984375\n",
      "> 26 | 0.5284105539321899 | 0.8398683071136475 | 0.703125 | 0.2984375\n",
      "> 27 | 0.5266864895820618 | 0.8336524963378906 | 0.7 | 0.2984375\n",
      "> 28 | 0.52501380443573 | 0.8275509476661682 | 0.6984375 | 0.2984375\n",
      "> 29 | 0.5233907699584961 | 0.8215627670288086 | 0.7 | 0.2984375\n",
      "> 30 | 0.5218156576156616 | 0.8156870007514954 | 0.7015625 | 0.2984375\n",
      "> 31 | 0.5202866792678833 | 0.8099225759506226 | 0.703125 | 0.2984375\n",
      "> 32 | 0.5188022255897522 | 0.804268479347229 | 0.70625 | 0.2984375\n",
      "> 33 | 0.5173605680465698 | 0.7987232208251953 | 0.7109375 | 0.2984375\n",
      "> 34 | 0.5159600377082825 | 0.7932856678962708 | 0.7125 | 0.2984375\n",
      "> 35 | 0.5145992040634155 | 0.7879544496536255 | 0.7171875 | 0.2984375\n",
      "> 36 | 0.5132764577865601 | 0.7827280759811401 | 0.721875 | 0.2984375\n",
      "> 37 | 0.5119904279708862 | 0.7776050567626953 | 0.721875 | 0.2984375\n",
      "> 38 | 0.5107396245002747 | 0.7725837230682373 | 0.725 | 0.2984375\n",
      "> 39 | 0.5095227956771851 | 0.767662763595581 | 0.7296875 | 0.3\n",
      "> 40 | 0.5083386301994324 | 0.7628403902053833 | 0.7296875 | 0.3\n",
      "> 41 | 0.5071858763694763 | 0.7581150531768799 | 0.7328125 | 0.3\n",
      "> 42 | 0.5060633420944214 | 0.7534850239753723 | 0.73125 | 0.3015625\n",
      "> 43 | 0.5049700140953064 | 0.7489487528800964 | 0.7359375 | 0.3015625\n",
      "> 44 | 0.5039047002792358 | 0.7445045709609985 | 0.7375 | 0.3046875\n",
      "> 45 | 0.5028664469718933 | 0.7401506900787354 | 0.740625 | 0.3046875\n",
      "> 46 | 0.5018543004989624 | 0.7358854413032532 | 0.7421875 | 0.31875\n",
      "> 47 | 0.5008671879768372 | 0.7317073345184326 | 0.7421875 | 0.3203125\n",
      "> 48 | 0.4999043941497803 | 0.7276145219802856 | 0.7421875 | 0.3296875\n",
      "> 49 | 0.49896493554115295 | 0.7236054539680481 | 0.7421875 | 0.3421875\n",
      "> 50 | 0.4980480670928955 | 0.7196784019470215 | 0.740625 | 0.35\n",
      "> 51 | 0.49715298414230347 | 0.7158318758010864 | 0.74375 | 0.3578125\n",
      "> 52 | 0.4962790310382843 | 0.7120641469955444 | 0.7453125 | 0.365625\n",
      "> 53 | 0.49542540311813354 | 0.7083736658096313 | 0.7484375 | 0.3765625\n",
      "> 54 | 0.4945914149284363 | 0.704758882522583 | 0.7484375 | 0.3921875\n",
      "> 55 | 0.4937765300273895 | 0.7012181282043457 | 0.7484375 | 0.421875\n",
      "> 56 | 0.4929800033569336 | 0.6977499723434448 | 0.7484375 | 0.4375\n",
      "> 57 | 0.4922012984752655 | 0.6943528652191162 | 0.7484375 | 0.44375\n",
      "> 58 | 0.4914398789405823 | 0.6910253763198853 | 0.75 | 0.4734375\n",
      "> 59 | 0.49069517850875854 | 0.687765896320343 | 0.7515625 | 0.4875\n",
      "> 60 | 0.4899666905403137 | 0.6845730543136597 | 0.7484375 | 0.5140625\n",
      "> 61 | 0.4892539381980896 | 0.6814454197883606 | 0.7484375 | 0.5171875\n",
      "> 62 | 0.4885563552379608 | 0.6783815622329712 | 0.7484375 | 0.5265625\n",
      "> 63 | 0.48787355422973633 | 0.6753802299499512 | 0.746875 | 0.528125\n",
      "> 64 | 0.4872050881385803 | 0.6724399328231812 | 0.7453125 | 0.5390625\n",
      "> 65 | 0.48655056953430176 | 0.6695594191551208 | 0.7453125 | 0.5484375\n",
      "> 66 | 0.4859095513820648 | 0.6667373180389404 | 0.7453125 | 0.5578125\n",
      "> 67 | 0.48528164625167847 | 0.6639724969863892 | 0.7453125 | 0.5640625\n",
      "> 68 | 0.48466652631759644 | 0.6612635254859924 | 0.7453125 | 0.5625\n",
      "> 69 | 0.4840637445449829 | 0.6586092710494995 | 0.7453125 | 0.571875\n",
      "> 70 | 0.4834730327129364 | 0.6560085415840149 | 0.7484375 | 0.5734375\n",
      "> 71 | 0.48289406299591064 | 0.6534601449966431 | 0.75 | 0.584375\n",
      "> 72 | 0.4823265075683594 | 0.6509628295898438 | 0.75 | 0.5953125\n",
      "> 73 | 0.48177003860473633 | 0.6485155820846558 | 0.7515625 | 0.6046875\n",
      "> 74 | 0.48122429847717285 | 0.6461172103881836 | 0.75 | 0.6140625\n",
      "> 75 | 0.4806891083717346 | 0.6437667608261108 | 0.75 | 0.6140625\n",
      "> 76 | 0.48016417026519775 | 0.641463041305542 | 0.7515625 | 0.6234375\n",
      "> 77 | 0.47964921593666077 | 0.6392051577568054 | 0.7515625 | 0.6296875\n",
      "> 78 | 0.4791439473628998 | 0.6369919776916504 | 0.7515625 | 0.634375\n",
      "> 79 | 0.47864818572998047 | 0.6348224878311157 | 0.7484375 | 0.6375\n",
      "> 80 | 0.47816163301467896 | 0.6326957941055298 | 0.7484375 | 0.6453125\n",
      "> 81 | 0.4776840806007385 | 0.6306108832359314 | 0.746875 | 0.6453125\n",
      "> 82 | 0.4772152602672577 | 0.6285669207572937 | 0.746875 | 0.65625\n",
      "> 83 | 0.4767550528049469 | 0.6265628337860107 | 0.746875 | 0.6546875\n",
      "> 84 | 0.47630318999290466 | 0.6245979070663452 | 0.7484375 | 0.65625\n",
      "> 85 | 0.4758594334125519 | 0.6226712465286255 | 0.7484375 | 0.659375\n",
      "> 86 | 0.4754236340522766 | 0.6207818388938904 | 0.746875 | 0.6625\n",
      "> 87 | 0.47499561309814453 | 0.6189290881156921 | 0.746875 | 0.6734375\n",
      "> 88 | 0.4745751619338989 | 0.6171120405197144 | 0.746875 | 0.678125\n",
      "> 89 | 0.47416213154792786 | 0.6153299808502197 | 0.746875 | 0.675\n",
      "> 90 | 0.4737563133239746 | 0.6135820150375366 | 0.746875 | 0.678125\n",
      "> 91 | 0.47335755825042725 | 0.6118676066398621 | 0.7453125 | 0.678125\n",
      "> 92 | 0.47296571731567383 | 0.6101858019828796 | 0.74375 | 0.678125\n",
      "> 93 | 0.47258061170578003 | 0.6085360050201416 | 0.7421875 | 0.6828125\n",
      "> 94 | 0.4722020626068115 | 0.6069173812866211 | 0.7421875 | 0.684375\n",
      "> 95 | 0.47182992100715637 | 0.6053293943405151 | 0.7390625 | 0.6796875\n",
      "> 96 | 0.4714641571044922 | 0.6037713289260864 | 0.7390625 | 0.6796875\n",
      "> 97 | 0.4711045026779175 | 0.6022425293922424 | 0.7390625 | 0.6796875\n",
      "> 98 | 0.4707508683204651 | 0.6007423996925354 | 0.7375 | 0.6796875\n",
      "> 99 | 0.4704030752182007 | 0.5992701649665833 | 0.7359375 | 0.68125\n",
      "> 100 | 0.47006112337112427 | 0.5978253483772278 | 0.7359375 | 0.6828125\n",
      "> Evaluation\n",
      "> Class Acc = 0.71875\n",
      "> Adv Acc = 0.71875\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.7812846302986145 | 0.7250852659344673 | 0.8952254801988602\n",
      "> Confusion Matrix \n",
      "TN: 31.0 | FP: 37.0 \n",
      "FN: 35.0 | TP: 153.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 19.0 | FP: 7.0 \n",
      "FN: 15.0 | TP: 43.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 12.0 | FP: 30.0 \n",
      "FN: 20.0 | TP: 110.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.652691662311554 | 1.0383983850479126 | 0.7078125 | 0.3109375\n",
      "> 2 | 0.6476470232009888 | 1.028359055519104 | 0.7078125 | 0.3109375\n",
      "> 3 | 0.6425511240959167 | 1.01858389377594 | 0.7078125 | 0.3109375\n",
      "> 4 | 0.6377372741699219 | 1.009074091911316 | 0.7078125 | 0.3109375\n",
      "> 5 | 0.633297324180603 | 0.9998105764389038 | 0.7078125 | 0.3109375\n",
      "> 6 | 0.629223108291626 | 0.9907667636871338 | 0.7078125 | 0.3109375\n",
      "> 7 | 0.6254774332046509 | 0.9819172620773315 | 0.7078125 | 0.3109375\n",
      "> 8 | 0.6220200061798096 | 0.9732416868209839 | 0.7078125 | 0.3109375\n",
      "> 9 | 0.6188154220581055 | 0.9647254943847656 | 0.7078125 | 0.3109375\n",
      "> 10 | 0.61583411693573 | 0.9563589096069336 | 0.7078125 | 0.3109375\n",
      "> 11 | 0.6130517721176147 | 0.9481353759765625 | 0.7078125 | 0.3109375\n",
      "> 12 | 0.6104481220245361 | 0.9400505423545837 | 0.7078125 | 0.3109375\n",
      "> 13 | 0.6080061197280884 | 0.9321017861366272 | 0.7078125 | 0.3109375\n",
      "> 14 | 0.6057116985321045 | 0.9242873191833496 | 0.7078125 | 0.3109375\n",
      "> 15 | 0.6035523414611816 | 0.9166058301925659 | 0.7078125 | 0.3109375\n",
      "> 16 | 0.6015173196792603 | 0.909056544303894 | 0.7078125 | 0.3109375\n",
      "> 17 | 0.599597156047821 | 0.9016386866569519 | 0.7078125 | 0.3109375\n",
      "> 18 | 0.5977834463119507 | 0.8943515419960022 | 0.7078125 | 0.3109375\n",
      "> 19 | 0.5960686206817627 | 0.8871945738792419 | 0.7078125 | 0.3109375\n",
      "> 20 | 0.5944458246231079 | 0.8801668286323547 | 0.7078125 | 0.3109375\n",
      "> 21 | 0.5929088592529297 | 0.8732675313949585 | 0.7078125 | 0.3109375\n",
      "> 22 | 0.5914520025253296 | 0.8664957284927368 | 0.7078125 | 0.3109375\n",
      "> 23 | 0.5900701284408569 | 0.8598503470420837 | 0.7078125 | 0.3109375\n",
      "> 24 | 0.5887584090232849 | 0.853330135345459 | 0.709375 | 0.3109375\n",
      "> 25 | 0.5875123739242554 | 0.8469340801239014 | 0.7078125 | 0.3109375\n",
      "> 26 | 0.5863280296325684 | 0.8406606316566467 | 0.7109375 | 0.3109375\n",
      "> 27 | 0.5852015614509583 | 0.8345084190368652 | 0.7109375 | 0.3109375\n",
      "> 28 | 0.5841293931007385 | 0.828475832939148 | 0.7125 | 0.3109375\n",
      "> 29 | 0.5831083059310913 | 0.822561502456665 | 0.7125 | 0.3109375\n",
      "> 30 | 0.5821353197097778 | 0.8167636394500732 | 0.7125 | 0.3109375\n",
      "> 31 | 0.5812075138092041 | 0.8110806941986084 | 0.7125 | 0.3109375\n",
      "> 32 | 0.580322265625 | 0.8055108189582825 | 0.7140625 | 0.3109375\n",
      "> 33 | 0.5794771909713745 | 0.8000523447990417 | 0.7171875 | 0.3109375\n",
      "> 34 | 0.5786699056625366 | 0.7947034239768982 | 0.7203125 | 0.3109375\n",
      "> 35 | 0.5778983235359192 | 0.7894623875617981 | 0.721875 | 0.3109375\n",
      "> 36 | 0.5771603584289551 | 0.7843272686004639 | 0.7234375 | 0.3109375\n",
      "> 37 | 0.576454222202301 | 0.7792962789535522 | 0.721875 | 0.3109375\n",
      "> 38 | 0.5757781267166138 | 0.7743676900863647 | 0.721875 | 0.3109375\n",
      "> 39 | 0.57513028383255 | 0.7695394158363342 | 0.7203125 | 0.3109375\n",
      "> 40 | 0.5745094418525696 | 0.7648098468780518 | 0.7203125 | 0.3109375\n",
      "> 41 | 0.5739138722419739 | 0.7601770758628845 | 0.7234375 | 0.3109375\n",
      "> 42 | 0.5733424425125122 | 0.7556391954421997 | 0.7234375 | 0.315625\n",
      "> 43 | 0.57279372215271 | 0.7511943578720093 | 0.7234375 | 0.3203125\n",
      "> 44 | 0.5722664594650269 | 0.7468408942222595 | 0.721875 | 0.328125\n",
      "> 45 | 0.5717597603797913 | 0.7425769567489624 | 0.7203125 | 0.3390625\n",
      "> 46 | 0.5712723731994629 | 0.7384006977081299 | 0.721875 | 0.3421875\n",
      "> 47 | 0.5708034038543701 | 0.7343103885650635 | 0.721875 | 0.3484375\n",
      "> 48 | 0.5703518390655518 | 0.7303042411804199 | 0.7234375 | 0.35\n",
      "> 49 | 0.569916844367981 | 0.7263806462287903 | 0.725 | 0.35625\n",
      "> 50 | 0.5694975852966309 | 0.7225377559661865 | 0.721875 | 0.365625\n",
      "> 51 | 0.5690932273864746 | 0.7187738418579102 | 0.7234375 | 0.378125\n",
      "> 52 | 0.5687031745910645 | 0.7150875329971313 | 0.7265625 | 0.390625\n",
      "> 53 | 0.5683265924453735 | 0.7114768624305725 | 0.73125 | 0.4078125\n",
      "> 54 | 0.5679628849029541 | 0.707940399646759 | 0.73125 | 0.421875\n",
      "> 55 | 0.5676113367080688 | 0.7044764757156372 | 0.7328125 | 0.4265625\n",
      "> 56 | 0.5672714114189148 | 0.7010835409164429 | 0.7359375 | 0.4453125\n",
      "> 57 | 0.5669426321983337 | 0.6977601051330566 | 0.7359375 | 0.4546875\n",
      "> 58 | 0.5666243433952332 | 0.6945046186447144 | 0.7390625 | 0.465625\n",
      "> 59 | 0.5663161277770996 | 0.6913154721260071 | 0.7390625 | 0.4734375\n",
      "> 60 | 0.5660175085067749 | 0.6881914138793945 | 0.7390625 | 0.478125\n",
      "> 61 | 0.5657280087471008 | 0.6851310729980469 | 0.7390625 | 0.4828125\n",
      "> 62 | 0.565447211265564 | 0.6821327209472656 | 0.7390625 | 0.4875\n",
      "> 63 | 0.5651747584342957 | 0.6791953444480896 | 0.7390625 | 0.49375\n",
      "> 64 | 0.5649102330207825 | 0.6763173341751099 | 0.740625 | 0.5078125\n",
      "> 65 | 0.5646532773971558 | 0.6734974980354309 | 0.7421875 | 0.51875\n",
      "> 66 | 0.5644035339355469 | 0.6707345247268677 | 0.7421875 | 0.53125\n",
      "> 67 | 0.5641607046127319 | 0.6680271625518799 | 0.7421875 | 0.546875\n",
      "> 68 | 0.5639244318008423 | 0.6653739213943481 | 0.7421875 | 0.553125\n",
      "> 69 | 0.5636944770812988 | 0.6627740263938904 | 0.74375 | 0.5671875\n",
      "> 70 | 0.5634705424308777 | 0.6602259278297424 | 0.74375 | 0.58125\n",
      "> 71 | 0.563252329826355 | 0.6577286124229431 | 0.746875 | 0.5890625\n",
      "> 72 | 0.5630396604537964 | 0.6552809476852417 | 0.7484375 | 0.5953125\n",
      "> 73 | 0.562832236289978 | 0.6528817415237427 | 0.75 | 0.6125\n",
      "> 74 | 0.5626298189163208 | 0.6505299806594849 | 0.75 | 0.609375\n",
      "> 75 | 0.5624322295188904 | 0.6482244729995728 | 0.75 | 0.61875\n",
      "> 76 | 0.5622391700744629 | 0.6459643840789795 | 0.75 | 0.621875\n",
      "> 77 | 0.5620506405830383 | 0.6437485218048096 | 0.7515625 | 0.628125\n",
      "> 78 | 0.561866283416748 | 0.6415759325027466 | 0.7515625 | 0.6328125\n",
      "> 79 | 0.5616859197616577 | 0.6394456624984741 | 0.753125 | 0.6359375\n",
      "> 80 | 0.561509370803833 | 0.6373567581176758 | 0.753125 | 0.640625\n",
      "> 81 | 0.5613366365432739 | 0.6353083252906799 | 0.7546875 | 0.64375\n",
      "> 82 | 0.5611673593521118 | 0.6332993507385254 | 0.7546875 | 0.646875\n",
      "> 83 | 0.5610015392303467 | 0.6313290596008301 | 0.7546875 | 0.6453125\n",
      "> 84 | 0.5608389377593994 | 0.6293964385986328 | 0.753125 | 0.653125\n",
      "> 85 | 0.5606794953346252 | 0.6275007724761963 | 0.753125 | 0.6546875\n",
      "> 86 | 0.5605230331420898 | 0.6256413459777832 | 0.753125 | 0.653125\n",
      "> 87 | 0.5603694319725037 | 0.6238170266151428 | 0.7515625 | 0.6578125\n",
      "> 88 | 0.5602185130119324 | 0.6220272779464722 | 0.75 | 0.6640625\n",
      "> 89 | 0.560070276260376 | 0.6202712059020996 | 0.75 | 0.6625\n",
      "> 90 | 0.5599246621131897 | 0.6185482144355774 | 0.7484375 | 0.665625\n",
      "> 91 | 0.5597813129425049 | 0.6168574094772339 | 0.746875 | 0.6671875\n",
      "> 92 | 0.5596404075622559 | 0.6151981353759766 | 0.746875 | 0.6671875\n",
      "> 93 | 0.5595016479492188 | 0.6135697364807129 | 0.746875 | 0.671875\n",
      "> 94 | 0.5593650937080383 | 0.6119714975357056 | 0.7484375 | 0.675\n",
      "> 95 | 0.5592305660247803 | 0.6104025840759277 | 0.75 | 0.671875\n",
      "> 96 | 0.5590981245040894 | 0.6088626384735107 | 0.75 | 0.6765625\n",
      "> 97 | 0.5589674711227417 | 0.6073509454727173 | 0.7484375 | 0.6765625\n",
      "> 98 | 0.5588387250900269 | 0.6058667302131653 | 0.75 | 0.6828125\n",
      "> 99 | 0.5587116479873657 | 0.6044095754623413 | 0.75 | 0.684375\n",
      "> 100 | 0.5585863590240479 | 0.6029787659645081 | 0.75 | 0.6875\n",
      "> Evaluation\n",
      "> Class Acc = 0.71484375\n",
      "> Adv Acc = 0.71484375\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8867195844650269 | 0.9224127419292927 | 0.9477666988968849\n",
      "> Confusion Matrix \n",
      "TN: 31.0 | FP: 56.0 \n",
      "FN: 17.0 | TP: 152.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 15.0 | FP: 21.0 \n",
      "FN: 6.0 | TP: 37.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 16.0 | FP: 35.0 \n",
      "FN: 11.0 | TP: 115.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6222296953201294 | 0.9155155420303345 | 0.7078125 | 0.309375\n",
      "> 2 | 0.6177249550819397 | 0.9079821109771729 | 0.7078125 | 0.309375\n",
      "> 3 | 0.6130226850509644 | 0.9007301330566406 | 0.7078125 | 0.309375\n",
      "> 4 | 0.6084326505661011 | 0.8937339186668396 | 0.7078125 | 0.309375\n",
      "> 5 | 0.604059100151062 | 0.8869693875312805 | 0.7078125 | 0.309375\n",
      "> 6 | 0.5999189615249634 | 0.8804136514663696 | 0.7078125 | 0.309375\n",
      "> 7 | 0.596000075340271 | 0.8740462064743042 | 0.7078125 | 0.309375\n",
      "> 8 | 0.5922835469245911 | 0.8678504228591919 | 0.7078125 | 0.309375\n",
      "> 9 | 0.5887510180473328 | 0.8618131279945374 | 0.7078125 | 0.309375\n",
      "> 10 | 0.5853862166404724 | 0.8559248447418213 | 0.7078125 | 0.309375\n",
      "> 11 | 0.5821753144264221 | 0.8501780033111572 | 0.7078125 | 0.309375\n",
      "> 12 | 0.5791064500808716 | 0.8445666432380676 | 0.7078125 | 0.309375\n",
      "> 13 | 0.576169490814209 | 0.8390862941741943 | 0.7078125 | 0.309375\n",
      "> 14 | 0.5733555555343628 | 0.833733320236206 | 0.7078125 | 0.309375\n",
      "> 15 | 0.5706566572189331 | 0.8285044431686401 | 0.7078125 | 0.309375\n",
      "> 16 | 0.568065881729126 | 0.8233970999717712 | 0.7078125 | 0.309375\n",
      "> 17 | 0.56557697057724 | 0.8184089660644531 | 0.7078125 | 0.309375\n",
      "> 18 | 0.5631841421127319 | 0.8135377764701843 | 0.7078125 | 0.309375\n",
      "> 19 | 0.5608820915222168 | 0.808781623840332 | 0.7078125 | 0.309375\n",
      "> 20 | 0.5586661696434021 | 0.8041387796401978 | 0.7109375 | 0.309375\n",
      "> 21 | 0.5565317869186401 | 0.7996072173118591 | 0.709375 | 0.309375\n",
      "> 22 | 0.5544748306274414 | 0.7951853275299072 | 0.709375 | 0.309375\n",
      "> 23 | 0.5524915456771851 | 0.7908713817596436 | 0.709375 | 0.309375\n",
      "> 24 | 0.5505781769752502 | 0.7866636514663696 | 0.7125 | 0.309375\n",
      "> 25 | 0.5487313866615295 | 0.7825603485107422 | 0.7125 | 0.309375\n",
      "> 26 | 0.5469481348991394 | 0.7785598635673523 | 0.7140625 | 0.309375\n",
      "> 27 | 0.5452253222465515 | 0.7746604681015015 | 0.715625 | 0.309375\n",
      "> 28 | 0.5435601472854614 | 0.7708603739738464 | 0.7140625 | 0.309375\n",
      "> 29 | 0.5419501066207886 | 0.7671579122543335 | 0.7140625 | 0.309375\n",
      "> 30 | 0.5403924584388733 | 0.7635512948036194 | 0.715625 | 0.309375\n",
      "> 31 | 0.5388851165771484 | 0.7600387334823608 | 0.7171875 | 0.309375\n",
      "> 32 | 0.5374257564544678 | 0.7566185593605042 | 0.7171875 | 0.309375\n",
      "> 33 | 0.5360122323036194 | 0.7532888650894165 | 0.721875 | 0.309375\n",
      "> 34 | 0.5346425771713257 | 0.7500479817390442 | 0.721875 | 0.309375\n",
      "> 35 | 0.5333149433135986 | 0.7468940615653992 | 0.7234375 | 0.309375\n",
      "> 36 | 0.5320274829864502 | 0.7438253164291382 | 0.728125 | 0.309375\n",
      "> 37 | 0.5307785272598267 | 0.7408400774002075 | 0.734375 | 0.309375\n",
      "> 38 | 0.5295664668083191 | 0.7379363775253296 | 0.7359375 | 0.309375\n",
      "> 39 | 0.5283897519111633 | 0.7351125478744507 | 0.7265625 | 0.309375\n",
      "> 40 | 0.5272469520568848 | 0.7323669195175171 | 0.728125 | 0.309375\n",
      "> 41 | 0.5261366963386536 | 0.729697585105896 | 0.725 | 0.309375\n",
      "> 42 | 0.5250576734542847 | 0.7271029353141785 | 0.725 | 0.309375\n",
      "> 43 | 0.5240086317062378 | 0.7245811820030212 | 0.7265625 | 0.309375\n",
      "> 44 | 0.5229884386062622 | 0.7221306562423706 | 0.7265625 | 0.309375\n",
      "> 45 | 0.5219957828521729 | 0.7197497487068176 | 0.7296875 | 0.315625\n",
      "> 46 | 0.5210297703742981 | 0.717436671257019 | 0.73125 | 0.328125\n",
      "> 47 | 0.520089328289032 | 0.7151899337768555 | 0.734375 | 0.33125\n",
      "> 48 | 0.5191735029220581 | 0.7130079865455627 | 0.7359375 | 0.3421875\n",
      "> 49 | 0.5182812809944153 | 0.7108891010284424 | 0.7359375 | 0.3515625\n",
      "> 50 | 0.5174118280410767 | 0.708831787109375 | 0.7375 | 0.3609375\n",
      "> 51 | 0.5165643692016602 | 0.7068344950675964 | 0.7390625 | 0.3703125\n",
      "> 52 | 0.5157379508018494 | 0.7048958539962769 | 0.7375 | 0.3796875\n",
      "> 53 | 0.5149319171905518 | 0.7030142545700073 | 0.734375 | 0.3859375\n",
      "> 54 | 0.5141454339027405 | 0.701188325881958 | 0.734375 | 0.4046875\n",
      "> 55 | 0.5133779048919678 | 0.6994166970252991 | 0.734375 | 0.428125\n",
      "> 56 | 0.5126286149024963 | 0.6976979970932007 | 0.734375 | 0.4546875\n",
      "> 57 | 0.5118968486785889 | 0.6960307359695435 | 0.734375 | 0.46875\n",
      "> 58 | 0.5111821293830872 | 0.6944137811660767 | 0.734375 | 0.475\n",
      "> 59 | 0.5104838013648987 | 0.6928457021713257 | 0.734375 | 0.484375\n",
      "> 60 | 0.5098012685775757 | 0.6913253664970398 | 0.734375 | 0.50625\n",
      "> 61 | 0.5091339349746704 | 0.6898514032363892 | 0.7359375 | 0.528125\n",
      "> 62 | 0.508481502532959 | 0.688422679901123 | 0.740625 | 0.5484375\n",
      "> 63 | 0.5078432559967041 | 0.687038004398346 | 0.7421875 | 0.565625\n",
      "> 64 | 0.5072188377380371 | 0.6856961250305176 | 0.74375 | 0.5875\n",
      "> 65 | 0.506607711315155 | 0.6843961477279663 | 0.7453125 | 0.5921875\n",
      "> 66 | 0.5060095191001892 | 0.6831367015838623 | 0.7453125 | 0.5984375\n",
      "> 67 | 0.5054237842559814 | 0.6819168329238892 | 0.746875 | 0.60625\n",
      "> 68 | 0.5048501491546631 | 0.6807354688644409 | 0.74375 | 0.6171875\n",
      "> 69 | 0.5042881965637207 | 0.679591715335846 | 0.7421875 | 0.61875\n",
      "> 70 | 0.5037376284599304 | 0.678484320640564 | 0.7421875 | 0.634375\n",
      "> 71 | 0.503197968006134 | 0.6774125099182129 | 0.7421875 | 0.6359375\n",
      "> 72 | 0.5026689767837524 | 0.6763752698898315 | 0.74375 | 0.6453125\n",
      "> 73 | 0.5021501779556274 | 0.675371527671814 | 0.7421875 | 0.659375\n",
      "> 74 | 0.5016415119171143 | 0.6744004487991333 | 0.7421875 | 0.6625\n",
      "> 75 | 0.5011423826217651 | 0.6734613180160522 | 0.74375 | 0.665625\n",
      "> 76 | 0.5006526708602905 | 0.6725529432296753 | 0.7453125 | 0.6671875\n",
      "> 77 | 0.5001721382141113 | 0.6716747283935547 | 0.7453125 | 0.6765625\n",
      "> 78 | 0.4997003674507141 | 0.6708258390426636 | 0.75 | 0.6765625\n",
      "> 79 | 0.49923717975616455 | 0.670005202293396 | 0.7484375 | 0.6765625\n",
      "> 80 | 0.49878236651420593 | 0.6692123413085938 | 0.75 | 0.6765625\n",
      "> 81 | 0.4983355700969696 | 0.6684463024139404 | 0.75 | 0.678125\n",
      "> 82 | 0.497896671295166 | 0.6677063703536987 | 0.75 | 0.68125\n",
      "> 83 | 0.4974653720855713 | 0.6669918298721313 | 0.75 | 0.690625\n",
      "> 84 | 0.4970414638519287 | 0.6663018465042114 | 0.75 | 0.6921875\n",
      "> 85 | 0.49662476778030396 | 0.6656359434127808 | 0.75 | 0.69375\n",
      "> 86 | 0.4962151050567627 | 0.664993166923523 | 0.75 | 0.6921875\n",
      "> 87 | 0.49581223726272583 | 0.6643730998039246 | 0.75 | 0.6953125\n",
      "> 88 | 0.49541595578193665 | 0.6637749075889587 | 0.75 | 0.7\n",
      "> 89 | 0.4950261116027832 | 0.6631980538368225 | 0.7515625 | 0.7015625\n",
      "> 90 | 0.49464258551597595 | 0.6626418828964233 | 0.7515625 | 0.7046875\n",
      "> 91 | 0.494265079498291 | 0.6621057987213135 | 0.7515625 | 0.7046875\n",
      "> 92 | 0.4938935935497284 | 0.6615892052650452 | 0.7515625 | 0.7015625\n",
      "> 93 | 0.4935278594493866 | 0.6610915660858154 | 0.7515625 | 0.7\n",
      "> 94 | 0.4931677579879761 | 0.6606122255325317 | 0.753125 | 0.7015625\n",
      "> 95 | 0.4928131401538849 | 0.6601507663726807 | 0.7546875 | 0.7015625\n",
      "> 96 | 0.4924638569355011 | 0.6597064733505249 | 0.7546875 | 0.7\n",
      "> 97 | 0.49211975932121277 | 0.6592789888381958 | 0.7546875 | 0.7\n",
      "> 98 | 0.4917807877063751 | 0.6588678359985352 | 0.75625 | 0.7\n",
      "> 99 | 0.49144673347473145 | 0.6584724187850952 | 0.75625 | 0.7046875\n",
      "> 100 | 0.49111756682395935 | 0.6580922603607178 | 0.75625 | 0.70625\n",
      "> Evaluation\n",
      "> Class Acc = 0.71484375\n",
      "> Adv Acc = 0.71484375\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8611524105072021 | 0.8208042047917843 | 0.9230769202113152\n",
      "> Confusion Matrix \n",
      "TN: 19.0 | FP: 55.0 \n",
      "FN: 18.0 | TP: 164.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 10.0 | FP: 12.0 \n",
      "FN: 8.0 | TP: 44.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 9.0 | FP: 43.0 \n",
      "FN: 10.0 | TP: 120.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.5169619917869568 | 0.9467998743057251 | 0.6984375 | 0.3046875\n",
      "> 2 | 0.5162380933761597 | 0.9387199878692627 | 0.6984375 | 0.3046875\n",
      "> 3 | 0.5150118470191956 | 0.9308907985687256 | 0.6984375 | 0.3046875\n",
      "> 4 | 0.5135465264320374 | 0.9233055710792542 | 0.6984375 | 0.3046875\n",
      "> 5 | 0.5119518637657166 | 0.9159456491470337 | 0.6984375 | 0.3046875\n",
      "> 6 | 0.5102777481079102 | 0.9087893962860107 | 0.6984375 | 0.3046875\n",
      "> 7 | 0.508552610874176 | 0.9018164277076721 | 0.6984375 | 0.3046875\n",
      "> 8 | 0.506797194480896 | 0.8950097560882568 | 0.6984375 | 0.3046875\n",
      "> 9 | 0.5050278902053833 | 0.8883566856384277 | 0.6984375 | 0.3046875\n",
      "> 10 | 0.5032585859298706 | 0.8818477392196655 | 0.6984375 | 0.3046875\n",
      "> 11 | 0.5015006065368652 | 0.8754758834838867 | 0.6984375 | 0.3046875\n",
      "> 12 | 0.4997633397579193 | 0.869236171245575 | 0.6984375 | 0.3046875\n",
      "> 13 | 0.49805423617362976 | 0.8631244897842407 | 0.6984375 | 0.3046875\n",
      "> 14 | 0.4963790774345398 | 0.8571380376815796 | 0.6984375 | 0.3046875\n",
      "> 15 | 0.49474239349365234 | 0.8512742519378662 | 0.6984375 | 0.3046875\n",
      "> 16 | 0.4931472837924957 | 0.8455312252044678 | 0.6984375 | 0.3046875\n",
      "> 17 | 0.4915960729122162 | 0.8399072289466858 | 0.6984375 | 0.3046875\n",
      "> 18 | 0.4900902211666107 | 0.8344006538391113 | 0.6984375 | 0.3046875\n",
      "> 19 | 0.4886305034160614 | 0.8290099501609802 | 0.6984375 | 0.3046875\n",
      "> 20 | 0.4872171878814697 | 0.8237336874008179 | 0.7015625 | 0.3046875\n",
      "> 21 | 0.4858500063419342 | 0.818570613861084 | 0.7046875 | 0.3046875\n",
      "> 22 | 0.4845285713672638 | 0.8135188817977905 | 0.70625 | 0.3046875\n",
      "> 23 | 0.48325204849243164 | 0.8085771203041077 | 0.7046875 | 0.3046875\n",
      "> 24 | 0.4820193648338318 | 0.8037438988685608 | 0.70625 | 0.3046875\n",
      "> 25 | 0.480829656124115 | 0.7990173697471619 | 0.7078125 | 0.3046875\n",
      "> 26 | 0.47968149185180664 | 0.7943960428237915 | 0.7109375 | 0.3046875\n",
      "> 27 | 0.4785737097263336 | 0.789878249168396 | 0.7125 | 0.3046875\n",
      "> 28 | 0.4775049388408661 | 0.7854622006416321 | 0.715625 | 0.3046875\n",
      "> 29 | 0.476473867893219 | 0.7811461687088013 | 0.71875 | 0.3046875\n",
      "> 30 | 0.4754790663719177 | 0.7769284248352051 | 0.7203125 | 0.3046875\n",
      "> 31 | 0.4745193123817444 | 0.7728071212768555 | 0.721875 | 0.3046875\n",
      "> 32 | 0.47359323501586914 | 0.7687804698944092 | 0.7171875 | 0.3046875\n",
      "> 33 | 0.47269952297210693 | 0.764846682548523 | 0.7171875 | 0.3046875\n",
      "> 34 | 0.4718369245529175 | 0.7610039710998535 | 0.721875 | 0.3046875\n",
      "> 35 | 0.4710042178630829 | 0.7572504281997681 | 0.7203125 | 0.3046875\n",
      "> 36 | 0.47020021080970764 | 0.7535843253135681 | 0.71875 | 0.3046875\n",
      "> 37 | 0.469423770904541 | 0.7500038146972656 | 0.7234375 | 0.3046875\n",
      "> 38 | 0.4686737656593323 | 0.7465071678161621 | 0.725 | 0.3046875\n",
      "> 39 | 0.4679492115974426 | 0.7430925369262695 | 0.725 | 0.3046875\n",
      "> 40 | 0.4672490358352661 | 0.7397582530975342 | 0.725 | 0.3046875\n",
      "> 41 | 0.46657222509384155 | 0.7365024089813232 | 0.7265625 | 0.3046875\n",
      "> 42 | 0.4659179449081421 | 0.7333234548568726 | 0.7296875 | 0.3046875\n",
      "> 43 | 0.4652852416038513 | 0.7302195429801941 | 0.7296875 | 0.3046875\n",
      "> 44 | 0.46467334032058716 | 0.7271891832351685 | 0.73125 | 0.309375\n",
      "> 45 | 0.4640813171863556 | 0.7242305278778076 | 0.7296875 | 0.3109375\n",
      "> 46 | 0.4635085165500641 | 0.7213422060012817 | 0.7296875 | 0.3140625\n",
      "> 47 | 0.4629541039466858 | 0.7185224294662476 | 0.73125 | 0.3203125\n",
      "> 48 | 0.4624174237251282 | 0.7157696485519409 | 0.73125 | 0.33125\n",
      "> 49 | 0.4618977904319763 | 0.7130823135375977 | 0.734375 | 0.3421875\n",
      "> 50 | 0.4613945782184601 | 0.7104589939117432 | 0.7390625 | 0.3625\n",
      "> 51 | 0.4609071612358093 | 0.7078981399536133 | 0.7421875 | 0.3875\n",
      "> 52 | 0.4604349732398987 | 0.7053983807563782 | 0.7421875 | 0.403125\n",
      "> 53 | 0.4599774479866028 | 0.7029581069946289 | 0.7421875 | 0.4390625\n",
      "> 54 | 0.45953401923179626 | 0.7005761861801147 | 0.7421875 | 0.471875\n",
      "> 55 | 0.4591042399406433 | 0.698250949382782 | 0.7453125 | 0.4859375\n",
      "> 56 | 0.45868760347366333 | 0.6959812641143799 | 0.74375 | 0.5140625\n",
      "> 57 | 0.4582836627960205 | 0.6937656998634338 | 0.7453125 | 0.5296875\n",
      "> 58 | 0.45789188146591187 | 0.6916030645370483 | 0.7453125 | 0.55625\n",
      "> 59 | 0.4575120210647583 | 0.6894919872283936 | 0.74375 | 0.5734375\n",
      "> 60 | 0.45714354515075684 | 0.6874312162399292 | 0.74375 | 0.5796875\n",
      "> 61 | 0.4567860960960388 | 0.6854197382926941 | 0.7421875 | 0.58125\n",
      "> 62 | 0.456439346075058 | 0.6834560632705688 | 0.7421875 | 0.5953125\n",
      "> 63 | 0.4561029076576233 | 0.6815394163131714 | 0.7453125 | 0.6078125\n",
      "> 64 | 0.45577648282051086 | 0.6796683073043823 | 0.746875 | 0.6203125\n",
      "> 65 | 0.45545968413352966 | 0.6778417229652405 | 0.746875 | 0.6265625\n",
      "> 66 | 0.4551522731781006 | 0.6760586500167847 | 0.7484375 | 0.634375\n",
      "> 67 | 0.45485395193099976 | 0.6743180155754089 | 0.75 | 0.6421875\n",
      "> 68 | 0.4545644521713257 | 0.6726187467575073 | 0.7515625 | 0.6484375\n",
      "> 69 | 0.4542834460735321 | 0.6709598302841187 | 0.7515625 | 0.65625\n",
      "> 70 | 0.4540106952190399 | 0.6693403124809265 | 0.7515625 | 0.665625\n",
      "> 71 | 0.4537459909915924 | 0.6677591800689697 | 0.7515625 | 0.6703125\n",
      "> 72 | 0.4534890651702881 | 0.6662154197692871 | 0.75 | 0.6765625\n",
      "> 73 | 0.45323967933654785 | 0.6647082567214966 | 0.75 | 0.678125\n",
      "> 74 | 0.45299768447875977 | 0.6632366180419922 | 0.7484375 | 0.675\n",
      "> 75 | 0.45276278257369995 | 0.6617997884750366 | 0.7484375 | 0.6828125\n",
      "> 76 | 0.4525347948074341 | 0.6603966951370239 | 0.7484375 | 0.6828125\n",
      "> 77 | 0.4523135721683502 | 0.6590267419815063 | 0.7484375 | 0.690625\n",
      "> 78 | 0.45209890604019165 | 0.6576889753341675 | 0.746875 | 0.6984375\n",
      "> 79 | 0.45189061760902405 | 0.6563825607299805 | 0.746875 | 0.703125\n",
      "> 80 | 0.4516885280609131 | 0.655106782913208 | 0.746875 | 0.7015625\n",
      "> 81 | 0.45149242877960205 | 0.6538609266281128 | 0.746875 | 0.7046875\n",
      "> 82 | 0.4513022303581238 | 0.6526440382003784 | 0.746875 | 0.70625\n",
      "> 83 | 0.45111778378486633 | 0.6514555811882019 | 0.7484375 | 0.7078125\n",
      "> 84 | 0.450938880443573 | 0.6502946615219116 | 0.7484375 | 0.709375\n",
      "> 85 | 0.4507654309272766 | 0.6491608023643494 | 0.7484375 | 0.709375\n",
      "> 86 | 0.45059722661972046 | 0.6480531692504883 | 0.7484375 | 0.7125\n",
      "> 87 | 0.450434148311615 | 0.6469712257385254 | 0.746875 | 0.715625\n",
      "> 88 | 0.45027613639831543 | 0.6459141969680786 | 0.7484375 | 0.7140625\n",
      "> 89 | 0.4501230716705322 | 0.6448814868927002 | 0.7484375 | 0.715625\n",
      "> 90 | 0.4499747157096863 | 0.6438726186752319 | 0.746875 | 0.7171875\n",
      "> 91 | 0.4498310685157776 | 0.642886757850647 | 0.746875 | 0.7140625\n",
      "> 92 | 0.4496919512748718 | 0.6419235467910767 | 0.746875 | 0.7140625\n",
      "> 93 | 0.44955727458000183 | 0.6409822702407837 | 0.7484375 | 0.7125\n",
      "> 94 | 0.44942688941955566 | 0.6400625109672546 | 0.75 | 0.7125\n",
      "> 95 | 0.44930076599121094 | 0.639163613319397 | 0.7484375 | 0.7109375\n",
      "> 96 | 0.4491787552833557 | 0.6382850408554077 | 0.75 | 0.709375\n",
      "> 97 | 0.4490607976913452 | 0.6374263763427734 | 0.746875 | 0.709375\n",
      "> 98 | 0.4489467740058899 | 0.6365870237350464 | 0.746875 | 0.7125\n",
      "> 99 | 0.4488365650177002 | 0.6357666254043579 | 0.746875 | 0.7109375\n",
      "> 100 | 0.44873011112213135 | 0.634964644908905 | 0.746875 | 0.7109375\n",
      "> Evaluation\n",
      "> Class Acc = 0.71484375\n",
      "> Adv Acc = 0.71484375\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.874155580997467 | 0.8469903394579887 | 0.9247498959302902\n",
      "> Confusion Matrix \n",
      "TN: 24.0 | FP: 54.0 \n",
      "FN: 19.0 | TP: 159.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 12.0 | FP: 14.0 \n",
      "FN: 9.0 | TP: 48.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 12.0 | FP: 40.0 \n",
      "FN: 10.0 | TP: 111.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6509820222854614 | 1.0844109058380127 | 0.690625 | 0.3109375\n",
      "> 2 | 0.6439554691314697 | 1.0736303329467773 | 0.690625 | 0.3109375\n",
      "> 3 | 0.6368228793144226 | 1.063185214996338 | 0.690625 | 0.3109375\n",
      "> 4 | 0.6300750970840454 | 1.0530776977539062 | 0.690625 | 0.3109375\n",
      "> 5 | 0.6238448619842529 | 1.0432746410369873 | 0.690625 | 0.3109375\n",
      "> 6 | 0.6181128025054932 | 1.0337316989898682 | 0.690625 | 0.3109375\n",
      "> 7 | 0.6128177642822266 | 1.0244066715240479 | 0.690625 | 0.3109375\n",
      "> 8 | 0.6078959107398987 | 1.0152668952941895 | 0.690625 | 0.3109375\n",
      "> 9 | 0.6032933592796326 | 1.0062892436981201 | 0.690625 | 0.3109375\n",
      "> 10 | 0.5989664793014526 | 0.9974590539932251 | 0.690625 | 0.3109375\n",
      "> 11 | 0.5948810577392578 | 0.9887673854827881 | 0.690625 | 0.3109375\n",
      "> 12 | 0.5910097360610962 | 0.9802089333534241 | 0.690625 | 0.3109375\n",
      "> 13 | 0.5873305797576904 | 0.9717812538146973 | 0.690625 | 0.3109375\n",
      "> 14 | 0.5838257074356079 | 0.9634835720062256 | 0.690625 | 0.3109375\n",
      "> 15 | 0.5804802179336548 | 0.9553155303001404 | 0.690625 | 0.3109375\n",
      "> 16 | 0.5772815942764282 | 0.9472776651382446 | 0.690625 | 0.3109375\n",
      "> 17 | 0.5742193460464478 | 0.939370334148407 | 0.6921875 | 0.3109375\n",
      "> 18 | 0.5712839365005493 | 0.93159419298172 | 0.6921875 | 0.3109375\n",
      "> 19 | 0.5684675574302673 | 0.9239494800567627 | 0.6921875 | 0.3109375\n",
      "> 20 | 0.5657627582550049 | 0.9164365530014038 | 0.69375 | 0.3109375\n",
      "> 21 | 0.563163161277771 | 0.909055233001709 | 0.69375 | 0.3109375\n",
      "> 22 | 0.5606628060340881 | 0.9018055200576782 | 0.69375 | 0.3109375\n",
      "> 23 | 0.5582563877105713 | 0.8946869373321533 | 0.6953125 | 0.3109375\n",
      "> 24 | 0.5559390783309937 | 0.8876990079879761 | 0.696875 | 0.3109375\n",
      "> 25 | 0.5537062287330627 | 0.8808407783508301 | 0.6984375 | 0.3109375\n",
      "> 26 | 0.5515536665916443 | 0.8741114735603333 | 0.7015625 | 0.3109375\n",
      "> 27 | 0.5494775176048279 | 0.8675099611282349 | 0.7015625 | 0.3109375\n",
      "> 28 | 0.5474740862846375 | 0.8610351085662842 | 0.703125 | 0.3109375\n",
      "> 29 | 0.5455399751663208 | 0.8546855449676514 | 0.703125 | 0.3109375\n",
      "> 30 | 0.5436720848083496 | 0.8484598398208618 | 0.7046875 | 0.3109375\n",
      "> 31 | 0.5418672561645508 | 0.8423565030097961 | 0.7078125 | 0.3109375\n",
      "> 32 | 0.5401227474212646 | 0.8363738059997559 | 0.7125 | 0.3109375\n",
      "> 33 | 0.5384359359741211 | 0.8305102586746216 | 0.7140625 | 0.3109375\n",
      "> 34 | 0.53680419921875 | 0.8247639536857605 | 0.7125 | 0.3109375\n",
      "> 35 | 0.5352252125740051 | 0.8191331624984741 | 0.7125 | 0.3109375\n",
      "> 36 | 0.5336967706680298 | 0.813616156578064 | 0.7109375 | 0.3109375\n",
      "> 37 | 0.5322167277336121 | 0.8082109689712524 | 0.7171875 | 0.3109375\n",
      "> 38 | 0.5307829976081848 | 0.8029156923294067 | 0.7203125 | 0.3109375\n",
      "> 39 | 0.5293937921524048 | 0.7977284789085388 | 0.7203125 | 0.3109375\n",
      "> 40 | 0.5280472040176392 | 0.7926473617553711 | 0.7234375 | 0.3109375\n",
      "> 41 | 0.526741623878479 | 0.7876704335212708 | 0.7234375 | 0.3109375\n",
      "> 42 | 0.5254753828048706 | 0.782795786857605 | 0.7296875 | 0.3109375\n",
      "> 43 | 0.5242468118667603 | 0.7780213356018066 | 0.728125 | 0.3109375\n",
      "> 44 | 0.5230545997619629 | 0.7733452916145325 | 0.73125 | 0.3109375\n",
      "> 45 | 0.5218971967697144 | 0.7687656879425049 | 0.73125 | 0.3140625\n",
      "> 46 | 0.5207734107971191 | 0.7642805576324463 | 0.7328125 | 0.315625\n",
      "> 47 | 0.5196818113327026 | 0.7598880529403687 | 0.7328125 | 0.3234375\n",
      "> 48 | 0.5186213254928589 | 0.7555862665176392 | 0.7328125 | 0.325\n",
      "> 49 | 0.5175907611846924 | 0.751373291015625 | 0.7296875 | 0.33125\n",
      "> 50 | 0.5165889859199524 | 0.7472473382949829 | 0.7296875 | 0.3375\n",
      "> 51 | 0.5156148672103882 | 0.7432065010070801 | 0.7296875 | 0.3421875\n",
      "> 52 | 0.5146675109863281 | 0.739249050617218 | 0.7296875 | 0.346875\n",
      "> 53 | 0.5137460231781006 | 0.7353731989860535 | 0.728125 | 0.353125\n",
      "> 54 | 0.5128492712974548 | 0.7315771579742432 | 0.73125 | 0.3765625\n",
      "> 55 | 0.5119765400886536 | 0.7278591394424438 | 0.7328125 | 0.3953125\n",
      "> 56 | 0.5111269354820251 | 0.7242175340652466 | 0.7328125 | 0.4109375\n",
      "> 57 | 0.5102996826171875 | 0.7206505537033081 | 0.73125 | 0.4265625\n",
      "> 58 | 0.5094940066337585 | 0.7171567678451538 | 0.7296875 | 0.45\n",
      "> 59 | 0.5087090730667114 | 0.7137343883514404 | 0.73125 | 0.4640625\n",
      "> 60 | 0.5079444050788879 | 0.7103818655014038 | 0.734375 | 0.4703125\n",
      "> 61 | 0.5071990489959717 | 0.7070976495742798 | 0.734375 | 0.4828125\n",
      "> 62 | 0.5064725875854492 | 0.7038801312446594 | 0.734375 | 0.50625\n",
      "> 63 | 0.505764365196228 | 0.7007279396057129 | 0.7375 | 0.5171875\n",
      "> 64 | 0.505073606967926 | 0.6976395845413208 | 0.7375 | 0.525\n",
      "> 65 | 0.5043999552726746 | 0.6946135759353638 | 0.7390625 | 0.5390625\n",
      "> 66 | 0.5037427544593811 | 0.6916487216949463 | 0.740625 | 0.5484375\n",
      "> 67 | 0.5031015872955322 | 0.6887432932853699 | 0.7421875 | 0.5609375\n",
      "> 68 | 0.5024757385253906 | 0.6858961582183838 | 0.74375 | 0.575\n",
      "> 69 | 0.5018649101257324 | 0.6831059455871582 | 0.74375 | 0.5859375\n",
      "> 70 | 0.5012686848640442 | 0.6803714036941528 | 0.74375 | 0.6046875\n",
      "> 71 | 0.5006864666938782 | 0.6776912212371826 | 0.7453125 | 0.6046875\n",
      "> 72 | 0.5001177787780762 | 0.6750643253326416 | 0.7453125 | 0.609375\n",
      "> 73 | 0.49956244230270386 | 0.6724892854690552 | 0.7453125 | 0.61875\n",
      "> 74 | 0.49901992082595825 | 0.6699651479721069 | 0.7453125 | 0.625\n",
      "> 75 | 0.4984897971153259 | 0.667490541934967 | 0.7453125 | 0.634375\n",
      "> 76 | 0.497971773147583 | 0.6650645732879639 | 0.746875 | 0.6421875\n",
      "> 77 | 0.49746546149253845 | 0.6626859903335571 | 0.746875 | 0.65\n",
      "> 78 | 0.4969705641269684 | 0.6603537797927856 | 0.7484375 | 0.6546875\n",
      "> 79 | 0.49648669362068176 | 0.6580669283866882 | 0.7515625 | 0.659375\n",
      "> 80 | 0.4960135817527771 | 0.6558243632316589 | 0.7515625 | 0.659375\n",
      "> 81 | 0.49555090069770813 | 0.6536251306533813 | 0.7515625 | 0.6609375\n",
      "> 82 | 0.49509841203689575 | 0.6514682769775391 | 0.7546875 | 0.6703125\n",
      "> 83 | 0.4946557581424713 | 0.6493527889251709 | 0.75625 | 0.675\n",
      "> 84 | 0.4942226707935333 | 0.64727783203125 | 0.75625 | 0.678125\n",
      "> 85 | 0.49379897117614746 | 0.64524245262146 | 0.75625 | 0.678125\n",
      "> 86 | 0.49338430166244507 | 0.6432457566261292 | 0.7578125 | 0.678125\n",
      "> 87 | 0.4929784834384918 | 0.6412869095802307 | 0.75625 | 0.6765625\n",
      "> 88 | 0.4925812780857086 | 0.6393651366233826 | 0.75625 | 0.678125\n",
      "> 89 | 0.49219244718551636 | 0.6374795436859131 | 0.75625 | 0.6765625\n",
      "> 90 | 0.49181169271469116 | 0.635629415512085 | 0.759375 | 0.68125\n",
      "> 91 | 0.49143892526626587 | 0.6338138580322266 | 0.759375 | 0.684375\n",
      "> 92 | 0.4910739064216614 | 0.6320321559906006 | 0.7578125 | 0.6828125\n",
      "> 93 | 0.4907163977622986 | 0.6302837133407593 | 0.7578125 | 0.6828125\n",
      "> 94 | 0.49036622047424316 | 0.628567636013031 | 0.7578125 | 0.6828125\n",
      "> 95 | 0.4900231659412384 | 0.6268832683563232 | 0.7609375 | 0.6828125\n",
      "> 96 | 0.48968708515167236 | 0.6252299547195435 | 0.7625 | 0.684375\n",
      "> 97 | 0.4893578290939331 | 0.6236069798469543 | 0.7640625 | 0.6875\n",
      "> 98 | 0.48903512954711914 | 0.6220138072967529 | 0.7640625 | 0.6921875\n",
      "> 99 | 0.48871898651123047 | 0.6204497218132019 | 0.7640625 | 0.690625\n",
      "> 100 | 0.4884090721607208 | 0.618914008140564 | 0.765625 | 0.6890625\n",
      "> Evaluation\n",
      "> Class Acc = 0.74609375\n",
      "> Adv Acc = 0.74609375\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.952728271484375 | 0.9737232774496078 | 0.9656283557415009\n",
      "> Confusion Matrix \n",
      "TN: 23.0 | FP: 51.0 \n",
      "FN: 14.0 | TP: 168.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 9.0 | FP: 21.0 \n",
      "FN: 5.0 | TP: 44.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 14.0 | FP: 30.0 \n",
      "FN: 9.0 | TP: 124.0\n"
     ]
    }
   ],
   "source": [
    "fairdef = 'DemPar'\n",
    "\n",
    "for cv_seed in cv_seeds:\n",
    "    x_train, x_test, y_train, y_test, a_train, a_test = train_test_split(\n",
    "        x, y, a, test_size=0.3, random_state=cv_seed)\n",
    "\n",
    "    train_data = Dataset.from_tensor_slices((x_train, y_train, a_train))\n",
    "    train_data = train_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    test_data = Dataset.from_tensor_slices((x_test, y_test, a_test))\n",
    "    test_data = test_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    # train below\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    model = FairLogisticRegression(xdim, ydim, adim, batch_size, fairdef)\n",
    "    zhang_train(model, raw_data, train_data, epochs, opt)\n",
    "\n",
    "    Y, A, Y_hat, A_hat = fair_evaluation(model, test_data)\n",
    "    clas_acc, dp, deqodds, deqopp, confusion_matrix, metrics_a0, metrics_a1 = compute_metrics(Y, A, Y_hat, A_hat, adim)\n",
    "\n",
    "    fair_metrics = (dp, deqodds, deqopp)\n",
    "    tradeoff = []\n",
    "    for fair_metric in fair_metrics:\n",
    "        tradeoff.append(compute_tradeoff(clas_acc, fair_metric))\n",
    "\n",
    "    result = ['Zhang4DP', cv_seed, clas_acc, dp, deqodds, deqopp, tradeoff[0], tradeoff[1], tradeoff[2]] + metrics_a0 + metrics_a1\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    del(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhang for Eq Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.5918697118759155 | 1.0342029333114624 | 0.6734375 | 0.2984375\n",
      "> 2 | 0.5884822010993958 | 1.0194097757339478 | 0.6734375 | 0.2984375\n",
      "> 3 | 0.5849649906158447 | 1.0046213865280151 | 0.6734375 | 0.2984375\n",
      "> 4 | 0.5815534591674805 | 0.9901756048202515 | 0.6734375 | 0.2984375\n",
      "> 5 | 0.5782995820045471 | 0.9761829376220703 | 0.6734375 | 0.2984375\n",
      "> 6 | 0.5751881003379822 | 0.9626451730728149 | 0.6734375 | 0.2984375\n",
      "> 7 | 0.5721908807754517 | 0.9495275020599365 | 0.6734375 | 0.2984375\n",
      "> 8 | 0.5692838430404663 | 0.9367902278900146 | 0.6734375 | 0.2984375\n",
      "> 9 | 0.5664511919021606 | 0.9243993163108826 | 0.6734375 | 0.2984375\n",
      "> 10 | 0.5636833906173706 | 0.9123280048370361 | 0.6734375 | 0.2984375\n",
      "> 11 | 0.5609760880470276 | 0.9005568027496338 | 0.6734375 | 0.2984375\n",
      "> 12 | 0.5583276748657227 | 0.8890718221664429 | 0.6734375 | 0.2984375\n",
      "> 13 | 0.5557384490966797 | 0.8778634071350098 | 0.6734375 | 0.2984375\n",
      "> 14 | 0.5532094240188599 | 0.8669252991676331 | 0.6734375 | 0.2984375\n",
      "> 15 | 0.5507417321205139 | 0.8562532067298889 | 0.6734375 | 0.2984375\n",
      "> 16 | 0.5483365058898926 | 0.8458443880081177 | 0.6734375 | 0.2984375\n",
      "> 17 | 0.5459945201873779 | 0.8356971144676208 | 0.675 | 0.2984375\n",
      "> 18 | 0.5437160730361938 | 0.8258098363876343 | 0.675 | 0.2984375\n",
      "> 19 | 0.5415010452270508 | 0.8161813616752625 | 0.6765625 | 0.2984375\n",
      "> 20 | 0.5393490791320801 | 0.8068103194236755 | 0.68125 | 0.2984375\n",
      "> 21 | 0.5372591614723206 | 0.7976951599121094 | 0.6859375 | 0.2984375\n",
      "> 22 | 0.535230278968811 | 0.7888341546058655 | 0.6921875 | 0.2984375\n",
      "> 23 | 0.5332611203193665 | 0.7802249789237976 | 0.69375 | 0.2984375\n",
      "> 24 | 0.5313501358032227 | 0.7718651294708252 | 0.696875 | 0.2984375\n",
      "> 25 | 0.5294956564903259 | 0.763751745223999 | 0.7015625 | 0.2984375\n",
      "> 26 | 0.5276959538459778 | 0.7558814883232117 | 0.70625 | 0.2984375\n",
      "> 27 | 0.5259492993354797 | 0.7482507228851318 | 0.703125 | 0.3\n",
      "> 28 | 0.5242538452148438 | 0.7408555746078491 | 0.6984375 | 0.3\n",
      "> 29 | 0.522607684135437 | 0.7336918711662292 | 0.6984375 | 0.3\n",
      "> 30 | 0.5210091471672058 | 0.7267551422119141 | 0.7 | 0.3046875\n",
      "> 31 | 0.5194564461708069 | 0.7200406789779663 | 0.7015625 | 0.31875\n",
      "> 32 | 0.517947793006897 | 0.7135436534881592 | 0.7046875 | 0.33125\n",
      "> 33 | 0.5164815187454224 | 0.7072592973709106 | 0.7078125 | 0.3546875\n",
      "> 34 | 0.5150560140609741 | 0.7011823058128357 | 0.7109375 | 0.3921875\n",
      "> 35 | 0.5136697292327881 | 0.6953076124191284 | 0.7171875 | 0.428125\n",
      "> 36 | 0.5123211145401001 | 0.6896300315856934 | 0.7203125 | 0.45\n",
      "> 37 | 0.5110087394714355 | 0.6841442584991455 | 0.721875 | 0.4734375\n",
      "> 38 | 0.5097311735153198 | 0.6788450479507446 | 0.721875 | 0.5125\n",
      "> 39 | 0.5084869861602783 | 0.6737270355224609 | 0.725 | 0.54375\n",
      "> 40 | 0.5072751641273499 | 0.668785035610199 | 0.728125 | 0.56875\n",
      "> 41 | 0.5060943365097046 | 0.6640137434005737 | 0.73125 | 0.5921875\n",
      "> 42 | 0.5049432516098022 | 0.6594080924987793 | 0.7328125 | 0.596875\n",
      "> 43 | 0.5038208961486816 | 0.6549628376960754 | 0.734375 | 0.609375\n",
      "> 44 | 0.5027261972427368 | 0.6506730318069458 | 0.7359375 | 0.6125\n",
      "> 45 | 0.5016582012176514 | 0.6465335488319397 | 0.7390625 | 0.6359375\n",
      "> 46 | 0.5006158351898193 | 0.6425396800041199 | 0.740625 | 0.634375\n",
      "> 47 | 0.49959826469421387 | 0.6386864185333252 | 0.74375 | 0.6546875\n",
      "> 48 | 0.49860456585884094 | 0.6349692344665527 | 0.7453125 | 0.665625\n",
      "> 49 | 0.4976338744163513 | 0.63138347864151 | 0.7421875 | 0.6578125\n",
      "> 50 | 0.4966855049133301 | 0.6279246807098389 | 0.74375 | 0.659375\n",
      "> 51 | 0.4957585334777832 | 0.6245883703231812 | 0.7453125 | 0.665625\n",
      "> 52 | 0.49485236406326294 | 0.6213703155517578 | 0.74375 | 0.6671875\n",
      "> 53 | 0.493966281414032 | 0.6182663440704346 | 0.7453125 | 0.6671875\n",
      "> 54 | 0.493099570274353 | 0.6152724027633667 | 0.7453125 | 0.671875\n",
      "> 55 | 0.4922516345977783 | 0.6123846769332886 | 0.746875 | 0.6734375\n",
      "> 56 | 0.4914218485355377 | 0.6095991134643555 | 0.7484375 | 0.675\n",
      "> 57 | 0.49060967564582825 | 0.6069121360778809 | 0.75 | 0.6765625\n",
      "> 58 | 0.48981451988220215 | 0.6043201088905334 | 0.75 | 0.6765625\n",
      "> 59 | 0.4890359044075012 | 0.601819634437561 | 0.7515625 | 0.675\n",
      "> 60 | 0.4882732033729553 | 0.5994071960449219 | 0.7546875 | 0.68125\n",
      "> 61 | 0.4875260591506958 | 0.5970796346664429 | 0.7546875 | 0.684375\n",
      "> 62 | 0.48679396510124207 | 0.5948337316513062 | 0.7546875 | 0.6859375\n",
      "> 63 | 0.4860764145851135 | 0.5926664471626282 | 0.7546875 | 0.684375\n",
      "> 64 | 0.4853730797767639 | 0.5905748009681702 | 0.75625 | 0.684375\n",
      "> 65 | 0.48468345403671265 | 0.5885560512542725 | 0.753125 | 0.6859375\n",
      "> 66 | 0.48400723934173584 | 0.5866072773933411 | 0.753125 | 0.6859375\n",
      "> 67 | 0.4833439290523529 | 0.5847259759902954 | 0.753125 | 0.684375\n",
      "> 68 | 0.48269325494766235 | 0.5829095244407654 | 0.7546875 | 0.684375\n",
      "> 69 | 0.48205485939979553 | 0.5811554193496704 | 0.7515625 | 0.6859375\n",
      "> 70 | 0.4814284145832062 | 0.5794613361358643 | 0.75 | 0.6828125\n",
      "> 71 | 0.48081350326538086 | 0.5778250098228455 | 0.75 | 0.68125\n",
      "> 72 | 0.4802098870277405 | 0.5762441158294678 | 0.75 | 0.684375\n",
      "> 73 | 0.4796172082424164 | 0.5747166275978088 | 0.75 | 0.6875\n",
      "> 74 | 0.47903525829315186 | 0.5732405185699463 | 0.7515625 | 0.6890625\n",
      "> 75 | 0.47846364974975586 | 0.571813702583313 | 0.7515625 | 0.6875\n",
      "> 76 | 0.47790226340293884 | 0.5704343318939209 | 0.7515625 | 0.6859375\n",
      "> 77 | 0.477350652217865 | 0.5691006183624268 | 0.7515625 | 0.684375\n",
      "> 78 | 0.47680866718292236 | 0.5678108334541321 | 0.7515625 | 0.6859375\n",
      "> 79 | 0.47627606987953186 | 0.5665632486343384 | 0.75 | 0.6875\n",
      "> 80 | 0.4757525324821472 | 0.5653562545776367 | 0.7515625 | 0.6890625\n",
      "> 81 | 0.4752379357814789 | 0.5641883611679077 | 0.7515625 | 0.690625\n",
      "> 82 | 0.474731981754303 | 0.5630578994750977 | 0.75 | 0.6921875\n",
      "> 83 | 0.4742344915866852 | 0.5619635581970215 | 0.7515625 | 0.6921875\n",
      "> 84 | 0.47374528646469116 | 0.5609039664268494 | 0.7484375 | 0.6921875\n",
      "> 85 | 0.47326406836509705 | 0.5598778128623962 | 0.746875 | 0.69375\n",
      "> 86 | 0.4727907180786133 | 0.558883786201477 | 0.746875 | 0.69375\n",
      "> 87 | 0.47232502698898315 | 0.5579205751419067 | 0.7453125 | 0.69375\n",
      "> 88 | 0.47186681628227234 | 0.5569871664047241 | 0.7453125 | 0.6921875\n",
      "> 89 | 0.47141584753990173 | 0.5560823678970337 | 0.74375 | 0.6890625\n",
      "> 90 | 0.47097206115722656 | 0.5552051067352295 | 0.7453125 | 0.6890625\n",
      "> 91 | 0.47053515911102295 | 0.5543543100357056 | 0.7453125 | 0.6890625\n",
      "> 92 | 0.4701051115989685 | 0.5535290241241455 | 0.7453125 | 0.690625\n",
      "> 93 | 0.46968168020248413 | 0.5527281761169434 | 0.746875 | 0.6921875\n",
      "> 94 | 0.4692647457122803 | 0.5519510507583618 | 0.746875 | 0.6953125\n",
      "> 95 | 0.4688540995121002 | 0.5511966347694397 | 0.746875 | 0.6953125\n",
      "> 96 | 0.4684496521949768 | 0.5504641532897949 | 0.746875 | 0.6953125\n",
      "> 97 | 0.4680511951446533 | 0.5497526526451111 | 0.7453125 | 0.6953125\n",
      "> 98 | 0.4676586985588074 | 0.5490615367889404 | 0.746875 | 0.696875\n",
      "> 99 | 0.46727192401885986 | 0.5483899116516113 | 0.7453125 | 0.6953125\n",
      "> 100 | 0.46689078211784363 | 0.5477371215820312 | 0.746875 | 0.6953125\n",
      "> Evaluation\n",
      "> Class Acc = 0.72265625\n",
      "> Adv Acc = 0.72265625\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.7693798542022705 | 0.7058544829487801 | 0.8952254801988602\n",
      "> Confusion Matrix \n",
      "TN: 32.0 | FP: 36.0 \n",
      "FN: 35.0 | TP: 153.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 20.0 | FP: 6.0 \n",
      "FN: 15.0 | TP: 43.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 12.0 | FP: 30.0 \n",
      "FN: 20.0 | TP: 110.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6526965498924255 | 1.0346646308898926 | 0.7078125 | 0.3109375\n",
      "> 2 | 0.6476641893386841 | 1.02016019821167 | 0.7078125 | 0.3109375\n",
      "> 3 | 0.6425833702087402 | 1.0055495500564575 | 0.7078125 | 0.3109375\n",
      "> 4 | 0.6377840042114258 | 0.9911697506904602 | 0.7078125 | 0.3109375\n",
      "> 5 | 0.6333556771278381 | 0.9771422743797302 | 0.7078125 | 0.3109375\n",
      "> 6 | 0.6292896270751953 | 0.9634873270988464 | 0.7078125 | 0.3109375\n",
      "> 7 | 0.625548243522644 | 0.9501923322677612 | 0.7078125 | 0.3109375\n",
      "> 8 | 0.622092068195343 | 0.937239408493042 | 0.7078125 | 0.3109375\n",
      "> 9 | 0.6188857555389404 | 0.9246139526367188 | 0.7078125 | 0.3109375\n",
      "> 10 | 0.6159001588821411 | 0.9123056530952454 | 0.7078125 | 0.3109375\n",
      "> 11 | 0.6131113767623901 | 0.9003078937530518 | 0.7078125 | 0.3109375\n",
      "> 12 | 0.6104995012283325 | 0.8886159658432007 | 0.7078125 | 0.3109375\n",
      "> 13 | 0.6080478429794312 | 0.8772268295288086 | 0.7078125 | 0.3109375\n",
      "> 14 | 0.6057424545288086 | 0.8661378026008606 | 0.7078125 | 0.3109375\n",
      "> 15 | 0.6035712361335754 | 0.8553466200828552 | 0.7078125 | 0.3109375\n",
      "> 16 | 0.6015233993530273 | 0.8448506593704224 | 0.7078125 | 0.3109375\n",
      "> 17 | 0.5995896458625793 | 0.8346471786499023 | 0.7078125 | 0.3109375\n",
      "> 18 | 0.5977618098258972 | 0.8247331380844116 | 0.7078125 | 0.3109375\n",
      "> 19 | 0.5960323810577393 | 0.8151048421859741 | 0.7078125 | 0.3109375\n",
      "> 20 | 0.5943945646286011 | 0.8057584762573242 | 0.7078125 | 0.3109375\n",
      "> 21 | 0.5928422212600708 | 0.7966896891593933 | 0.7078125 | 0.3109375\n",
      "> 22 | 0.5913697481155396 | 0.7878938317298889 | 0.7078125 | 0.3109375\n",
      "> 23 | 0.5899720191955566 | 0.7793660163879395 | 0.7078125 | 0.3109375\n",
      "> 24 | 0.58864426612854 | 0.7711009383201599 | 0.709375 | 0.3109375\n",
      "> 25 | 0.5873821377754211 | 0.7630931735038757 | 0.7078125 | 0.3109375\n",
      "> 26 | 0.586181640625 | 0.7553369998931885 | 0.7109375 | 0.3109375\n",
      "> 27 | 0.5850389003753662 | 0.7478268146514893 | 0.7109375 | 0.3109375\n",
      "> 28 | 0.5839505791664124 | 0.7405567169189453 | 0.709375 | 0.3109375\n",
      "> 29 | 0.5829132795333862 | 0.7335206270217896 | 0.7125 | 0.315625\n",
      "> 30 | 0.5819241404533386 | 0.7267124652862549 | 0.7125 | 0.33125\n",
      "> 31 | 0.5809803009033203 | 0.720126211643219 | 0.7125 | 0.3453125\n",
      "> 32 | 0.5800790786743164 | 0.7137559056282043 | 0.715625 | 0.353125\n",
      "> 33 | 0.5792180895805359 | 0.7075954675674438 | 0.7171875 | 0.3859375\n",
      "> 34 | 0.5783951282501221 | 0.7016387581825256 | 0.71875 | 0.409375\n",
      "> 35 | 0.5776078701019287 | 0.6958799362182617 | 0.721875 | 0.4265625\n",
      "> 36 | 0.5768545866012573 | 0.6903130412101746 | 0.7234375 | 0.4578125\n",
      "> 37 | 0.576133131980896 | 0.6849321126937866 | 0.721875 | 0.4890625\n",
      "> 38 | 0.5754419565200806 | 0.6797316074371338 | 0.7234375 | 0.5046875\n",
      "> 39 | 0.5747793912887573 | 0.6747058033943176 | 0.721875 | 0.5359375\n",
      "> 40 | 0.5741438865661621 | 0.669849157333374 | 0.7234375 | 0.565625\n",
      "> 41 | 0.5735339522361755 | 0.6651561260223389 | 0.725 | 0.571875\n",
      "> 42 | 0.5729482769966125 | 0.6606215238571167 | 0.725 | 0.5796875\n",
      "> 43 | 0.5723855495452881 | 0.6562399864196777 | 0.7234375 | 0.6046875\n",
      "> 44 | 0.5718446969985962 | 0.6520064473152161 | 0.721875 | 0.6296875\n",
      "> 45 | 0.5713245868682861 | 0.6479160785675049 | 0.721875 | 0.6328125\n",
      "> 46 | 0.5708239674568176 | 0.6439638733863831 | 0.7234375 | 0.6421875\n",
      "> 47 | 0.5703420639038086 | 0.6401451230049133 | 0.7234375 | 0.6578125\n",
      "> 48 | 0.5698778629302979 | 0.6364552974700928 | 0.7234375 | 0.665625\n",
      "> 49 | 0.5694304704666138 | 0.632889986038208 | 0.7234375 | 0.6640625\n",
      "> 50 | 0.5689990520477295 | 0.6294447779655457 | 0.725 | 0.6609375\n",
      "> 51 | 0.5685828924179077 | 0.6261154413223267 | 0.725 | 0.6625\n",
      "> 52 | 0.5681811571121216 | 0.6228979825973511 | 0.725 | 0.6703125\n",
      "> 53 | 0.5677932500839233 | 0.6197883486747742 | 0.728125 | 0.6796875\n",
      "> 54 | 0.5674184560775757 | 0.6167827844619751 | 0.7296875 | 0.6828125\n",
      "> 55 | 0.5670560598373413 | 0.6138775944709778 | 0.73125 | 0.6890625\n",
      "> 56 | 0.566705584526062 | 0.6110690832138062 | 0.73125 | 0.6875\n",
      "> 57 | 0.5663665533065796 | 0.6083539724349976 | 0.734375 | 0.6875\n",
      "> 58 | 0.5660382509231567 | 0.6057287454605103 | 0.734375 | 0.6890625\n",
      "> 59 | 0.5657203197479248 | 0.6031903028488159 | 0.7390625 | 0.6890625\n",
      "> 60 | 0.5654122233390808 | 0.6007353663444519 | 0.7390625 | 0.690625\n",
      "> 61 | 0.5651135444641113 | 0.5983610153198242 | 0.7390625 | 0.6875\n",
      "> 62 | 0.5648238062858582 | 0.5960642099380493 | 0.7390625 | 0.6875\n",
      "> 63 | 0.5645425915718079 | 0.5938422679901123 | 0.7390625 | 0.6875\n",
      "> 64 | 0.5642696022987366 | 0.5916925668716431 | 0.740625 | 0.690625\n",
      "> 65 | 0.5640044808387756 | 0.5896123647689819 | 0.740625 | 0.690625\n",
      "> 66 | 0.5637468099594116 | 0.5875991582870483 | 0.7421875 | 0.6921875\n",
      "> 67 | 0.5634962320327759 | 0.5856504440307617 | 0.7421875 | 0.690625\n",
      "> 68 | 0.5632525682449341 | 0.5837640762329102 | 0.74375 | 0.6921875\n",
      "> 69 | 0.5630154609680176 | 0.5819377303123474 | 0.746875 | 0.690625\n",
      "> 70 | 0.5627845525741577 | 0.5801692008972168 | 0.7484375 | 0.6921875\n",
      "> 71 | 0.5625596046447754 | 0.5784564018249512 | 0.7484375 | 0.6921875\n",
      "> 72 | 0.562340497970581 | 0.5767974257469177 | 0.7484375 | 0.6921875\n",
      "> 73 | 0.562126874923706 | 0.5751902461051941 | 0.75 | 0.6953125\n",
      "> 74 | 0.5619184374809265 | 0.573633074760437 | 0.7515625 | 0.6953125\n",
      "> 75 | 0.5617151260375977 | 0.5721241235733032 | 0.753125 | 0.6953125\n",
      "> 76 | 0.5615165829658508 | 0.5706616044044495 | 0.7546875 | 0.6953125\n",
      "> 77 | 0.5613226890563965 | 0.5692439675331116 | 0.753125 | 0.6953125\n",
      "> 78 | 0.5611332654953003 | 0.5678695440292358 | 0.753125 | 0.6984375\n",
      "> 79 | 0.5609481334686279 | 0.5665369033813477 | 0.753125 | 0.6984375\n",
      "> 80 | 0.5607669949531555 | 0.5652445554733276 | 0.753125 | 0.6953125\n",
      "> 81 | 0.5605899095535278 | 0.5639910101890564 | 0.753125 | 0.6984375\n",
      "> 82 | 0.560416579246521 | 0.5627749562263489 | 0.7546875 | 0.696875\n",
      "> 83 | 0.5602467656135559 | 0.56159508228302 | 0.7546875 | 0.696875\n",
      "> 84 | 0.5600805282592773 | 0.5604502558708191 | 0.7515625 | 0.696875\n",
      "> 85 | 0.5599176287651062 | 0.559339165687561 | 0.7515625 | 0.696875\n",
      "> 86 | 0.5597579479217529 | 0.5582606792449951 | 0.7515625 | 0.696875\n",
      "> 87 | 0.5596013069152832 | 0.5572136640548706 | 0.753125 | 0.6984375\n",
      "> 88 | 0.5594477653503418 | 0.5561969876289368 | 0.7515625 | 0.6984375\n",
      "> 89 | 0.5592969655990601 | 0.555209755897522 | 0.7546875 | 0.6984375\n",
      "> 90 | 0.5591490268707275 | 0.5542508959770203 | 0.7546875 | 0.6984375\n",
      "> 91 | 0.5590037107467651 | 0.5533194541931152 | 0.7546875 | 0.6984375\n",
      "> 92 | 0.5588609576225281 | 0.55241459608078 | 0.753125 | 0.6984375\n",
      "> 93 | 0.5587207078933716 | 0.5515353679656982 | 0.753125 | 0.696875\n",
      "> 94 | 0.5585827827453613 | 0.5506808757781982 | 0.753125 | 0.696875\n",
      "> 95 | 0.5584472417831421 | 0.5498504042625427 | 0.753125 | 0.6953125\n",
      "> 96 | 0.5583138465881348 | 0.5490431189537048 | 0.753125 | 0.6953125\n",
      "> 97 | 0.5581825971603394 | 0.5482582449913025 | 0.7546875 | 0.6953125\n",
      "> 98 | 0.5580534934997559 | 0.5474951267242432 | 0.7515625 | 0.69375\n",
      "> 99 | 0.5579262971878052 | 0.5467529892921448 | 0.7515625 | 0.69375\n",
      "> 100 | 0.5578011274337769 | 0.5460311770439148 | 0.7515625 | 0.69375\n",
      "> Evaluation\n",
      "> Class Acc = 0.71875\n",
      "> Adv Acc = 0.71875\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8697704672813416 | 0.9046723134815693 | 0.9318936839699745\n",
      "> Confusion Matrix \n",
      "TN: 30.0 | FP: 57.0 \n",
      "FN: 15.0 | TP: 154.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 15.0 | FP: 21.0 \n",
      "FN: 6.0 | TP: 37.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 15.0 | FP: 36.0 \n",
      "FN: 9.0 | TP: 117.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6222320795059204 | 0.9128239750862122 | 0.7078125 | 0.309375\n",
      "> 2 | 0.6177321672439575 | 0.9021185040473938 | 0.7078125 | 0.309375\n",
      "> 3 | 0.6130355000495911 | 0.8914653062820435 | 0.7078125 | 0.309375\n",
      "> 4 | 0.6084499359130859 | 0.8810839056968689 | 0.7078125 | 0.309375\n",
      "> 5 | 0.6040786504745483 | 0.8710536956787109 | 0.7078125 | 0.309375\n",
      "> 6 | 0.599938154220581 | 0.8613865375518799 | 0.7078125 | 0.309375\n",
      "> 7 | 0.5960164070129395 | 0.8520705103874207 | 0.7078125 | 0.309375\n",
      "> 8 | 0.5922946929931641 | 0.8430889844894409 | 0.7078125 | 0.309375\n",
      "> 9 | 0.5887550711631775 | 0.8344265222549438 | 0.7078125 | 0.309375\n",
      "> 10 | 0.5853813886642456 | 0.8260704874992371 | 0.7078125 | 0.309375\n",
      "> 11 | 0.582160234451294 | 0.8180102109909058 | 0.7078125 | 0.309375\n",
      "> 12 | 0.5790797472000122 | 0.8102368712425232 | 0.7078125 | 0.309375\n",
      "> 13 | 0.5761300325393677 | 0.8027429580688477 | 0.7078125 | 0.309375\n",
      "> 14 | 0.5733022689819336 | 0.79552161693573 | 0.7078125 | 0.309375\n",
      "> 15 | 0.5705888271331787 | 0.7885664701461792 | 0.7078125 | 0.309375\n",
      "> 16 | 0.5679826736450195 | 0.7818717956542969 | 0.7078125 | 0.309375\n",
      "> 17 | 0.5654776096343994 | 0.7754315733909607 | 0.7078125 | 0.309375\n",
      "> 18 | 0.5630680322647095 | 0.7692402601242065 | 0.7078125 | 0.309375\n",
      "> 19 | 0.5607486963272095 | 0.7632920145988464 | 0.7078125 | 0.309375\n",
      "> 20 | 0.5585147738456726 | 0.7575812339782715 | 0.7109375 | 0.309375\n",
      "> 21 | 0.5563619136810303 | 0.7521021366119385 | 0.7109375 | 0.309375\n",
      "> 22 | 0.554286003112793 | 0.746849000453949 | 0.709375 | 0.309375\n",
      "> 23 | 0.5522831678390503 | 0.7418159246444702 | 0.709375 | 0.309375\n",
      "> 24 | 0.5503499507904053 | 0.7369970083236694 | 0.7109375 | 0.309375\n",
      "> 25 | 0.5484828948974609 | 0.7323864698410034 | 0.7125 | 0.309375\n",
      "> 26 | 0.5466788411140442 | 0.7279783487319946 | 0.7140625 | 0.309375\n",
      "> 27 | 0.544934868812561 | 0.7237666845321655 | 0.715625 | 0.309375\n",
      "> 28 | 0.5432482361793518 | 0.7197455167770386 | 0.7140625 | 0.309375\n",
      "> 29 | 0.5416163206100464 | 0.7159090042114258 | 0.715625 | 0.309375\n",
      "> 30 | 0.5400364995002747 | 0.7122511863708496 | 0.715625 | 0.315625\n",
      "> 31 | 0.5385066270828247 | 0.7087662220001221 | 0.715625 | 0.3328125\n",
      "> 32 | 0.5370243787765503 | 0.7054481506347656 | 0.715625 | 0.346875\n",
      "> 33 | 0.535587728023529 | 0.7022913098335266 | 0.7203125 | 0.365625\n",
      "> 34 | 0.5341946482658386 | 0.6992900371551514 | 0.721875 | 0.384375\n",
      "> 35 | 0.5328432321548462 | 0.6964386701583862 | 0.721875 | 0.4359375\n",
      "> 36 | 0.531531810760498 | 0.6937316656112671 | 0.725 | 0.4734375\n",
      "> 37 | 0.5302585959434509 | 0.6911634206771851 | 0.7359375 | 0.5140625\n",
      "> 38 | 0.5290220379829407 | 0.6887288093566895 | 0.734375 | 0.5609375\n",
      "> 39 | 0.5278206467628479 | 0.68642258644104 | 0.73125 | 0.5875\n",
      "> 40 | 0.5266528129577637 | 0.6842395067214966 | 0.7265625 | 0.6140625\n",
      "> 41 | 0.5255174040794373 | 0.6821746230125427 | 0.725 | 0.63125\n",
      "> 42 | 0.524412989616394 | 0.6802229881286621 | 0.725 | 0.640625\n",
      "> 43 | 0.5233383178710938 | 0.678380012512207 | 0.725 | 0.653125\n",
      "> 44 | 0.5222923159599304 | 0.6766409873962402 | 0.7265625 | 0.665625\n",
      "> 45 | 0.5212737917900085 | 0.6750013828277588 | 0.7296875 | 0.6796875\n",
      "> 46 | 0.5202816724777222 | 0.6734569072723389 | 0.7296875 | 0.678125\n",
      "> 47 | 0.5193148851394653 | 0.6720033288002014 | 0.7296875 | 0.68125\n",
      "> 48 | 0.5183725953102112 | 0.6706366539001465 | 0.7359375 | 0.6828125\n",
      "> 49 | 0.5174537897109985 | 0.6693527698516846 | 0.7359375 | 0.6890625\n",
      "> 50 | 0.5165576934814453 | 0.6681479215621948 | 0.7390625 | 0.7\n",
      "> 51 | 0.5156832933425903 | 0.6670185327529907 | 0.740625 | 0.7078125\n",
      "> 52 | 0.5148299932479858 | 0.6659609079360962 | 0.7375 | 0.70625\n",
      "> 53 | 0.5139968395233154 | 0.6649718284606934 | 0.7375 | 0.709375\n",
      "> 54 | 0.5131832361221313 | 0.6640477776527405 | 0.7375 | 0.709375\n",
      "> 55 | 0.5123884677886963 | 0.663185715675354 | 0.7375 | 0.7125\n",
      "> 56 | 0.5116117596626282 | 0.6623824834823608 | 0.7375 | 0.7140625\n",
      "> 57 | 0.5108526349067688 | 0.6616353988647461 | 0.7375 | 0.7109375\n",
      "> 58 | 0.5101103782653809 | 0.6609413623809814 | 0.7375 | 0.709375\n",
      "> 59 | 0.5093843936920166 | 0.6602978706359863 | 0.7359375 | 0.709375\n",
      "> 60 | 0.5086742639541626 | 0.6597023010253906 | 0.7375 | 0.7109375\n",
      "> 61 | 0.5079792737960815 | 0.6591520309448242 | 0.7375 | 0.70625\n",
      "> 62 | 0.5072990655899048 | 0.6586447954177856 | 0.740625 | 0.70625\n",
      "> 63 | 0.5066330432891846 | 0.6581783890724182 | 0.74375 | 0.70625\n",
      "> 64 | 0.5059807300567627 | 0.6577504873275757 | 0.7453125 | 0.7046875\n",
      "> 65 | 0.5053418278694153 | 0.6573590636253357 | 0.7453125 | 0.703125\n",
      "> 66 | 0.5047158002853394 | 0.6570020914077759 | 0.746875 | 0.7046875\n",
      "> 67 | 0.5041021108627319 | 0.6566777229309082 | 0.7453125 | 0.7046875\n",
      "> 68 | 0.5035006999969482 | 0.6563839912414551 | 0.746875 | 0.7\n",
      "> 69 | 0.502910852432251 | 0.6561193466186523 | 0.746875 | 0.6953125\n",
      "> 70 | 0.502332329750061 | 0.655881941318512 | 0.7453125 | 0.69375\n",
      "> 71 | 0.5017647743225098 | 0.6556702852249146 | 0.7453125 | 0.69375\n",
      "> 72 | 0.5012078881263733 | 0.655482828617096 | 0.746875 | 0.69375\n",
      "> 73 | 0.500661313533783 | 0.6553181409835815 | 0.746875 | 0.69375\n",
      "> 74 | 0.5001247525215149 | 0.655174732208252 | 0.746875 | 0.6953125\n",
      "> 75 | 0.49959784746170044 | 0.6550513505935669 | 0.746875 | 0.6984375\n",
      "> 76 | 0.49908044934272766 | 0.6549468636512756 | 0.7484375 | 0.7\n",
      "> 77 | 0.4985722005367279 | 0.6548599004745483 | 0.75 | 0.7\n",
      "> 78 | 0.4980727732181549 | 0.6547893285751343 | 0.75 | 0.696875\n",
      "> 79 | 0.4975820481777191 | 0.654734194278717 | 0.75 | 0.6953125\n",
      "> 80 | 0.49709972739219666 | 0.6546933054924011 | 0.75 | 0.69375\n",
      "> 81 | 0.49662551283836365 | 0.6546658277511597 | 0.7515625 | 0.69375\n",
      "> 82 | 0.49615925550460815 | 0.6546506285667419 | 0.7515625 | 0.69375\n",
      "> 83 | 0.49570074677467346 | 0.6546469926834106 | 0.753125 | 0.69375\n",
      "> 84 | 0.49524974822998047 | 0.6546540856361389 | 0.753125 | 0.69375\n",
      "> 85 | 0.4948060214519501 | 0.6546710729598999 | 0.7546875 | 0.69375\n",
      "> 86 | 0.4943694472312927 | 0.6546971201896667 | 0.7546875 | 0.69375\n",
      "> 87 | 0.4939398467540741 | 0.6547315120697021 | 0.75625 | 0.6953125\n",
      "> 88 | 0.4935169517993927 | 0.6547737121582031 | 0.75625 | 0.69375\n",
      "> 89 | 0.49310067296028137 | 0.654822826385498 | 0.7546875 | 0.69375\n",
      "> 90 | 0.4926908314228058 | 0.654878556728363 | 0.75625 | 0.69375\n",
      "> 91 | 0.492287278175354 | 0.654940128326416 | 0.75625 | 0.69375\n",
      "> 92 | 0.4918898046016693 | 0.655007004737854 | 0.75625 | 0.69375\n",
      "> 93 | 0.49149829149246216 | 0.6550787091255188 | 0.7578125 | 0.69375\n",
      "> 94 | 0.4911126494407654 | 0.6551547646522522 | 0.7578125 | 0.69375\n",
      "> 95 | 0.49073269963264465 | 0.655234694480896 | 0.7578125 | 0.69375\n",
      "> 96 | 0.4903583228588104 | 0.655318021774292 | 0.759375 | 0.69375\n",
      "> 97 | 0.48998939990997314 | 0.6554044485092163 | 0.7578125 | 0.69375\n",
      "> 98 | 0.4896257519721985 | 0.6554934978485107 | 0.7625 | 0.69375\n",
      "> 99 | 0.48926734924316406 | 0.6555848121643066 | 0.7625 | 0.69375\n",
      "> 100 | 0.48891401290893555 | 0.6556781530380249 | 0.7609375 | 0.69375\n",
      "> Evaluation\n",
      "> Class Acc = 0.7109375\n",
      "> Adv Acc = 0.7109375\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8936738967895508 | 0.856992993503809 | 0.9499999955296516\n",
      "> Confusion Matrix \n",
      "TN: 18.0 | FP: 56.0 \n",
      "FN: 18.0 | TP: 164.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 9.0 | FP: 13.0 \n",
      "FN: 7.0 | TP: 45.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 9.0 | FP: 43.0 \n",
      "FN: 11.0 | TP: 119.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.5169521570205688 | 0.9438004493713379 | 0.6984375 | 0.3046875\n",
      "> 2 | 0.5161983966827393 | 0.9321804046630859 | 0.6984375 | 0.3046875\n",
      "> 3 | 0.5149251222610474 | 0.9205429553985596 | 0.6984375 | 0.3046875\n",
      "> 4 | 0.5134008526802063 | 0.9091485738754272 | 0.6984375 | 0.3046875\n",
      "> 5 | 0.511740505695343 | 0.8980904817581177 | 0.6984375 | 0.3046875\n",
      "> 6 | 0.509998083114624 | 0.8873839378356934 | 0.6984375 | 0.3046875\n",
      "> 7 | 0.5082051753997803 | 0.877017617225647 | 0.6984375 | 0.3046875\n",
      "> 8 | 0.5063840746879578 | 0.8669752478599548 | 0.6984375 | 0.3046875\n",
      "> 9 | 0.5045522451400757 | 0.8572423458099365 | 0.6984375 | 0.3046875\n",
      "> 10 | 0.5027239918708801 | 0.8478070497512817 | 0.6984375 | 0.3046875\n",
      "> 11 | 0.5009106993675232 | 0.8386605381965637 | 0.6984375 | 0.3046875\n",
      "> 12 | 0.4991215467453003 | 0.8297958374023438 | 0.6984375 | 0.3046875\n",
      "> 13 | 0.49736371636390686 | 0.8212070465087891 | 0.6984375 | 0.3046875\n",
      "> 14 | 0.495642751455307 | 0.8128893375396729 | 0.6984375 | 0.3046875\n",
      "> 15 | 0.49396267533302307 | 0.8048383593559265 | 0.6984375 | 0.3046875\n",
      "> 16 | 0.49232637882232666 | 0.7970497012138367 | 0.6984375 | 0.3046875\n",
      "> 17 | 0.49073588848114014 | 0.7895190715789795 | 0.6984375 | 0.3046875\n",
      "> 18 | 0.48919230699539185 | 0.7822422385215759 | 0.6984375 | 0.3046875\n",
      "> 19 | 0.48769611120224 | 0.7752146124839783 | 0.6984375 | 0.3046875\n",
      "> 20 | 0.4862474203109741 | 0.768431544303894 | 0.7015625 | 0.3046875\n",
      "> 21 | 0.4848458766937256 | 0.7618881464004517 | 0.7046875 | 0.3046875\n",
      "> 22 | 0.4834907650947571 | 0.7555793523788452 | 0.7046875 | 0.3046875\n",
      "> 23 | 0.482181191444397 | 0.7494999766349792 | 0.7046875 | 0.3046875\n",
      "> 24 | 0.4809161424636841 | 0.7436445951461792 | 0.70625 | 0.3046875\n",
      "> 25 | 0.4796944260597229 | 0.738007664680481 | 0.7078125 | 0.3046875\n",
      "> 26 | 0.4785146415233612 | 0.7325837016105652 | 0.7125 | 0.3046875\n",
      "> 27 | 0.4773756265640259 | 0.7273667454719543 | 0.7125 | 0.3046875\n",
      "> 28 | 0.4762759804725647 | 0.7223511934280396 | 0.715625 | 0.3046875\n",
      "> 29 | 0.4752143621444702 | 0.7175310850143433 | 0.71875 | 0.3046875\n",
      "> 30 | 0.4741893708705902 | 0.712900698184967 | 0.7203125 | 0.30625\n",
      "> 31 | 0.47319966554641724 | 0.7084542512893677 | 0.725 | 0.3234375\n",
      "> 32 | 0.4722439646720886 | 0.7041858434677124 | 0.7203125 | 0.3484375\n",
      "> 33 | 0.4713209867477417 | 0.7000897526741028 | 0.7171875 | 0.3953125\n",
      "> 34 | 0.47042950987815857 | 0.6961603164672852 | 0.7203125 | 0.45\n",
      "> 35 | 0.46956831216812134 | 0.6923918724060059 | 0.721875 | 0.5046875\n",
      "> 36 | 0.4687362015247345 | 0.688778817653656 | 0.721875 | 0.5359375\n",
      "> 37 | 0.4679321050643921 | 0.6853157877922058 | 0.725 | 0.58125\n",
      "> 38 | 0.46715497970581055 | 0.6819972991943359 | 0.7265625 | 0.603125\n",
      "> 39 | 0.46640369296073914 | 0.6788182258605957 | 0.7234375 | 0.628125\n",
      "> 40 | 0.4656773805618286 | 0.6757733821868896 | 0.725 | 0.6484375\n",
      "> 41 | 0.4649750590324402 | 0.6728577613830566 | 0.728125 | 0.6703125\n",
      "> 42 | 0.46429577469825745 | 0.6700663566589355 | 0.728125 | 0.6875\n",
      "> 43 | 0.4636387228965759 | 0.6673943996429443 | 0.7296875 | 0.6921875\n",
      "> 44 | 0.46300309896469116 | 0.6648373603820801 | 0.73125 | 0.696875\n",
      "> 45 | 0.4623880088329315 | 0.6623905301094055 | 0.73125 | 0.6984375\n",
      "> 46 | 0.46179282665252686 | 0.660049557685852 | 0.73125 | 0.703125\n",
      "> 47 | 0.4612167775630951 | 0.6578103303909302 | 0.73125 | 0.6984375\n",
      "> 48 | 0.4606591761112213 | 0.6556684970855713 | 0.7328125 | 0.7125\n",
      "> 49 | 0.460119366645813 | 0.653620183467865 | 0.734375 | 0.7140625\n",
      "> 50 | 0.45959681272506714 | 0.6516613960266113 | 0.7359375 | 0.7140625\n",
      "> 51 | 0.45909079909324646 | 0.6497883796691895 | 0.740625 | 0.7203125\n",
      "> 52 | 0.45860081911087036 | 0.6479975581169128 | 0.7390625 | 0.7234375\n",
      "> 53 | 0.45812636613845825 | 0.646285355091095 | 0.740625 | 0.7234375\n",
      "> 54 | 0.4576668441295624 | 0.6446484327316284 | 0.74375 | 0.7234375\n",
      "> 55 | 0.45722177624702454 | 0.6430834531784058 | 0.7453125 | 0.7265625\n",
      "> 56 | 0.4567907452583313 | 0.6415873169898987 | 0.746875 | 0.7265625\n",
      "> 57 | 0.45637327432632446 | 0.6401569843292236 | 0.7453125 | 0.725\n",
      "> 58 | 0.4559689164161682 | 0.6387894749641418 | 0.7453125 | 0.7234375\n",
      "> 59 | 0.4555772542953491 | 0.6374820470809937 | 0.7453125 | 0.725\n",
      "> 60 | 0.45519793033599854 | 0.6362318992614746 | 0.7453125 | 0.7234375\n",
      "> 61 | 0.45483046770095825 | 0.6350364089012146 | 0.7453125 | 0.721875\n",
      "> 62 | 0.45447462797164917 | 0.6338931322097778 | 0.746875 | 0.721875\n",
      "> 63 | 0.45412999391555786 | 0.6327997446060181 | 0.7484375 | 0.7234375\n",
      "> 64 | 0.4537962079048157 | 0.6317537426948547 | 0.75 | 0.725\n",
      "> 65 | 0.45347297191619873 | 0.6307530999183655 | 0.75 | 0.7265625\n",
      "> 66 | 0.45316004753112793 | 0.6297955513000488 | 0.75 | 0.725\n",
      "> 67 | 0.4528570771217346 | 0.6288790702819824 | 0.75 | 0.7265625\n",
      "> 68 | 0.4525637626647949 | 0.6280016899108887 | 0.753125 | 0.725\n",
      "> 69 | 0.45227980613708496 | 0.6271615624427795 | 0.753125 | 0.7265625\n",
      "> 70 | 0.4520050287246704 | 0.6263568997383118 | 0.7515625 | 0.728125\n",
      "> 71 | 0.4517391324043274 | 0.6255860328674316 | 0.7515625 | 0.728125\n",
      "> 72 | 0.4514818787574768 | 0.6248471736907959 | 0.7515625 | 0.7265625\n",
      "> 73 | 0.45123302936553955 | 0.6241389513015747 | 0.75 | 0.7265625\n",
      "> 74 | 0.4509923458099365 | 0.6234596967697144 | 0.75 | 0.7265625\n",
      "> 75 | 0.450759619474411 | 0.6228080987930298 | 0.75 | 0.725\n",
      "> 76 | 0.4505346417427063 | 0.6221826076507568 | 0.75 | 0.725\n",
      "> 77 | 0.4503172039985657 | 0.6215821504592896 | 0.75 | 0.728125\n",
      "> 78 | 0.4501070976257324 | 0.6210052967071533 | 0.75 | 0.728125\n",
      "> 79 | 0.44990411400794983 | 0.6204508543014526 | 0.7484375 | 0.728125\n",
      "> 80 | 0.44970810413360596 | 0.6199177503585815 | 0.7484375 | 0.728125\n",
      "> 81 | 0.44951894879341125 | 0.6194049119949341 | 0.7484375 | 0.728125\n",
      "> 82 | 0.44933629035949707 | 0.6189113259315491 | 0.7484375 | 0.728125\n",
      "> 83 | 0.4491601884365082 | 0.6184359192848206 | 0.75 | 0.728125\n",
      "> 84 | 0.4489903151988983 | 0.6179777383804321 | 0.75 | 0.728125\n",
      "> 85 | 0.4488265812397003 | 0.6175360679626465 | 0.75 | 0.728125\n",
      "> 86 | 0.44866877794265747 | 0.6171098947525024 | 0.7515625 | 0.728125\n",
      "> 87 | 0.4485167860984802 | 0.6166983842849731 | 0.75 | 0.728125\n",
      "> 88 | 0.4483705163002014 | 0.6163009405136108 | 0.7515625 | 0.728125\n",
      "> 89 | 0.4482297897338867 | 0.6159166693687439 | 0.75 | 0.728125\n",
      "> 90 | 0.4480944275856018 | 0.6155449151992798 | 0.7515625 | 0.728125\n",
      "> 91 | 0.44796431064605713 | 0.6151850819587708 | 0.75 | 0.728125\n",
      "> 92 | 0.4478394091129303 | 0.6148364543914795 | 0.75 | 0.728125\n",
      "> 93 | 0.44771939516067505 | 0.614498496055603 | 0.7484375 | 0.728125\n",
      "> 94 | 0.44760435819625854 | 0.6141706705093384 | 0.75 | 0.728125\n",
      "> 95 | 0.4474940896034241 | 0.6138523817062378 | 0.7484375 | 0.7265625\n",
      "> 96 | 0.4473884403705597 | 0.6135430335998535 | 0.746875 | 0.7265625\n",
      "> 97 | 0.44728732109069824 | 0.6132423281669617 | 0.746875 | 0.7265625\n",
      "> 98 | 0.44719067215919495 | 0.6129497289657593 | 0.746875 | 0.7265625\n",
      "> 99 | 0.4470983147621155 | 0.6126646995544434 | 0.7484375 | 0.7265625\n",
      "> 100 | 0.4470101594924927 | 0.6123868227005005 | 0.7484375 | 0.728125\n",
      "> Evaluation\n",
      "> Class Acc = 0.71875\n",
      "> Adv Acc = 0.71875\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.874643087387085 | 0.8420146442949772 | 0.9340292885899544\n",
      "> Confusion Matrix \n",
      "TN: 23.0 | FP: 55.0 \n",
      "FN: 17.0 | TP: 161.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 12.0 | FP: 14.0 \n",
      "FN: 8.0 | TP: 49.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 11.0 | FP: 41.0 \n",
      "FN: 9.0 | TP: 112.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6509883403778076 | 1.0803430080413818 | 0.690625 | 0.3109375\n",
      "> 2 | 0.6439776420593262 | 1.0647051334381104 | 0.690625 | 0.3109375\n",
      "> 3 | 0.63686603307724 | 1.0490233898162842 | 0.690625 | 0.3109375\n",
      "> 4 | 0.630139946937561 | 1.0336596965789795 | 0.690625 | 0.3109375\n",
      "> 5 | 0.6239291429519653 | 1.018721103668213 | 0.690625 | 0.3109375\n",
      "> 6 | 0.6182135343551636 | 1.0042011737823486 | 0.690625 | 0.3109375\n",
      "> 7 | 0.6129316687583923 | 0.9900616407394409 | 0.690625 | 0.3109375\n",
      "> 8 | 0.6080204248428345 | 0.9762665033340454 | 0.690625 | 0.3109375\n",
      "> 9 | 0.6034260392189026 | 0.962790310382843 | 0.690625 | 0.3109375\n",
      "> 10 | 0.599105715751648 | 0.9496175646781921 | 0.690625 | 0.3109375\n",
      "> 11 | 0.5950251817703247 | 0.9367402791976929 | 0.690625 | 0.3109375\n",
      "> 12 | 0.5911576747894287 | 0.9241552948951721 | 0.690625 | 0.3109375\n",
      "> 13 | 0.5874814987182617 | 0.9118620753288269 | 0.690625 | 0.3109375\n",
      "> 14 | 0.5839788913726807 | 0.8998614549636841 | 0.690625 | 0.3109375\n",
      "> 15 | 0.5806351900100708 | 0.8881545066833496 | 0.690625 | 0.3109375\n",
      "> 16 | 0.5774381756782532 | 0.8767422437667847 | 0.690625 | 0.3109375\n",
      "> 17 | 0.5743772387504578 | 0.8656251430511475 | 0.6921875 | 0.3109375\n",
      "> 18 | 0.5714432001113892 | 0.8548029661178589 | 0.6921875 | 0.3109375\n",
      "> 19 | 0.5686280727386475 | 0.8442747592926025 | 0.6921875 | 0.3109375\n",
      "> 20 | 0.5659246444702148 | 0.8340389728546143 | 0.69375 | 0.3109375\n",
      "> 21 | 0.5633265376091003 | 0.8240933418273926 | 0.69375 | 0.3109375\n",
      "> 22 | 0.5608280301094055 | 0.8144348859786987 | 0.69375 | 0.3109375\n",
      "> 23 | 0.558423638343811 | 0.8050602674484253 | 0.69375 | 0.3109375\n",
      "> 24 | 0.5561085343360901 | 0.7959654331207275 | 0.6953125 | 0.3109375\n",
      "> 25 | 0.5538783073425293 | 0.7871459722518921 | 0.7 | 0.3109375\n",
      "> 26 | 0.5517286062240601 | 0.7785972356796265 | 0.7015625 | 0.3109375\n",
      "> 27 | 0.5496556758880615 | 0.7703142166137695 | 0.7015625 | 0.3109375\n",
      "> 28 | 0.5476558208465576 | 0.7622914910316467 | 0.703125 | 0.3109375\n",
      "> 29 | 0.5457257032394409 | 0.754523515701294 | 0.703125 | 0.3109375\n",
      "> 30 | 0.5438620448112488 | 0.7470047473907471 | 0.703125 | 0.3140625\n",
      "> 31 | 0.5420618653297424 | 0.7397291660308838 | 0.7078125 | 0.3234375\n",
      "> 32 | 0.5403223633766174 | 0.7326909303665161 | 0.709375 | 0.328125\n",
      "> 33 | 0.5386408567428589 | 0.7258840203285217 | 0.7125 | 0.3421875\n",
      "> 34 | 0.5370148420333862 | 0.7193024158477783 | 0.715625 | 0.371875\n",
      "> 35 | 0.5354418754577637 | 0.7129399180412292 | 0.709375 | 0.4125\n",
      "> 36 | 0.5339198112487793 | 0.7067906260490417 | 0.709375 | 0.4578125\n",
      "> 37 | 0.5324465036392212 | 0.700848400592804 | 0.7171875 | 0.490625\n",
      "> 38 | 0.5310198068618774 | 0.6951072216033936 | 0.7203125 | 0.5015625\n",
      "> 39 | 0.5296379923820496 | 0.6895613670349121 | 0.7234375 | 0.528125\n",
      "> 40 | 0.52829909324646 | 0.6842045783996582 | 0.725 | 0.5609375\n",
      "> 41 | 0.5270013809204102 | 0.6790313720703125 | 0.725 | 0.59375\n",
      "> 42 | 0.5257432460784912 | 0.674035906791687 | 0.728125 | 0.6140625\n",
      "> 43 | 0.5245231986045837 | 0.6692125797271729 | 0.73125 | 0.6203125\n",
      "> 44 | 0.5233396291732788 | 0.6645559072494507 | 0.73125 | 0.634375\n",
      "> 45 | 0.5221911668777466 | 0.660060465335846 | 0.7328125 | 0.65\n",
      "> 46 | 0.5210764408111572 | 0.6557210683822632 | 0.7328125 | 0.6640625\n",
      "> 47 | 0.5199942588806152 | 0.6515323519706726 | 0.7328125 | 0.66875\n",
      "> 48 | 0.518943190574646 | 0.6474893093109131 | 0.7328125 | 0.675\n",
      "> 49 | 0.5179222822189331 | 0.6435871124267578 | 0.7328125 | 0.684375\n",
      "> 50 | 0.516930341720581 | 0.63982093334198 | 0.73125 | 0.68125\n",
      "> 51 | 0.5159661769866943 | 0.6361860632896423 | 0.73125 | 0.6859375\n",
      "> 52 | 0.5150288939476013 | 0.6326779127120972 | 0.7296875 | 0.6890625\n",
      "> 53 | 0.5141174793243408 | 0.6292921304702759 | 0.73125 | 0.690625\n",
      "> 54 | 0.5132309198379517 | 0.6260243654251099 | 0.7296875 | 0.696875\n",
      "> 55 | 0.5123685002326965 | 0.6228704452514648 | 0.73125 | 0.6953125\n",
      "> 56 | 0.5115293264389038 | 0.6198264360427856 | 0.7296875 | 0.6953125\n",
      "> 57 | 0.5107125043869019 | 0.6168882846832275 | 0.73125 | 0.6984375\n",
      "> 58 | 0.5099171996116638 | 0.6140521764755249 | 0.7328125 | 0.7015625\n",
      "> 59 | 0.5091428160667419 | 0.6113145351409912 | 0.7328125 | 0.703125\n",
      "> 60 | 0.5083885788917542 | 0.6086717844009399 | 0.7375 | 0.7015625\n",
      "> 61 | 0.5076537728309631 | 0.6061203479766846 | 0.7375 | 0.7015625\n",
      "> 62 | 0.5069377422332764 | 0.603657066822052 | 0.7375 | 0.7\n",
      "> 63 | 0.5062398910522461 | 0.60127854347229 | 0.7359375 | 0.7046875\n",
      "> 64 | 0.5055596828460693 | 0.5989818572998047 | 0.734375 | 0.703125\n",
      "> 65 | 0.5048964023590088 | 0.5967639684677124 | 0.7390625 | 0.7015625\n",
      "> 66 | 0.5042495131492615 | 0.5946217775344849 | 0.740625 | 0.703125\n",
      "> 67 | 0.503618597984314 | 0.5925527811050415 | 0.7421875 | 0.703125\n",
      "> 68 | 0.5030030608177185 | 0.5905541181564331 | 0.74375 | 0.7\n",
      "> 69 | 0.5024023652076721 | 0.5886231660842896 | 0.74375 | 0.6984375\n",
      "> 70 | 0.5018161535263062 | 0.5867575407028198 | 0.740625 | 0.7\n",
      "> 71 | 0.5012439489364624 | 0.5849547386169434 | 0.7421875 | 0.7\n",
      "> 72 | 0.5006852149963379 | 0.5832124352455139 | 0.74375 | 0.7\n",
      "> 73 | 0.5001397132873535 | 0.5815284848213196 | 0.74375 | 0.7015625\n",
      "> 74 | 0.4996068477630615 | 0.5799006223678589 | 0.74375 | 0.7\n",
      "> 75 | 0.4990864396095276 | 0.5783268213272095 | 0.74375 | 0.7\n",
      "> 76 | 0.49857795238494873 | 0.5768051147460938 | 0.746875 | 0.6984375\n",
      "> 77 | 0.49808117747306824 | 0.5753335356712341 | 0.746875 | 0.6984375\n",
      "> 78 | 0.4975956082344055 | 0.5739102959632874 | 0.7453125 | 0.6953125\n",
      "> 79 | 0.49712103605270386 | 0.5725334882736206 | 0.7453125 | 0.6953125\n",
      "> 80 | 0.4966570734977722 | 0.5712015628814697 | 0.74375 | 0.6953125\n",
      "> 81 | 0.4962034821510315 | 0.5699127912521362 | 0.746875 | 0.69375\n",
      "> 82 | 0.49575987458229065 | 0.5686657428741455 | 0.746875 | 0.6953125\n",
      "> 83 | 0.49532613158226013 | 0.5674586296081543 | 0.746875 | 0.6953125\n",
      "> 84 | 0.49490177631378174 | 0.5662901401519775 | 0.7484375 | 0.69375\n",
      "> 85 | 0.4944867193698883 | 0.5651589632034302 | 0.7484375 | 0.69375\n",
      "> 86 | 0.4940806031227112 | 0.5640636682510376 | 0.7484375 | 0.69375\n",
      "> 87 | 0.49368321895599365 | 0.5630028247833252 | 0.7515625 | 0.69375\n",
      "> 88 | 0.4932943284511566 | 0.5619754195213318 | 0.753125 | 0.69375\n",
      "> 89 | 0.49291372299194336 | 0.5609802007675171 | 0.753125 | 0.69375\n",
      "> 90 | 0.4925411641597748 | 0.560015857219696 | 0.753125 | 0.6921875\n",
      "> 91 | 0.492176353931427 | 0.5590814352035522 | 0.753125 | 0.6921875\n",
      "> 92 | 0.49181926250457764 | 0.5581758618354797 | 0.753125 | 0.6921875\n",
      "> 93 | 0.4914695620536804 | 0.5572981238365173 | 0.7546875 | 0.6921875\n",
      "> 94 | 0.4911271035671234 | 0.5564472675323486 | 0.75625 | 0.6921875\n",
      "> 95 | 0.4907916784286499 | 0.5556222200393677 | 0.75625 | 0.6921875\n",
      "> 96 | 0.4904631972312927 | 0.5548222064971924 | 0.759375 | 0.6921875\n",
      "> 97 | 0.490141361951828 | 0.5540462732315063 | 0.759375 | 0.6921875\n",
      "> 98 | 0.48982611298561096 | 0.5532935857772827 | 0.7609375 | 0.6921875\n",
      "> 99 | 0.4895171821117401 | 0.552563488483429 | 0.7609375 | 0.6921875\n",
      "> 100 | 0.4892144799232483 | 0.5518550872802734 | 0.7609375 | 0.6921875\n",
      "> Evaluation\n",
      "> Class Acc = 0.74609375\n",
      "> Adv Acc = 0.74609375\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.952728271484375 | 0.9737232774496078 | 0.9656283557415009\n",
      "> Confusion Matrix \n",
      "TN: 23.0 | FP: 51.0 \n",
      "FN: 14.0 | TP: 168.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 9.0 | FP: 21.0 \n",
      "FN: 5.0 | TP: 44.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 14.0 | FP: 30.0 \n",
      "FN: 9.0 | TP: 124.0\n"
     ]
    }
   ],
   "source": [
    "fairdef = 'EqOdds'\n",
    "\n",
    "for cv_seed in cv_seeds:\n",
    "    x_train, x_test, y_train, y_test, a_train, a_test = train_test_split(\n",
    "        x, y, a, test_size=0.3, random_state=cv_seed)\n",
    "\n",
    "    train_data = Dataset.from_tensor_slices((x_train, y_train, a_train))\n",
    "    train_data = train_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    test_data = Dataset.from_tensor_slices((x_test, y_test, a_test))\n",
    "    test_data = test_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    # train below\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "    \n",
    "    model = FairLogisticRegression(xdim, ydim, adim, batch_size, fairdef)\n",
    "    zhang_train(model, raw_data, train_data, epochs, opt)\n",
    "\n",
    "    Y, A, Y_hat, A_hat = fair_evaluation(model, test_data)\n",
    "    clas_acc, dp, deqodds, deqopp, confusion_matrix, metrics_a0, metrics_a1 = compute_metrics(Y, A, Y_hat, A_hat, adim)\n",
    "\n",
    "    fair_metrics = (dp, deqodds, deqopp)\n",
    "    tradeoff = []\n",
    "    for fair_metric in fair_metrics:\n",
    "        tradeoff.append(compute_tradeoff(clas_acc, fair_metric))\n",
    "\n",
    "    result = ['Zhang4EqOdds', cv_seed, clas_acc, dp, deqodds, deqopp, tradeoff[0], tradeoff[1], tradeoff[2]] + metrics_a0 + metrics_a1\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    del(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhang for Eq Opp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.5919795036315918 | 0.7619445323944092 | 0.6734375 | 0.2984375\n",
      "> 2 | 0.5888176560401917 | 0.7507501244544983 | 0.6734375 | 0.2984375\n",
      "> 3 | 0.5854759216308594 | 0.739605724811554 | 0.6734375 | 0.2984375\n",
      "> 4 | 0.5822166204452515 | 0.7287383079528809 | 0.6734375 | 0.2984375\n",
      "> 5 | 0.5791046619415283 | 0.7182154059410095 | 0.6734375 | 0.2984375\n",
      "> 6 | 0.5761302709579468 | 0.7080291509628296 | 0.6734375 | 0.2984375\n",
      "> 7 | 0.5732675194740295 | 0.6981483697891235 | 0.6734375 | 0.2984375\n",
      "> 8 | 0.5704933404922485 | 0.6885406970977783 | 0.6734375 | 0.2984375\n",
      "> 9 | 0.5677918791770935 | 0.679179310798645 | 0.6734375 | 0.2984375\n",
      "> 10 | 0.5651538372039795 | 0.6700440645217896 | 0.6734375 | 0.2984375\n",
      "> 11 | 0.5625743865966797 | 0.6611207127571106 | 0.6734375 | 0.2984375\n",
      "> 12 | 0.560051679611206 | 0.6523997783660889 | 0.6734375 | 0.2984375\n",
      "> 13 | 0.5575857162475586 | 0.6438751220703125 | 0.6734375 | 0.2984375\n",
      "> 14 | 0.5551770925521851 | 0.6355429887771606 | 0.6734375 | 0.2984375\n",
      "> 15 | 0.5528268814086914 | 0.6274016499519348 | 0.6734375 | 0.2984375\n",
      "> 16 | 0.5505359172821045 | 0.6194499135017395 | 0.6734375 | 0.2984375\n",
      "> 17 | 0.5483046174049377 | 0.6116877198219299 | 0.675 | 0.2984375\n",
      "> 18 | 0.5461333394050598 | 0.6041148900985718 | 0.675 | 0.2984375\n",
      "> 19 | 0.5440219044685364 | 0.5967315435409546 | 0.6765625 | 0.2984375\n",
      "> 20 | 0.5419697761535645 | 0.5895373821258545 | 0.6796875 | 0.2984375\n",
      "> 21 | 0.5399760007858276 | 0.5825321674346924 | 0.6859375 | 0.2984375\n",
      "> 22 | 0.5380395650863647 | 0.575715184211731 | 0.69375 | 0.2984375\n",
      "> 23 | 0.536159098148346 | 0.5690852403640747 | 0.6953125 | 0.2984375\n",
      "> 24 | 0.5343332290649414 | 0.5626411437988281 | 0.6984375 | 0.2984375\n",
      "> 25 | 0.5325602293014526 | 0.5563809871673584 | 0.7015625 | 0.2984375\n",
      "> 26 | 0.5308383703231812 | 0.5503028631210327 | 0.7015625 | 0.2984375\n",
      "> 27 | 0.5291661024093628 | 0.5444043278694153 | 0.70625 | 0.2984375\n",
      "> 28 | 0.5275415778160095 | 0.5386828184127808 | 0.7046875 | 0.2984375\n",
      "> 29 | 0.5259631276130676 | 0.5331352353096008 | 0.7 | 0.3\n",
      "> 30 | 0.5244288444519043 | 0.5277587175369263 | 0.696875 | 0.3\n",
      "> 31 | 0.5229372978210449 | 0.5225497484207153 | 0.7 | 0.30625\n",
      "> 32 | 0.5214866399765015 | 0.5175051093101501 | 0.7078125 | 0.3125\n",
      "> 33 | 0.5200753211975098 | 0.5126210451126099 | 0.709375 | 0.3421875\n",
      "> 34 | 0.5187018513679504 | 0.5078939199447632 | 0.715625 | 0.3625\n",
      "> 35 | 0.5173647403717041 | 0.5033199787139893 | 0.7171875 | 0.3859375\n",
      "> 36 | 0.5160624980926514 | 0.4988953471183777 | 0.7203125 | 0.415625\n",
      "> 37 | 0.5147937536239624 | 0.4946162700653076 | 0.7203125 | 0.434375\n",
      "> 38 | 0.5135571956634521 | 0.4904786944389343 | 0.721875 | 0.4625\n",
      "> 39 | 0.5123516321182251 | 0.4864787459373474 | 0.721875 | 0.5\n",
      "> 40 | 0.511175811290741 | 0.48261260986328125 | 0.7265625 | 0.5109375\n",
      "> 41 | 0.510028600692749 | 0.47887635231018066 | 0.728125 | 0.51875\n",
      "> 42 | 0.5089088678359985 | 0.4752660393714905 | 0.728125 | 0.5375\n",
      "> 43 | 0.5078155994415283 | 0.4717779755592346 | 0.734375 | 0.553125\n",
      "> 44 | 0.506747841835022 | 0.46840834617614746 | 0.7359375 | 0.565625\n",
      "> 45 | 0.5057046413421631 | 0.46515339612960815 | 0.7359375 | 0.5703125\n",
      "> 46 | 0.5046850442886353 | 0.4620095193386078 | 0.734375 | 0.578125\n",
      "> 47 | 0.5036882758140564 | 0.45897307991981506 | 0.7359375 | 0.58125\n",
      "> 48 | 0.5027134418487549 | 0.456040620803833 | 0.7359375 | 0.5828125\n",
      "> 49 | 0.5017597675323486 | 0.4532086253166199 | 0.7375 | 0.596875\n",
      "> 50 | 0.5008265972137451 | 0.4504738450050354 | 0.74375 | 0.6\n",
      "> 51 | 0.4999130964279175 | 0.4478328227996826 | 0.7453125 | 0.596875\n",
      "> 52 | 0.49901872873306274 | 0.4452824592590332 | 0.7453125 | 0.596875\n",
      "> 53 | 0.4981427490711212 | 0.4428195655345917 | 0.74375 | 0.596875\n",
      "> 54 | 0.49728453159332275 | 0.44044119119644165 | 0.746875 | 0.5984375\n",
      "> 55 | 0.49644356966018677 | 0.4381442666053772 | 0.746875 | 0.5984375\n",
      "> 56 | 0.4956192672252655 | 0.43592602014541626 | 0.7484375 | 0.5984375\n",
      "> 57 | 0.49481111764907837 | 0.43378356099128723 | 0.7484375 | 0.603125\n",
      "> 58 | 0.4940185844898224 | 0.4317142367362976 | 0.75 | 0.6046875\n",
      "> 59 | 0.49324119091033936 | 0.4297153949737549 | 0.75 | 0.6046875\n",
      "> 60 | 0.4924784302711487 | 0.4277845025062561 | 0.7484375 | 0.60625\n",
      "> 61 | 0.49172985553741455 | 0.4259191155433655 | 0.7484375 | 0.6109375\n",
      "> 62 | 0.4909951090812683 | 0.4241167902946472 | 0.746875 | 0.6109375\n",
      "> 63 | 0.49027377367019653 | 0.42237532138824463 | 0.746875 | 0.615625\n",
      "> 64 | 0.48956534266471863 | 0.4206923246383667 | 0.746875 | 0.6140625\n",
      "> 65 | 0.4888695478439331 | 0.4190657436847687 | 0.7484375 | 0.6109375\n",
      "> 66 | 0.48818597197532654 | 0.4174934923648834 | 0.7515625 | 0.6125\n",
      "> 67 | 0.48751431703567505 | 0.4159735441207886 | 0.7515625 | 0.6125\n",
      "> 68 | 0.4868541955947876 | 0.4145039916038513 | 0.7515625 | 0.621875\n",
      "> 69 | 0.4862053394317627 | 0.41308289766311646 | 0.7546875 | 0.6234375\n",
      "> 70 | 0.4855673313140869 | 0.4117084741592407 | 0.75625 | 0.625\n",
      "> 71 | 0.4849400222301483 | 0.4103790521621704 | 0.75625 | 0.625\n",
      "> 72 | 0.48432299494743347 | 0.40909284353256226 | 0.75625 | 0.6265625\n",
      "> 73 | 0.48371610045433044 | 0.4078482687473297 | 0.75625 | 0.621875\n",
      "> 74 | 0.48311901092529297 | 0.4066438376903534 | 0.75625 | 0.6234375\n",
      "> 75 | 0.4825313687324524 | 0.40547800064086914 | 0.75625 | 0.634375\n",
      "> 76 | 0.48195308446884155 | 0.40434932708740234 | 0.753125 | 0.6359375\n",
      "> 77 | 0.4813838601112366 | 0.4032564163208008 | 0.753125 | 0.6359375\n",
      "> 78 | 0.48082345724105835 | 0.4021978974342346 | 0.753125 | 0.6390625\n",
      "> 79 | 0.4802716076374054 | 0.4011725187301636 | 0.753125 | 0.640625\n",
      "> 80 | 0.47972819209098816 | 0.40017902851104736 | 0.753125 | 0.6453125\n",
      "> 81 | 0.47919291257858276 | 0.39921629428863525 | 0.753125 | 0.6453125\n",
      "> 82 | 0.47866567969322205 | 0.39828312397003174 | 0.7515625 | 0.646875\n",
      "> 83 | 0.47814616560935974 | 0.3973783850669861 | 0.753125 | 0.6484375\n",
      "> 84 | 0.4776342809200287 | 0.3965010941028595 | 0.7546875 | 0.646875\n",
      "> 85 | 0.4771297574043274 | 0.395650178194046 | 0.7546875 | 0.6453125\n",
      "> 86 | 0.4766325056552887 | 0.39482471346855164 | 0.7578125 | 0.64375\n",
      "> 87 | 0.4761422872543335 | 0.3940237760543823 | 0.7578125 | 0.64375\n",
      "> 88 | 0.47565901279449463 | 0.3932463824748993 | 0.7578125 | 0.64375\n",
      "> 89 | 0.4751824736595154 | 0.3924916684627533 | 0.7578125 | 0.64375\n",
      "> 90 | 0.47471243143081665 | 0.39175891876220703 | 0.75625 | 0.64375\n",
      "> 91 | 0.47424888610839844 | 0.39104723930358887 | 0.75625 | 0.6421875\n",
      "> 92 | 0.47379162907600403 | 0.3903558552265167 | 0.75625 | 0.64375\n",
      "> 93 | 0.4733404517173767 | 0.3896840810775757 | 0.7578125 | 0.64375\n",
      "> 94 | 0.4728953242301941 | 0.38903123140335083 | 0.7578125 | 0.646875\n",
      "> 95 | 0.47245603799819946 | 0.38839656114578247 | 0.7578125 | 0.65\n",
      "> 96 | 0.47202253341674805 | 0.3877794146537781 | 0.7578125 | 0.6515625\n",
      "> 97 | 0.47159451246261597 | 0.38717925548553467 | 0.7578125 | 0.6515625\n",
      "> 98 | 0.4711720645427704 | 0.3865954279899597 | 0.759375 | 0.653125\n",
      "> 99 | 0.4707549214363098 | 0.3860272765159607 | 0.759375 | 0.6546875\n",
      "> 100 | 0.47034305334091187 | 0.38547438383102417 | 0.759375 | 0.6578125\n",
      "> Evaluation\n",
      "> Class Acc = 0.70703125\n",
      "> Adv Acc = 0.70703125\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.7870985269546509 | 0.7208728268742561 | 0.910610094666481\n",
      "> Confusion Matrix \n",
      "TN: 30.0 | FP: 38.0 \n",
      "FN: 37.0 | TP: 151.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 19.0 | FP: 7.0 \n",
      "FN: 15.0 | TP: 43.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 11.0 | FP: 31.0 \n",
      "FN: 22.0 | TP: 108.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6528537273406982 | 0.7271773815155029 | 0.7078125 | 0.3109375\n",
      "> 2 | 0.6480297446250916 | 0.7162047624588013 | 0.7078125 | 0.3109375\n",
      "> 3 | 0.6431070566177368 | 0.705168604850769 | 0.7078125 | 0.3109375\n",
      "> 4 | 0.6384414434432983 | 0.6943001747131348 | 0.7078125 | 0.3109375\n",
      "> 5 | 0.6341344118118286 | 0.6836785078048706 | 0.7078125 | 0.3109375\n",
      "> 6 | 0.6301823854446411 | 0.6733130812644958 | 0.7078125 | 0.3109375\n",
      "> 7 | 0.6265501976013184 | 0.6631911993026733 | 0.7078125 | 0.3109375\n",
      "> 8 | 0.6231990456581116 | 0.6532981395721436 | 0.7078125 | 0.3109375\n",
      "> 9 | 0.6200944185256958 | 0.6436227560043335 | 0.7078125 | 0.3109375\n",
      "> 10 | 0.6172075271606445 | 0.6341580748558044 | 0.7078125 | 0.3109375\n",
      "> 11 | 0.6145144701004028 | 0.6248997449874878 | 0.7078125 | 0.3109375\n",
      "> 12 | 0.6119954586029053 | 0.6158459782600403 | 0.7078125 | 0.3109375\n",
      "> 13 | 0.6096341013908386 | 0.6069955825805664 | 0.7078125 | 0.3109375\n",
      "> 14 | 0.6074162721633911 | 0.5983482599258423 | 0.7078125 | 0.3109375\n",
      "> 15 | 0.6053299307823181 | 0.5899038314819336 | 0.7078125 | 0.3109375\n",
      "> 16 | 0.6033644676208496 | 0.5816618800163269 | 0.7078125 | 0.3109375\n",
      "> 17 | 0.601510763168335 | 0.5736218094825745 | 0.7078125 | 0.3109375\n",
      "> 18 | 0.5997604727745056 | 0.5657827854156494 | 0.7078125 | 0.3109375\n",
      "> 19 | 0.5981061458587646 | 0.5581434965133667 | 0.7078125 | 0.3109375\n",
      "> 20 | 0.5965411067008972 | 0.5507023334503174 | 0.7078125 | 0.3109375\n",
      "> 21 | 0.5950592756271362 | 0.5434574484825134 | 0.7078125 | 0.3109375\n",
      "> 22 | 0.5936551094055176 | 0.5364064574241638 | 0.7078125 | 0.3109375\n",
      "> 23 | 0.5923234820365906 | 0.5295467972755432 | 0.7078125 | 0.3109375\n",
      "> 24 | 0.591059684753418 | 0.5228756666183472 | 0.7109375 | 0.3109375\n",
      "> 25 | 0.5898594260215759 | 0.5163899660110474 | 0.709375 | 0.3109375\n",
      "> 26 | 0.5887186527252197 | 0.5100864171981812 | 0.709375 | 0.3109375\n",
      "> 27 | 0.5876336693763733 | 0.5039617419242859 | 0.7109375 | 0.3109375\n",
      "> 28 | 0.5866011381149292 | 0.49801215529441833 | 0.7109375 | 0.3109375\n",
      "> 29 | 0.5856176614761353 | 0.49223414063453674 | 0.7125 | 0.3109375\n",
      "> 30 | 0.5846803188323975 | 0.4866239130496979 | 0.7125 | 0.3171875\n",
      "> 31 | 0.5837864279747009 | 0.48117756843566895 | 0.7125 | 0.3328125\n",
      "> 32 | 0.5829334259033203 | 0.4758913218975067 | 0.715625 | 0.3453125\n",
      "> 33 | 0.5821186900138855 | 0.470761239528656 | 0.715625 | 0.359375\n",
      "> 34 | 0.5813402533531189 | 0.46578338742256165 | 0.7171875 | 0.378125\n",
      "> 35 | 0.580595850944519 | 0.46095383167266846 | 0.7203125 | 0.403125\n",
      "> 36 | 0.5798835158348083 | 0.4562687277793884 | 0.7203125 | 0.415625\n",
      "> 37 | 0.5792014598846436 | 0.4517241418361664 | 0.7203125 | 0.4484375\n",
      "> 38 | 0.578548014163971 | 0.4473162293434143 | 0.7203125 | 0.475\n",
      "> 39 | 0.5779215097427368 | 0.44304120540618896 | 0.721875 | 0.49375\n",
      "> 40 | 0.577320396900177 | 0.43889522552490234 | 0.7234375 | 0.5203125\n",
      "> 41 | 0.5767433643341064 | 0.4348747134208679 | 0.7234375 | 0.5296875\n",
      "> 42 | 0.5761890411376953 | 0.43097594380378723 | 0.7234375 | 0.5390625\n",
      "> 43 | 0.5756561756134033 | 0.42719539999961853 | 0.728125 | 0.540625\n",
      "> 44 | 0.575143575668335 | 0.4235294759273529 | 0.7296875 | 0.5515625\n",
      "> 45 | 0.5746502876281738 | 0.41997480392456055 | 0.7296875 | 0.5546875\n",
      "> 46 | 0.5741751790046692 | 0.41652801632881165 | 0.73125 | 0.55625\n",
      "> 47 | 0.5737173557281494 | 0.4131857752799988 | 0.73125 | 0.571875\n",
      "> 48 | 0.5732758045196533 | 0.40994489192962646 | 0.7296875 | 0.5828125\n",
      "> 49 | 0.5728497505187988 | 0.40680229663848877 | 0.7296875 | 0.584375\n",
      "> 50 | 0.5724384784698486 | 0.4037548303604126 | 0.7296875 | 0.590625\n",
      "> 51 | 0.5720410943031311 | 0.40079954266548157 | 0.7296875 | 0.5859375\n",
      "> 52 | 0.5716569423675537 | 0.39793360233306885 | 0.73125 | 0.5828125\n",
      "> 53 | 0.5712853670120239 | 0.39515408873558044 | 0.7296875 | 0.5875\n",
      "> 54 | 0.5709257125854492 | 0.39245834946632385 | 0.7328125 | 0.5921875\n",
      "> 55 | 0.5705775022506714 | 0.3898437023162842 | 0.73125 | 0.5984375\n",
      "> 56 | 0.5702400207519531 | 0.3873075246810913 | 0.734375 | 0.6\n",
      "> 57 | 0.5699129104614258 | 0.38484734296798706 | 0.7375 | 0.6046875\n",
      "> 58 | 0.569595456123352 | 0.38246071338653564 | 0.7359375 | 0.6078125\n",
      "> 59 | 0.5692874193191528 | 0.38014528155326843 | 0.7375 | 0.6046875\n",
      "> 60 | 0.5689882040023804 | 0.3778986930847168 | 0.7390625 | 0.60625\n",
      "> 61 | 0.5686975121498108 | 0.3757188320159912 | 0.740625 | 0.6078125\n",
      "> 62 | 0.5684148073196411 | 0.3736034631729126 | 0.7421875 | 0.603125\n",
      "> 63 | 0.568139910697937 | 0.37155061960220337 | 0.740625 | 0.603125\n",
      "> 64 | 0.5678722858428955 | 0.3695581555366516 | 0.7421875 | 0.60625\n",
      "> 65 | 0.5676117539405823 | 0.3676242232322693 | 0.7421875 | 0.60625\n",
      "> 66 | 0.5673578977584839 | 0.3657468855381012 | 0.74375 | 0.609375\n",
      "> 67 | 0.5671104788780212 | 0.3639243245124817 | 0.74375 | 0.6046875\n",
      "> 68 | 0.5668691396713257 | 0.3621547520160675 | 0.74375 | 0.6109375\n",
      "> 69 | 0.5666337013244629 | 0.36043646931648254 | 0.746875 | 0.6109375\n",
      "> 70 | 0.566403865814209 | 0.35876786708831787 | 0.746875 | 0.6109375\n",
      "> 71 | 0.5661795139312744 | 0.35714733600616455 | 0.746875 | 0.609375\n",
      "> 72 | 0.5659602284431458 | 0.35557329654693604 | 0.7453125 | 0.6109375\n",
      "> 73 | 0.5657458901405334 | 0.35404425859451294 | 0.7453125 | 0.6140625\n",
      "> 74 | 0.565536379814148 | 0.35255882143974304 | 0.7453125 | 0.6140625\n",
      "> 75 | 0.5653313398361206 | 0.35111555457115173 | 0.7453125 | 0.6140625\n",
      "> 76 | 0.5651306509971619 | 0.34971314668655396 | 0.746875 | 0.615625\n",
      "> 77 | 0.564934253692627 | 0.34835028648376465 | 0.7484375 | 0.6171875\n",
      "> 78 | 0.564741849899292 | 0.34702569246292114 | 0.7515625 | 0.6171875\n",
      "> 79 | 0.5645533204078674 | 0.34573814272880554 | 0.7515625 | 0.6171875\n",
      "> 80 | 0.564368486404419 | 0.3444864749908447 | 0.7515625 | 0.6171875\n",
      "> 81 | 0.5641872882843018 | 0.34326958656311035 | 0.7515625 | 0.6171875\n",
      "> 82 | 0.5640096068382263 | 0.3420863747596741 | 0.753125 | 0.615625\n",
      "> 83 | 0.5638352632522583 | 0.3409357964992523 | 0.753125 | 0.6140625\n",
      "> 84 | 0.5636640787124634 | 0.33981674909591675 | 0.7546875 | 0.615625\n",
      "> 85 | 0.5634959936141968 | 0.3387283682823181 | 0.7546875 | 0.6125\n",
      "> 86 | 0.5633309483528137 | 0.33766958117485046 | 0.7546875 | 0.6125\n",
      "> 87 | 0.5631687641143799 | 0.33663952350616455 | 0.7546875 | 0.6125\n",
      "> 88 | 0.56300950050354 | 0.33563727140426636 | 0.753125 | 0.6125\n",
      "> 89 | 0.5628527998924255 | 0.3346620798110962 | 0.753125 | 0.6125\n",
      "> 90 | 0.5626988410949707 | 0.33371293544769287 | 0.753125 | 0.615625\n",
      "> 91 | 0.5625473260879517 | 0.3327891528606415 | 0.753125 | 0.61875\n",
      "> 92 | 0.5623982548713684 | 0.33188992738723755 | 0.753125 | 0.61875\n",
      "> 93 | 0.562251627445221 | 0.3310145139694214 | 0.7546875 | 0.61875\n",
      "> 94 | 0.5621073246002197 | 0.3301621973514557 | 0.75625 | 0.61875\n",
      "> 95 | 0.5619651675224304 | 0.32933226227760315 | 0.75625 | 0.621875\n",
      "> 96 | 0.5618252754211426 | 0.32852405309677124 | 0.7546875 | 0.621875\n",
      "> 97 | 0.5616874098777771 | 0.32773691415786743 | 0.7546875 | 0.621875\n",
      "> 98 | 0.5615516901016235 | 0.3269701600074768 | 0.7546875 | 0.6203125\n",
      "> 99 | 0.5614178776741028 | 0.326223224401474 | 0.7546875 | 0.6203125\n",
      "> 100 | 0.5612860321998596 | 0.32549554109573364 | 0.7578125 | 0.6234375\n",
      "> Evaluation\n",
      "> Class Acc = 0.72265625\n",
      "> Adv Acc = 0.72265625\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8894371390342712 | 0.9343175161629915 | 0.9160206653177738\n",
      "> Confusion Matrix \n",
      "TN: 29.0 | FP: 58.0 \n",
      "FN: 13.0 | TP: 156.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 13.0 | FP: 23.0 \n",
      "FN: 6.0 | TP: 37.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 16.0 | FP: 35.0 \n",
      "FN: 7.0 | TP: 119.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.6221537590026855 | 0.6453790068626404 | 0.7078125 | 0.309375\n",
      "> 2 | 0.6176235675811768 | 0.6372734308242798 | 0.7078125 | 0.309375\n",
      "> 3 | 0.6128805875778198 | 0.6292338371276855 | 0.7078125 | 0.309375\n",
      "> 4 | 0.608238935470581 | 0.6213937997817993 | 0.7078125 | 0.309375\n",
      "> 5 | 0.603805422782898 | 0.6137999296188354 | 0.7078125 | 0.309375\n",
      "> 6 | 0.5995980501174927 | 0.6064559817314148 | 0.7078125 | 0.309375\n",
      "> 7 | 0.5956058502197266 | 0.5993513464927673 | 0.7078125 | 0.309375\n",
      "> 8 | 0.5918108820915222 | 0.5924736261367798 | 0.7078125 | 0.309375\n",
      "> 9 | 0.5881953239440918 | 0.5858120322227478 | 0.7078125 | 0.309375\n",
      "> 10 | 0.5847436189651489 | 0.5793584585189819 | 0.7078125 | 0.309375\n",
      "> 11 | 0.5814424157142639 | 0.5731065273284912 | 0.7078125 | 0.309375\n",
      "> 12 | 0.5782804489135742 | 0.5670514106750488 | 0.7078125 | 0.309375\n",
      "> 13 | 0.5752477645874023 | 0.5611891746520996 | 0.7078125 | 0.309375\n",
      "> 14 | 0.5723357796669006 | 0.5555163621902466 | 0.7078125 | 0.309375\n",
      "> 15 | 0.5695369243621826 | 0.5500301718711853 | 0.7078125 | 0.309375\n",
      "> 16 | 0.5668445229530334 | 0.5447277426719666 | 0.7078125 | 0.309375\n",
      "> 17 | 0.5642522573471069 | 0.5396060943603516 | 0.7078125 | 0.309375\n",
      "> 18 | 0.5617547631263733 | 0.5346626043319702 | 0.7078125 | 0.309375\n",
      "> 19 | 0.5593467950820923 | 0.529894232749939 | 0.7078125 | 0.309375\n",
      "> 20 | 0.5570236444473267 | 0.5252978801727295 | 0.709375 | 0.309375\n",
      "> 21 | 0.5547811985015869 | 0.5208703875541687 | 0.7109375 | 0.309375\n",
      "> 22 | 0.5526151657104492 | 0.5166084170341492 | 0.709375 | 0.309375\n",
      "> 23 | 0.5505220293998718 | 0.5125085115432739 | 0.7109375 | 0.309375\n",
      "> 24 | 0.5484981536865234 | 0.508567214012146 | 0.7125 | 0.309375\n",
      "> 25 | 0.5465402603149414 | 0.5047807693481445 | 0.7125 | 0.309375\n",
      "> 26 | 0.5446453094482422 | 0.5011453628540039 | 0.7125 | 0.309375\n",
      "> 27 | 0.5428104400634766 | 0.4976571798324585 | 0.7125 | 0.309375\n",
      "> 28 | 0.5410328507423401 | 0.4943123459815979 | 0.7109375 | 0.309375\n",
      "> 29 | 0.539310097694397 | 0.49110692739486694 | 0.7109375 | 0.309375\n",
      "> 30 | 0.5376396179199219 | 0.48803699016571045 | 0.7125 | 0.3109375\n",
      "> 31 | 0.5360192060470581 | 0.4850984215736389 | 0.7140625 | 0.3234375\n",
      "> 32 | 0.5344467759132385 | 0.48228734731674194 | 0.715625 | 0.340625\n",
      "> 33 | 0.532920241355896 | 0.47959983348846436 | 0.71875 | 0.3515625\n",
      "> 34 | 0.5314376354217529 | 0.4770318269729614 | 0.721875 | 0.365625\n",
      "> 35 | 0.5299971699714661 | 0.4745795726776123 | 0.7265625 | 0.3859375\n",
      "> 36 | 0.5285971164703369 | 0.47223907709121704 | 0.73125 | 0.440625\n",
      "> 37 | 0.5272358655929565 | 0.47000652551651 | 0.7328125 | 0.4796875\n",
      "> 38 | 0.525911808013916 | 0.46787816286087036 | 0.7359375 | 0.5140625\n",
      "> 39 | 0.5246235728263855 | 0.465850293636322 | 0.734375 | 0.54375\n",
      "> 40 | 0.5233696699142456 | 0.46391940116882324 | 0.73125 | 0.5671875\n",
      "> 41 | 0.5221487879753113 | 0.46208178997039795 | 0.728125 | 0.590625\n",
      "> 42 | 0.5209596753120422 | 0.4603339731693268 | 0.7296875 | 0.590625\n",
      "> 43 | 0.5198011994361877 | 0.45867258310317993 | 0.7296875 | 0.603125\n",
      "> 44 | 0.5186721086502075 | 0.45709434151649475 | 0.728125 | 0.60625\n",
      "> 45 | 0.5175713896751404 | 0.4555959701538086 | 0.728125 | 0.6078125\n",
      "> 46 | 0.5164979696273804 | 0.454174280166626 | 0.728125 | 0.6109375\n",
      "> 47 | 0.5154508948326111 | 0.45282623171806335 | 0.73125 | 0.6078125\n",
      "> 48 | 0.5144292116165161 | 0.45154887437820435 | 0.73125 | 0.6125\n",
      "> 49 | 0.5134320259094238 | 0.45033925771713257 | 0.7359375 | 0.615625\n",
      "> 50 | 0.5124584436416626 | 0.44919463992118835 | 0.7375 | 0.6140625\n",
      "> 51 | 0.5115076899528503 | 0.44811221957206726 | 0.7390625 | 0.621875\n",
      "> 52 | 0.510578989982605 | 0.44708940386772156 | 0.740625 | 0.625\n",
      "> 53 | 0.5096716284751892 | 0.4461236596107483 | 0.740625 | 0.6265625\n",
      "> 54 | 0.508784830570221 | 0.4452124536037445 | 0.740625 | 0.6265625\n",
      "> 55 | 0.5079179406166077 | 0.44435346126556396 | 0.7390625 | 0.6265625\n",
      "> 56 | 0.5070703029632568 | 0.4435443580150604 | 0.7390625 | 0.6296875\n",
      "> 57 | 0.5062413215637207 | 0.4427829384803772 | 0.7390625 | 0.6328125\n",
      "> 58 | 0.5054304003715515 | 0.44206702709198 | 0.740625 | 0.6296875\n",
      "> 59 | 0.5046368837356567 | 0.44139453768730164 | 0.740625 | 0.63125\n",
      "> 60 | 0.503860354423523 | 0.4407634735107422 | 0.740625 | 0.63125\n",
      "> 61 | 0.5031001567840576 | 0.440172016620636 | 0.7421875 | 0.6296875\n",
      "> 62 | 0.5023558735847473 | 0.43961820006370544 | 0.74375 | 0.6265625\n",
      "> 63 | 0.5016269683837891 | 0.4391002655029297 | 0.7453125 | 0.6265625\n",
      "> 64 | 0.5009130239486694 | 0.4386165738105774 | 0.7484375 | 0.628125\n",
      "> 65 | 0.5002135038375854 | 0.4381653666496277 | 0.7484375 | 0.6296875\n",
      "> 66 | 0.499528169631958 | 0.4377451539039612 | 0.7484375 | 0.6296875\n",
      "> 67 | 0.4988563656806946 | 0.43735432624816895 | 0.7484375 | 0.6328125\n",
      "> 68 | 0.49819785356521606 | 0.43699151277542114 | 0.7484375 | 0.6328125\n",
      "> 69 | 0.4975522458553314 | 0.4366552233695984 | 0.7484375 | 0.6328125\n",
      "> 70 | 0.49691909551620483 | 0.4363441467285156 | 0.7453125 | 0.6328125\n",
      "> 71 | 0.4962981045246124 | 0.43605706095695496 | 0.746875 | 0.6359375\n",
      "> 72 | 0.49568891525268555 | 0.43579262495040894 | 0.74375 | 0.6390625\n",
      "> 73 | 0.49509119987487793 | 0.4355497360229492 | 0.74375 | 0.6375\n",
      "> 74 | 0.4945046305656433 | 0.4353271424770355 | 0.746875 | 0.6390625\n",
      "> 75 | 0.4939289689064026 | 0.43512386083602905 | 0.746875 | 0.6375\n",
      "> 76 | 0.4933638274669647 | 0.43493878841400146 | 0.7484375 | 0.6390625\n",
      "> 77 | 0.4928089380264282 | 0.43477097153663635 | 0.75 | 0.6390625\n",
      "> 78 | 0.4922640919685364 | 0.43461936712265015 | 0.75 | 0.640625\n",
      "> 79 | 0.4917289912700653 | 0.43448320031166077 | 0.75 | 0.6390625\n",
      "> 80 | 0.4912033677101135 | 0.43436145782470703 | 0.75 | 0.6390625\n",
      "> 81 | 0.49068698287010193 | 0.43425339460372925 | 0.75 | 0.6421875\n",
      "> 82 | 0.4901795983314514 | 0.43415817618370056 | 0.7515625 | 0.64375\n",
      "> 83 | 0.48968103528022766 | 0.4340750277042389 | 0.7515625 | 0.6453125\n",
      "> 84 | 0.4891909956932068 | 0.4340032637119293 | 0.75 | 0.64375\n",
      "> 85 | 0.4887092709541321 | 0.43394210934638977 | 0.75 | 0.646875\n",
      "> 86 | 0.4882356524467468 | 0.4338909387588501 | 0.7484375 | 0.646875\n",
      "> 87 | 0.4877700209617615 | 0.43384918570518494 | 0.7484375 | 0.6453125\n",
      "> 88 | 0.4873121380805969 | 0.433816134929657 | 0.7484375 | 0.6453125\n",
      "> 89 | 0.4868617355823517 | 0.43379130959510803 | 0.75 | 0.646875\n",
      "> 90 | 0.4864187240600586 | 0.43377408385276794 | 0.7515625 | 0.646875\n",
      "> 91 | 0.4859829246997833 | 0.43376392126083374 | 0.75 | 0.6484375\n",
      "> 92 | 0.48555415868759155 | 0.4337604343891144 | 0.75 | 0.6484375\n",
      "> 93 | 0.48513221740722656 | 0.4337630271911621 | 0.75 | 0.646875\n",
      "> 94 | 0.4847169518470764 | 0.4337713122367859 | 0.7515625 | 0.6453125\n",
      "> 95 | 0.48430827260017395 | 0.4337848722934723 | 0.7515625 | 0.6421875\n",
      "> 96 | 0.48390597105026245 | 0.4338032603263855 | 0.7546875 | 0.6421875\n",
      "> 97 | 0.48350989818573 | 0.43382614850997925 | 0.75625 | 0.64375\n",
      "> 98 | 0.4831199645996094 | 0.4338530898094177 | 0.75625 | 0.64375\n",
      "> 99 | 0.4827359914779663 | 0.43388378620147705 | 0.7546875 | 0.646875\n",
      "> 100 | 0.48235782980918884 | 0.43391790986061096 | 0.75625 | 0.6453125\n",
      "> Evaluation\n",
      "> Class Acc = 0.70703125\n",
      "> Adv Acc = 0.70703125\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8961983919143677 | 0.847377598285675 | 0.9692307710647583\n",
      "> Confusion Matrix \n",
      "TN: 16.0 | FP: 58.0 \n",
      "FN: 17.0 | TP: 165.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 9.0 | FP: 13.0 \n",
      "FN: 6.0 | TP: 46.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 7.0 | FP: 45.0 \n",
      "FN: 11.0 | TP: 119.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.5168954133987427 | 0.8025915026664734 | 0.6984375 | 0.3046875\n",
      "> 2 | 0.5161252617835999 | 0.7916598320007324 | 0.6984375 | 0.3046875\n",
      "> 3 | 0.5148272514343262 | 0.780717670917511 | 0.6984375 | 0.3046875\n",
      "> 4 | 0.5132746696472168 | 0.7699974775314331 | 0.6984375 | 0.3046875\n",
      "> 5 | 0.511584997177124 | 0.7595793604850769 | 0.6984375 | 0.3046875\n",
      "> 6 | 0.5098133087158203 | 0.749472975730896 | 0.6984375 | 0.3046875\n",
      "> 7 | 0.5079916715621948 | 0.7396650314331055 | 0.6984375 | 0.3046875\n",
      "> 8 | 0.5061426162719727 | 0.7301387786865234 | 0.6984375 | 0.3046875\n",
      "> 9 | 0.5042837858200073 | 0.7208800911903381 | 0.6984375 | 0.3046875\n",
      "> 10 | 0.5024294257164001 | 0.7118781805038452 | 0.6984375 | 0.3046875\n",
      "> 11 | 0.5005908012390137 | 0.7031252384185791 | 0.6984375 | 0.3046875\n",
      "> 12 | 0.4987773299217224 | 0.6946156024932861 | 0.6984375 | 0.3046875\n",
      "> 13 | 0.4969959259033203 | 0.6863449215888977 | 0.6984375 | 0.3046875\n",
      "> 14 | 0.49525198340415955 | 0.678309977054596 | 0.6984375 | 0.3046875\n",
      "> 15 | 0.4935497045516968 | 0.6705078482627869 | 0.6984375 | 0.3046875\n",
      "> 16 | 0.49189186096191406 | 0.6629359722137451 | 0.6984375 | 0.3046875\n",
      "> 17 | 0.49028030037879944 | 0.6555917263031006 | 0.6984375 | 0.3046875\n",
      "> 18 | 0.4887162148952484 | 0.6484724879264832 | 0.6984375 | 0.3046875\n",
      "> 19 | 0.4872000217437744 | 0.6415753364562988 | 0.7 | 0.3046875\n",
      "> 20 | 0.4857317805290222 | 0.6348972320556641 | 0.7046875 | 0.3046875\n",
      "> 21 | 0.4843111038208008 | 0.6284351348876953 | 0.7046875 | 0.3046875\n",
      "> 22 | 0.4829372763633728 | 0.622185230255127 | 0.703125 | 0.3046875\n",
      "> 23 | 0.48160940408706665 | 0.616144061088562 | 0.7046875 | 0.3046875\n",
      "> 24 | 0.4803263545036316 | 0.610307514667511 | 0.70625 | 0.3046875\n",
      "> 25 | 0.4790869951248169 | 0.6046714782714844 | 0.709375 | 0.3046875\n",
      "> 26 | 0.4778899550437927 | 0.5992317795753479 | 0.7140625 | 0.3046875\n",
      "> 27 | 0.47673389315605164 | 0.5939838290214539 | 0.71875 | 0.3046875\n",
      "> 28 | 0.4756174683570862 | 0.5889230966567993 | 0.7171875 | 0.3046875\n",
      "> 29 | 0.4745393991470337 | 0.5840449929237366 | 0.7203125 | 0.3046875\n",
      "> 30 | 0.4734981060028076 | 0.579344630241394 | 0.7234375 | 0.3046875\n",
      "> 31 | 0.47249239683151245 | 0.5748172998428345 | 0.721875 | 0.325\n",
      "> 32 | 0.47152090072631836 | 0.570458173751831 | 0.721875 | 0.340625\n",
      "> 33 | 0.47058218717575073 | 0.5662623047828674 | 0.7234375 | 0.3671875\n",
      "> 34 | 0.4696751832962036 | 0.5622248649597168 | 0.725 | 0.421875\n",
      "> 35 | 0.4687986373901367 | 0.5583411455154419 | 0.728125 | 0.453125\n",
      "> 36 | 0.46795129776000977 | 0.5546060800552368 | 0.7234375 | 0.4953125\n",
      "> 37 | 0.467132031917572 | 0.5510150194168091 | 0.721875 | 0.528125\n",
      "> 38 | 0.4663398265838623 | 0.5475632548332214 | 0.725 | 0.553125\n",
      "> 39 | 0.4655735492706299 | 0.5442461371421814 | 0.7265625 | 0.5640625\n",
      "> 40 | 0.4648323059082031 | 0.5410589575767517 | 0.728125 | 0.584375\n",
      "> 41 | 0.46411505341529846 | 0.537997305393219 | 0.73125 | 0.590625\n",
      "> 42 | 0.46342092752456665 | 0.5350567102432251 | 0.728125 | 0.5984375\n",
      "> 43 | 0.46274900436401367 | 0.5322328209877014 | 0.728125 | 0.6109375\n",
      "> 44 | 0.46209847927093506 | 0.5295214653015137 | 0.7296875 | 0.621875\n",
      "> 45 | 0.4614686369895935 | 0.5269184112548828 | 0.7296875 | 0.628125\n",
      "> 46 | 0.4608585834503174 | 0.5244196653366089 | 0.7328125 | 0.625\n",
      "> 47 | 0.46026766300201416 | 0.5220211744308472 | 0.7328125 | 0.6296875\n",
      "> 48 | 0.4596951901912689 | 0.5197192430496216 | 0.734375 | 0.6265625\n",
      "> 49 | 0.45914050936698914 | 0.517509937286377 | 0.7390625 | 0.63125\n",
      "> 50 | 0.4586029648780823 | 0.5153898000717163 | 0.7421875 | 0.6359375\n",
      "> 51 | 0.4580819010734558 | 0.5133552551269531 | 0.7421875 | 0.634375\n",
      "> 52 | 0.4575768709182739 | 0.51140296459198 | 0.7421875 | 0.6390625\n",
      "> 53 | 0.45708730816841125 | 0.5095294713973999 | 0.7421875 | 0.6359375\n",
      "> 54 | 0.45661258697509766 | 0.5077317953109741 | 0.74375 | 0.6390625\n",
      "> 55 | 0.4561523497104645 | 0.5060064792633057 | 0.7453125 | 0.64375\n",
      "> 56 | 0.45570600032806396 | 0.5043509006500244 | 0.7453125 | 0.640625\n",
      "> 57 | 0.4552731513977051 | 0.5027620196342468 | 0.746875 | 0.6390625\n",
      "> 58 | 0.454853355884552 | 0.5012370347976685 | 0.7484375 | 0.6375\n",
      "> 59 | 0.4544461965560913 | 0.49977317452430725 | 0.746875 | 0.6375\n",
      "> 60 | 0.45405131578445435 | 0.4983680248260498 | 0.74375 | 0.6390625\n",
      "> 61 | 0.4536682665348053 | 0.497018963098526 | 0.74375 | 0.64375\n",
      "> 62 | 0.4532967209815979 | 0.4957236349582672 | 0.74375 | 0.64375\n",
      "> 63 | 0.4529363214969635 | 0.4944796860218048 | 0.74375 | 0.6453125\n",
      "> 64 | 0.45258674025535583 | 0.4932849407196045 | 0.74375 | 0.6453125\n",
      "> 65 | 0.45224764943122864 | 0.49213719367980957 | 0.74375 | 0.646875\n",
      "> 66 | 0.4519187808036804 | 0.49103444814682007 | 0.7453125 | 0.6515625\n",
      "> 67 | 0.45159977674484253 | 0.4899746775627136 | 0.7484375 | 0.6578125\n",
      "> 68 | 0.45129042863845825 | 0.4889560341835022 | 0.7484375 | 0.659375\n",
      "> 69 | 0.45099037885665894 | 0.4879765808582306 | 0.7484375 | 0.659375\n",
      "> 70 | 0.4506993889808655 | 0.48703470826148987 | 0.7484375 | 0.6625\n",
      "> 71 | 0.45041733980178833 | 0.48612865805625916 | 0.75 | 0.6640625\n",
      "> 72 | 0.45014381408691406 | 0.4852568507194519 | 0.75 | 0.665625\n",
      "> 73 | 0.4498786926269531 | 0.48441773653030396 | 0.7484375 | 0.671875\n",
      "> 74 | 0.44962161779403687 | 0.4836098849773407 | 0.7453125 | 0.675\n",
      "> 75 | 0.4493725597858429 | 0.48283177614212036 | 0.7453125 | 0.6765625\n",
      "> 76 | 0.4491311311721802 | 0.48208218812942505 | 0.7453125 | 0.68125\n",
      "> 77 | 0.4488973021507263 | 0.4813597798347473 | 0.7453125 | 0.6828125\n",
      "> 78 | 0.44867074489593506 | 0.4806632399559021 | 0.7453125 | 0.6828125\n",
      "> 79 | 0.44845134019851685 | 0.47999143600463867 | 0.7453125 | 0.6796875\n",
      "> 80 | 0.4482388496398926 | 0.4793432950973511 | 0.7453125 | 0.68125\n",
      "> 81 | 0.4480332136154175 | 0.4787176251411438 | 0.7453125 | 0.6828125\n",
      "> 82 | 0.4478341341018677 | 0.47811347246170044 | 0.7421875 | 0.684375\n",
      "> 83 | 0.4476415514945984 | 0.4775298535823822 | 0.7421875 | 0.684375\n",
      "> 84 | 0.4474552273750305 | 0.4769657254219055 | 0.7421875 | 0.6875\n",
      "> 85 | 0.4472750425338745 | 0.4764203131198883 | 0.7421875 | 0.6859375\n",
      "> 86 | 0.4471008777618408 | 0.47589266300201416 | 0.74375 | 0.6859375\n",
      "> 87 | 0.4469325542449951 | 0.4753820300102234 | 0.7453125 | 0.6859375\n",
      "> 88 | 0.44676995277404785 | 0.47488757967948914 | 0.7453125 | 0.6859375\n",
      "> 89 | 0.4466129243373871 | 0.4744085669517517 | 0.746875 | 0.690625\n",
      "> 90 | 0.4464613199234009 | 0.4739442467689514 | 0.746875 | 0.690625\n",
      "> 91 | 0.44631505012512207 | 0.4734940230846405 | 0.746875 | 0.6890625\n",
      "> 92 | 0.4461739957332611 | 0.47305721044540405 | 0.7484375 | 0.690625\n",
      "> 93 | 0.44603800773620605 | 0.4726331830024719 | 0.7484375 | 0.69375\n",
      "> 94 | 0.44590696692466736 | 0.472221314907074 | 0.7484375 | 0.69375\n",
      "> 95 | 0.44578081369400024 | 0.471821129322052 | 0.75 | 0.690625\n",
      "> 96 | 0.445659339427948 | 0.47143203020095825 | 0.7515625 | 0.6921875\n",
      "> 97 | 0.44554251432418823 | 0.47105351090431213 | 0.7515625 | 0.6921875\n",
      "> 98 | 0.44543027877807617 | 0.47068506479263306 | 0.7515625 | 0.69375\n",
      "> 99 | 0.4453223943710327 | 0.47032630443573 | 0.753125 | 0.6921875\n",
      "> 100 | 0.44521886110305786 | 0.4699767231941223 | 0.753125 | 0.6921875\n",
      "> Evaluation\n",
      "> Class Acc = 0.71484375\n",
      "> Adv Acc = 0.71484375\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8919841051101685 | 0.8758364841341972 | 0.9247498959302902\n",
      "> Confusion Matrix \n",
      "TN: 24.0 | FP: 54.0 \n",
      "FN: 19.0 | TP: 159.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 11.0 | FP: 15.0 \n",
      "FN: 9.0 | TP: 48.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 13.0 | FP: 39.0 \n",
      "FN: 10.0 | TP: 111.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.651167631149292 | 0.7272467613220215 | 0.690625 | 0.3109375\n",
      "> 2 | 0.6443504095077515 | 0.7165273427963257 | 0.690625 | 0.3109375\n",
      "> 3 | 0.6373809576034546 | 0.7057682871818542 | 0.690625 | 0.3109375\n",
      "> 4 | 0.6307709217071533 | 0.695199728012085 | 0.690625 | 0.3109375\n",
      "> 5 | 0.6246625781059265 | 0.6848859786987305 | 0.690625 | 0.3109375\n",
      "> 6 | 0.6190416216850281 | 0.6748186349868774 | 0.690625 | 0.3109375\n",
      "> 7 | 0.6138489842414856 | 0.664971113204956 | 0.690625 | 0.3109375\n",
      "> 8 | 0.6090227961540222 | 0.6553194522857666 | 0.690625 | 0.3109375\n",
      "> 9 | 0.6045100092887878 | 0.6458478569984436 | 0.690625 | 0.3109375\n",
      "> 10 | 0.6002680063247681 | 0.6365478038787842 | 0.690625 | 0.3109375\n",
      "> 11 | 0.5962628126144409 | 0.6274164319038391 | 0.690625 | 0.3109375\n",
      "> 12 | 0.5924676060676575 | 0.6184539198875427 | 0.690625 | 0.3109375\n",
      "> 13 | 0.5888607501983643 | 0.6096624135971069 | 0.690625 | 0.3109375\n",
      "> 14 | 0.5854244232177734 | 0.6010449528694153 | 0.690625 | 0.3109375\n",
      "> 15 | 0.5821441411972046 | 0.5926045179367065 | 0.690625 | 0.3109375\n",
      "> 16 | 0.5790074467658997 | 0.5843440294265747 | 0.690625 | 0.3109375\n",
      "> 17 | 0.5760038495063782 | 0.5762659311294556 | 0.6921875 | 0.3109375\n",
      "> 18 | 0.5731242895126343 | 0.5683718919754028 | 0.6921875 | 0.3109375\n",
      "> 19 | 0.5703606605529785 | 0.5606632232666016 | 0.6921875 | 0.3109375\n",
      "> 20 | 0.5677058696746826 | 0.5531405806541443 | 0.6921875 | 0.3109375\n",
      "> 21 | 0.5651534795761108 | 0.5458039045333862 | 0.69375 | 0.3109375\n",
      "> 22 | 0.5626978278160095 | 0.538652777671814 | 0.6953125 | 0.3109375\n",
      "> 23 | 0.5603336095809937 | 0.5316861867904663 | 0.6953125 | 0.3109375\n",
      "> 24 | 0.5580559372901917 | 0.5249027609825134 | 0.6984375 | 0.3109375\n",
      "> 25 | 0.5558603405952454 | 0.5183006525039673 | 0.7 | 0.3109375\n",
      "> 26 | 0.5537428259849548 | 0.511877715587616 | 0.7 | 0.3109375\n",
      "> 27 | 0.5516993999481201 | 0.505631685256958 | 0.7015625 | 0.3109375\n",
      "> 28 | 0.5497266054153442 | 0.4995597302913666 | 0.7046875 | 0.3109375\n",
      "> 29 | 0.547821044921875 | 0.4936590790748596 | 0.7015625 | 0.3109375\n",
      "> 30 | 0.5459796190261841 | 0.48792651295661926 | 0.7015625 | 0.3109375\n",
      "> 31 | 0.5441993474960327 | 0.4823589324951172 | 0.703125 | 0.3171875\n",
      "> 32 | 0.5424776077270508 | 0.47695299983024597 | 0.703125 | 0.321875\n",
      "> 33 | 0.5408115386962891 | 0.47170522809028625 | 0.709375 | 0.3359375\n",
      "> 34 | 0.5391989946365356 | 0.4666121006011963 | 0.7109375 | 0.35625\n",
      "> 35 | 0.53763747215271 | 0.46167004108428955 | 0.7125 | 0.3765625\n",
      "> 36 | 0.5361248254776001 | 0.45687544345855713 | 0.7140625 | 0.4\n",
      "> 37 | 0.5346590876579285 | 0.45222464203834534 | 0.721875 | 0.4421875\n",
      "> 38 | 0.5332381725311279 | 0.44771409034729004 | 0.7234375 | 0.465625\n",
      "> 39 | 0.5318603515625 | 0.44334009289741516 | 0.725 | 0.478125\n",
      "> 40 | 0.5305237770080566 | 0.439098984003067 | 0.73125 | 0.503125\n",
      "> 41 | 0.5292267799377441 | 0.43498724699020386 | 0.7328125 | 0.5171875\n",
      "> 42 | 0.5279679298400879 | 0.431001216173172 | 0.73125 | 0.5296875\n",
      "> 43 | 0.5267455577850342 | 0.42713743448257446 | 0.7296875 | 0.5359375\n",
      "> 44 | 0.525558352470398 | 0.4233924150466919 | 0.73125 | 0.553125\n",
      "> 45 | 0.5244048237800598 | 0.4197627305984497 | 0.7328125 | 0.5625\n",
      "> 46 | 0.5232838988304138 | 0.4162449836730957 | 0.73125 | 0.5703125\n",
      "> 47 | 0.5221942067146301 | 0.412835955619812 | 0.734375 | 0.5734375\n",
      "> 48 | 0.521134614944458 | 0.40953221917152405 | 0.7359375 | 0.5734375\n",
      "> 49 | 0.520103931427002 | 0.40633076429367065 | 0.7375 | 0.578125\n",
      "> 50 | 0.5191012024879456 | 0.4032283425331116 | 0.7375 | 0.584375\n",
      "> 51 | 0.5181254148483276 | 0.4002220332622528 | 0.7390625 | 0.5828125\n",
      "> 52 | 0.517175555229187 | 0.3973087668418884 | 0.740625 | 0.584375\n",
      "> 53 | 0.5162506699562073 | 0.3944857716560364 | 0.7390625 | 0.5890625\n",
      "> 54 | 0.5153499841690063 | 0.39175015687942505 | 0.7375 | 0.59375\n",
      "> 55 | 0.5144725441932678 | 0.38909912109375 | 0.7359375 | 0.5921875\n",
      "> 56 | 0.513617753982544 | 0.3865300416946411 | 0.7359375 | 0.59375\n",
      "> 57 | 0.5127845406532288 | 0.38404032588005066 | 0.734375 | 0.5953125\n",
      "> 58 | 0.5119723677635193 | 0.3816273510456085 | 0.7359375 | 0.596875\n",
      "> 59 | 0.5111805200576782 | 0.3792887032032013 | 0.7421875 | 0.5984375\n",
      "> 60 | 0.5104082822799683 | 0.37702202796936035 | 0.740625 | 0.596875\n",
      "> 61 | 0.5096550583839417 | 0.37482497096061707 | 0.7390625 | 0.6\n",
      "> 62 | 0.5089202523231506 | 0.37269526720046997 | 0.7375 | 0.6015625\n",
      "> 63 | 0.5082031488418579 | 0.37063074111938477 | 0.7390625 | 0.6\n",
      "> 64 | 0.50750333070755 | 0.36862918734550476 | 0.7375 | 0.6015625\n",
      "> 65 | 0.5068201422691345 | 0.36668866872787476 | 0.7359375 | 0.6046875\n",
      "> 66 | 0.5061531066894531 | 0.36480712890625 | 0.7359375 | 0.6015625\n",
      "> 67 | 0.5055017471313477 | 0.3629826605319977 | 0.7359375 | 0.5984375\n",
      "> 68 | 0.5048655867576599 | 0.3612133860588074 | 0.734375 | 0.6015625\n",
      "> 69 | 0.5042441487312317 | 0.3594974875450134 | 0.7375 | 0.6015625\n",
      "> 70 | 0.5036369562149048 | 0.35783326625823975 | 0.7359375 | 0.603125\n",
      "> 71 | 0.5030436515808105 | 0.35621896386146545 | 0.7375 | 0.60625\n",
      "> 72 | 0.5024638175964355 | 0.35465291142463684 | 0.7390625 | 0.60625\n",
      "> 73 | 0.5018969774246216 | 0.3531336486339569 | 0.7390625 | 0.60625\n",
      "> 74 | 0.5013429522514343 | 0.35165950655937195 | 0.740625 | 0.6078125\n",
      "> 75 | 0.5008012056350708 | 0.35022902488708496 | 0.7421875 | 0.60625\n",
      "> 76 | 0.5002714395523071 | 0.3488408923149109 | 0.740625 | 0.60625\n",
      "> 77 | 0.49975329637527466 | 0.34749358892440796 | 0.7421875 | 0.609375\n",
      "> 78 | 0.4992464780807495 | 0.3461857736110687 | 0.7421875 | 0.6140625\n",
      "> 79 | 0.4987506866455078 | 0.3449162244796753 | 0.7421875 | 0.6125\n",
      "> 80 | 0.4982656240463257 | 0.3436836302280426 | 0.74375 | 0.615625\n",
      "> 81 | 0.4977909326553345 | 0.3424868583679199 | 0.746875 | 0.6171875\n",
      "> 82 | 0.49732646346092224 | 0.3413246273994446 | 0.7484375 | 0.6171875\n",
      "> 83 | 0.49687185883522034 | 0.340195894241333 | 0.75 | 0.6171875\n",
      "> 84 | 0.49642691016197205 | 0.33909958600997925 | 0.75 | 0.615625\n",
      "> 85 | 0.4959913492202759 | 0.33803460001945496 | 0.753125 | 0.615625\n",
      "> 86 | 0.4955648183822632 | 0.3369998633861542 | 0.753125 | 0.615625\n",
      "> 87 | 0.4951472878456116 | 0.33599451184272766 | 0.753125 | 0.615625\n",
      "> 88 | 0.4947384297847748 | 0.3350175619125366 | 0.7546875 | 0.615625\n",
      "> 89 | 0.4943380653858185 | 0.3340680003166199 | 0.7546875 | 0.6171875\n",
      "> 90 | 0.4939458966255188 | 0.3331450819969177 | 0.7546875 | 0.6171875\n",
      "> 91 | 0.4935617744922638 | 0.33224785327911377 | 0.7546875 | 0.615625\n",
      "> 92 | 0.49318552017211914 | 0.3313755393028259 | 0.75625 | 0.6171875\n",
      "> 93 | 0.4928170144557953 | 0.33052733540534973 | 0.759375 | 0.61875\n",
      "> 94 | 0.4924558997154236 | 0.3297024369239807 | 0.759375 | 0.621875\n",
      "> 95 | 0.49210211634635925 | 0.32890015840530396 | 0.7609375 | 0.621875\n",
      "> 96 | 0.49175548553466797 | 0.3281197249889374 | 0.7609375 | 0.621875\n",
      "> 97 | 0.4914158582687378 | 0.32736045122146606 | 0.7609375 | 0.621875\n",
      "> 98 | 0.49108296632766724 | 0.3266217112541199 | 0.7625 | 0.6203125\n",
      "> 99 | 0.4907568097114563 | 0.3259028196334839 | 0.7625 | 0.6203125\n",
      "> 100 | 0.4904371201992035 | 0.3252031207084656 | 0.7625 | 0.621875\n",
      "> Evaluation\n",
      "> Class Acc = 0.7578125\n",
      "> Adv Acc = 0.7578125\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.9766859412193298 | 0.9612000808119774 | 0.9860365241765976\n",
      "> Confusion Matrix \n",
      "TN: 25.0 | FP: 49.0 \n",
      "FN: 13.0 | TP: 169.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 9.0 | FP: 21.0 \n",
      "FN: 4.0 | TP: 45.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 16.0 | FP: 28.0 \n",
      "FN: 9.0 | TP: 124.0\n"
     ]
    }
   ],
   "source": [
    "fairdef = 'EqOpp'\n",
    "\n",
    "for cv_seed in cv_seeds:\n",
    "    x_train, x_test, y_train, y_test, a_train, a_test = train_test_split(\n",
    "        x, y, a, test_size=0.3, random_state=cv_seed)\n",
    "\n",
    "    train_data = Dataset.from_tensor_slices((x_train, y_train, a_train))\n",
    "    train_data = train_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    test_data = Dataset.from_tensor_slices((x_test, y_test, a_test))\n",
    "    test_data = test_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    # train below\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "    \n",
    "    model = FairLogisticRegression(xdim, ydim, adim, batch_size, fairdef)\n",
    "    zhang_train(model, raw_data, train_data, epochs, opt)\n",
    "\n",
    "    Y, A, Y_hat, A_hat = fair_evaluation(model, test_data)\n",
    "    clas_acc, dp, deqodds, deqopp, confusion_matrix, metrics_a0, metrics_a1 = compute_metrics(Y, A, Y_hat, A_hat, adim)\n",
    "\n",
    "    fair_metrics = (dp, deqodds, deqopp)\n",
    "    tradeoff = []\n",
    "    for fair_metric in fair_metrics:\n",
    "        tradeoff.append(compute_tradeoff(clas_acc, fair_metric))\n",
    "\n",
    "    result = ['Zhang4EqOpp', cv_seed, clas_acc, dp, deqodds, deqopp, tradeoff[0], tradeoff[1], tradeoff[2]] + metrics_a0 + metrics_a1\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    del(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving into DF then CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>cv_seed</th>\n",
       "      <th>clas_acc</th>\n",
       "      <th>dp</th>\n",
       "      <th>deqodds</th>\n",
       "      <th>deqopp</th>\n",
       "      <th>trade_dp</th>\n",
       "      <th>trade_deqodds</th>\n",
       "      <th>trade_deqopp</th>\n",
       "      <th>TN_a0</th>\n",
       "      <th>FP_a0</th>\n",
       "      <th>FN_a0</th>\n",
       "      <th>TP_a0</th>\n",
       "      <th>TN_a1</th>\n",
       "      <th>FP_a1</th>\n",
       "      <th>FN_a1</th>\n",
       "      <th>TP_a1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>13</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.781285</td>\n",
       "      <td>0.725085</td>\n",
       "      <td>0.895225</td>\n",
       "      <td>0.748714</td>\n",
       "      <td>0.721904</td>\n",
       "      <td>0.797340</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>29</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>0.886720</td>\n",
       "      <td>0.922413</td>\n",
       "      <td>0.947767</td>\n",
       "      <td>0.791559</td>\n",
       "      <td>0.805471</td>\n",
       "      <td>0.814990</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>42</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>0.861152</td>\n",
       "      <td>0.820804</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.781207</td>\n",
       "      <td>0.764168</td>\n",
       "      <td>0.805724</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>55</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>0.874156</td>\n",
       "      <td>0.846990</td>\n",
       "      <td>0.924750</td>\n",
       "      <td>0.786513</td>\n",
       "      <td>0.775327</td>\n",
       "      <td>0.806360</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>73</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.952728</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.965628</td>\n",
       "      <td>0.836844</td>\n",
       "      <td>0.844844</td>\n",
       "      <td>0.841783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>13</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.769380</td>\n",
       "      <td>0.705854</td>\n",
       "      <td>0.895225</td>\n",
       "      <td>0.745286</td>\n",
       "      <td>0.714157</td>\n",
       "      <td>0.799737</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>29</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.869770</td>\n",
       "      <td>0.904672</td>\n",
       "      <td>0.931894</td>\n",
       "      <td>0.787081</td>\n",
       "      <td>0.801065</td>\n",
       "      <td>0.811560</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>42</td>\n",
       "      <td>0.710938</td>\n",
       "      <td>0.893674</td>\n",
       "      <td>0.856993</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.791901</td>\n",
       "      <td>0.777163</td>\n",
       "      <td>0.813264</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>55</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.874643</td>\n",
       "      <td>0.842015</td>\n",
       "      <td>0.934029</td>\n",
       "      <td>0.789070</td>\n",
       "      <td>0.775515</td>\n",
       "      <td>0.812369</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>73</td>\n",
       "      <td>0.746094</td>\n",
       "      <td>0.952728</td>\n",
       "      <td>0.973723</td>\n",
       "      <td>0.965628</td>\n",
       "      <td>0.836844</td>\n",
       "      <td>0.844844</td>\n",
       "      <td>0.841783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>13</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.787099</td>\n",
       "      <td>0.720873</td>\n",
       "      <td>0.910610</td>\n",
       "      <td>0.744920</td>\n",
       "      <td>0.713885</td>\n",
       "      <td>0.796011</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>29</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.889437</td>\n",
       "      <td>0.934318</td>\n",
       "      <td>0.916021</td>\n",
       "      <td>0.797419</td>\n",
       "      <td>0.814968</td>\n",
       "      <td>0.807930</td>\n",
       "      <td>13.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>42</td>\n",
       "      <td>0.707031</td>\n",
       "      <td>0.896198</td>\n",
       "      <td>0.847378</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.790455</td>\n",
       "      <td>0.770869</td>\n",
       "      <td>0.817624</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>55</td>\n",
       "      <td>0.714844</td>\n",
       "      <td>0.891984</td>\n",
       "      <td>0.875836</td>\n",
       "      <td>0.924750</td>\n",
       "      <td>0.793650</td>\n",
       "      <td>0.787193</td>\n",
       "      <td>0.806360</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>73</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.976686</td>\n",
       "      <td>0.961200</td>\n",
       "      <td>0.986037</td>\n",
       "      <td>0.853440</td>\n",
       "      <td>0.847474</td>\n",
       "      <td>0.856990</td>\n",
       "      <td>9.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  cv_seed  clas_acc        dp   deqodds    deqopp  trade_dp  \\\n",
       "0       Zhang4DP       13  0.718750  0.781285  0.725085  0.895225  0.748714   \n",
       "1       Zhang4DP       29  0.714844  0.886720  0.922413  0.947767  0.791559   \n",
       "2       Zhang4DP       42  0.714844  0.861152  0.820804  0.923077  0.781207   \n",
       "3       Zhang4DP       55  0.714844  0.874156  0.846990  0.924750  0.786513   \n",
       "4       Zhang4DP       73  0.746094  0.952728  0.973723  0.965628  0.836844   \n",
       "5   Zhang4EqOdds       13  0.722656  0.769380  0.705854  0.895225  0.745286   \n",
       "6   Zhang4EqOdds       29  0.718750  0.869770  0.904672  0.931894  0.787081   \n",
       "7   Zhang4EqOdds       42  0.710938  0.893674  0.856993  0.950000  0.791901   \n",
       "8   Zhang4EqOdds       55  0.718750  0.874643  0.842015  0.934029  0.789070   \n",
       "9   Zhang4EqOdds       73  0.746094  0.952728  0.973723  0.965628  0.836844   \n",
       "10   Zhang4EqOpp       13  0.707031  0.787099  0.720873  0.910610  0.744920   \n",
       "11   Zhang4EqOpp       29  0.722656  0.889437  0.934318  0.916021  0.797419   \n",
       "12   Zhang4EqOpp       42  0.707031  0.896198  0.847378  0.969231  0.790455   \n",
       "13   Zhang4EqOpp       55  0.714844  0.891984  0.875836  0.924750  0.793650   \n",
       "14   Zhang4EqOpp       73  0.757812  0.976686  0.961200  0.986037  0.853440   \n",
       "\n",
       "    trade_deqodds  trade_deqopp  TN_a0  FP_a0  FN_a0  TP_a0  TN_a1  FP_a1  \\\n",
       "0        0.721904      0.797340   19.0    7.0   15.0   43.0   12.0   30.0   \n",
       "1        0.805471      0.814990   15.0   21.0    6.0   37.0   16.0   35.0   \n",
       "2        0.764168      0.805724   10.0   12.0    8.0   44.0    9.0   43.0   \n",
       "3        0.775327      0.806360   12.0   14.0    9.0   48.0   12.0   40.0   \n",
       "4        0.844844      0.841783    9.0   21.0    5.0   44.0   14.0   30.0   \n",
       "5        0.714157      0.799737   20.0    6.0   15.0   43.0   12.0   30.0   \n",
       "6        0.801065      0.811560   15.0   21.0    6.0   37.0   15.0   36.0   \n",
       "7        0.777163      0.813264    9.0   13.0    7.0   45.0    9.0   43.0   \n",
       "8        0.775515      0.812369   12.0   14.0    8.0   49.0   11.0   41.0   \n",
       "9        0.844844      0.841783    9.0   21.0    5.0   44.0   14.0   30.0   \n",
       "10       0.713885      0.796011   19.0    7.0   15.0   43.0   11.0   31.0   \n",
       "11       0.814968      0.807930   13.0   23.0    6.0   37.0   16.0   35.0   \n",
       "12       0.770869      0.817624    9.0   13.0    6.0   46.0    7.0   45.0   \n",
       "13       0.787193      0.806360   11.0   15.0    9.0   48.0   13.0   39.0   \n",
       "14       0.847474      0.856990    9.0   21.0    4.0   45.0   16.0   28.0   \n",
       "\n",
       "    FN_a1  TP_a1  \n",
       "0    20.0  110.0  \n",
       "1    11.0  115.0  \n",
       "2    10.0  120.0  \n",
       "3    10.0  111.0  \n",
       "4     9.0  124.0  \n",
       "5    20.0  110.0  \n",
       "6     9.0  117.0  \n",
       "7    11.0  119.0  \n",
       "8     9.0  112.0  \n",
       "9     9.0  124.0  \n",
       "10   22.0  108.0  \n",
       "11    7.0  119.0  \n",
       "12   11.0  119.0  \n",
       "13   10.0  111.0  \n",
       "14    9.0  124.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(results, columns=header)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f'{data_name}-result/zhang-{epochs}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('falsb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "41359ec383f887151a607ad1e28cb7dbc05f61385692c63e2bb2f343bf03f280"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
