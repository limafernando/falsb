{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing file \n",
    "### where we evaluate Zhang's models using the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "\n",
    "from util.load_data import load_data\n",
    "from util.evaluation import *\n",
    "from models.zhang.models import FairLogisticRegression\n",
    "from models.zhang.learning import train_loop as zhang_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_seeds = [13, 29, 42, 55, 73]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'adult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, a = load_data(data_name)\n",
    "raw_data = (x, y, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdim = x.shape[1]\n",
    "ydim = y.shape[1]\n",
    "adim = a.shape[1]\n",
    "zdim = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = \"model_name\", \"cv_seed\", \"clas_acc\", \"dp\", \"deqodds\", \"deqopp\", \"trade_dp\", \"trade_deqodds\", \"trade_deqopp\", \"TN_a0\", \"FP_a0\", \"FN_a0\", \"TP_a0\", \"TN_a1\", \"FP_a1\", \"FN_a1\", \"TP_a1\"\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing loop\n",
    "#### Each model is evalueted 5 times\n",
    "#### In the end of each iteration we save the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhang for DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.4150388836860657 | 0.746207594871521 | 0.6860766700404858 | 0.32518345141700405\n",
      "> 2 | 0.3644813299179077 | 0.659429132938385 | 0.8214195344129555 | 0.47918775303643724\n",
      "> 3 | 0.3455881178379059 | 0.6233700513839722 | 0.8278087044534413 | 0.7169787449392713\n",
      "> 4 | 0.33521145582199097 | 0.6088754534721375 | 0.8318572874493927 | 0.6871837044534413\n",
      "> 5 | 0.32871943712234497 | 0.6031975746154785 | 0.8343560222672065 | 0.6767143218623481\n",
      "> 6 | 0.3243919610977173 | 0.6010741591453552 | 0.835463056680162 | 0.6753858805668016\n",
      "> 7 | 0.32138144969940186 | 0.6004577279090881 | 0.8373292004048583 | 0.675290991902834\n",
      "> 8 | 0.31921055912971497 | 0.6005649566650391 | 0.8389423076923077 | 0.6757970647773279\n",
      "> 9 | 0.3175855576992035 | 0.6011413931846619 | 0.8395432692307693 | 0.6769673582995951\n",
      "> 10 | 0.31632164120674133 | 0.6020426750183105 | 0.8406819331983806 | 0.6777580971659919\n",
      "> 11 | 0.31530165672302246 | 0.6032149195671082 | 0.8416308198380567 | 0.6808894230769231\n",
      "> 12 | 0.3144526183605194 | 0.6046347618103027 | 0.8417573380566802 | 0.6859185222672065\n",
      "> 13 | 0.31372857093811035 | 0.6061760187149048 | 0.8419471153846154 | 0.6897140688259109\n",
      "> 14 | 0.3131008744239807 | 0.6078251600265503 | 0.8425797064777328 | 0.6948064271255061\n",
      "> 15 | 0.3125509023666382 | 0.6095125675201416 | 0.8431806680161943 | 0.6996141194331984\n",
      "> 16 | 0.31206628680229187 | 0.6111865043640137 | 0.8436867408906883 | 0.7024607793522267\n",
      "> 17 | 0.3116391897201538 | 0.6128129959106445 | 0.844224443319838 | 0.7061930668016194\n",
      "> 18 | 0.31126245856285095 | 0.6143850088119507 | 0.8445091093117408 | 0.7094825404858299\n",
      "> 19 | 0.31093114614486694 | 0.6158734560012817 | 0.8450151821862348 | 0.7108742408906883\n",
      "> 20 | 0.3106408417224884 | 0.6172935962677002 | 0.8453947368421053 | 0.7126771255060729\n",
      "> 21 | 0.31038615107536316 | 0.618632435798645 | 0.8457426619433198 | 0.7134046052631579\n",
      "> 22 | 0.3101627826690674 | 0.6198994517326355 | 0.8456161437246964 | 0.7141637145748988\n",
      "> 23 | 0.3099672198295593 | 0.6211133599281311 | 0.8458375506072875 | 0.7145116396761133\n",
      "> 24 | 0.3097965121269226 | 0.6222332119941711 | 0.8456794028340081 | 0.7144800101214575\n",
      "> 25 | 0.30964815616607666 | 0.6233088374137878 | 0.8459956983805668 | 0.7143218623481782\n",
      "> 26 | 0.3095203638076782 | 0.6243183612823486 | 0.8461222165991903 | 0.7139739372469636\n",
      "> 27 | 0.3094118535518646 | 0.6252679228782654 | 0.8461222165991903 | 0.7142269736842105\n",
      "> 28 | 0.30932071805000305 | 0.6261711120605469 | 0.8463119939271255 | 0.7143851214574899\n",
      "> 29 | 0.3092465400695801 | 0.6270232796669006 | 0.8462487348178138 | 0.7144483805668016\n",
      "> 30 | 0.30918771028518677 | 0.6278203725814819 | 0.8465017712550608 | 0.7144483805668016\n",
      "> 31 | 0.3091434836387634 | 0.6285778284072876 | 0.8467548076923077 | 0.7143851214574899\n",
      "> 32 | 0.3091123700141907 | 0.6292941570281982 | 0.8468813259109311 | 0.714132085020243\n",
      "> 33 | 0.30909377336502075 | 0.6299731731414795 | 0.8468180668016194 | 0.7139106781376519\n",
      "> 34 | 0.3090865910053253 | 0.6306146383285522 | 0.8470394736842105 | 0.7134994939271255\n",
      "> 35 | 0.309090256690979 | 0.6312198638916016 | 0.8472292510121457 | 0.7132780870445344\n",
      "> 36 | 0.30910372734069824 | 0.6317996978759766 | 0.8473557692307693 | 0.713119939271255\n",
      "> 37 | 0.3091261684894562 | 0.6323438882827759 | 0.847419028340081 | 0.7125506072874493\n",
      "> 38 | 0.30915749073028564 | 0.6328650712966919 | 0.8476404352226721 | 0.7122026821862348\n",
      "> 39 | 0.30919623374938965 | 0.6333644986152649 | 0.8478618421052632 | 0.7117282388663968\n",
      "> 40 | 0.30924245715141296 | 0.6338523030281067 | 0.8480832489878543 | 0.7112854251012146\n",
      "> 41 | 0.309295654296875 | 0.634305477142334 | 0.8482413967611336 | 0.7111272773279352\n",
      "> 42 | 0.30935531854629517 | 0.6347432732582092 | 0.848367914979757 | 0.7109375\n",
      "> 43 | 0.3094213008880615 | 0.6351767778396606 | 0.8485893218623481 | 0.710463056680162\n",
      "> 44 | 0.30949288606643677 | 0.6355831623077393 | 0.848873987854251 | 0.7105263157894737\n",
      "> 45 | 0.30956965684890747 | 0.6359988451004028 | 0.8490953947368421 | 0.7100835020242915\n",
      "> 46 | 0.30965158343315125 | 0.6363769173622131 | 0.849380060728745 | 0.7098620951417004\n",
      "> 47 | 0.3097384572029114 | 0.6367513537406921 | 0.8497279858299596 | 0.7092611336032388\n",
      "> 48 | 0.3098297119140625 | 0.637108325958252 | 0.8500126518218624 | 0.7091662449392713\n",
      "> 49 | 0.3099253177642822 | 0.6374676823616028 | 0.8501391700404858 | 0.7090713562753036\n",
      "> 50 | 0.31002509593963623 | 0.637808084487915 | 0.8502973178137652 | 0.7088183198380567\n",
      "> 51 | 0.31012845039367676 | 0.6381442546844482 | 0.850328947368421 | 0.7087234311740891\n",
      "> 52 | 0.3102354407310486 | 0.6384788155555725 | 0.8505187246963563 | 0.7083438765182186\n",
      "> 53 | 0.3103456199169159 | 0.6387983560562134 | 0.8506452429149798 | 0.7082173582995951\n",
      "> 54 | 0.31045883893966675 | 0.6391207575798035 | 0.850835020242915 | 0.707995951417004\n",
      "> 55 | 0.3105754256248474 | 0.6394287943840027 | 0.850835020242915 | 0.7077745445344129\n",
      "> 56 | 0.3106943368911743 | 0.6397338509559631 | 0.8507401315789473 | 0.7075531376518218\n",
      "> 57 | 0.31081581115722656 | 0.6400318145751953 | 0.8508033906882592 | 0.7072368421052632\n",
      "> 58 | 0.3109394907951355 | 0.6403319835662842 | 0.8509931680161943 | 0.706794028340081\n",
      "> 59 | 0.3110653758049011 | 0.6406093239784241 | 0.8509615384615384 | 0.7069205465587044\n",
      "> 60 | 0.3111931085586548 | 0.6408933401107788 | 0.8509615384615384 | 0.7069521761133604\n",
      "> 61 | 0.3113224506378174 | 0.6411685347557068 | 0.8510247975708503 | 0.7070786943319838\n",
      "> 62 | 0.311453640460968 | 0.6414478421211243 | 0.851088056680162 | 0.7067307692307693\n",
      "> 63 | 0.31158608198165894 | 0.6417204141616821 | 0.8509931680161943 | 0.7066358805668016\n",
      "> 64 | 0.3117195963859558 | 0.6419820785522461 | 0.8512778340080972 | 0.7065726214574899\n",
      "> 65 | 0.31185388565063477 | 0.6422340869903564 | 0.8510564271255061 | 0.7061930668016194\n",
      "> 66 | 0.3119889795780182 | 0.6424974203109741 | 0.8511829453441295 | 0.7061298076923077\n",
      "> 67 | 0.31212472915649414 | 0.6427413821220398 | 0.851309463562753 | 0.7056553643724697\n",
      "> 68 | 0.3122609853744507 | 0.64298415184021 | 0.8513727226720648 | 0.7057502530364372\n",
      "> 69 | 0.3123977780342102 | 0.6432281732559204 | 0.8514043522267206 | 0.7056553643724697\n",
      "> 70 | 0.31253451108932495 | 0.6434746384620667 | 0.8515941295546559 | 0.7053390688259109\n",
      "> 71 | 0.3126711845397949 | 0.6437121629714966 | 0.8515941295546559 | 0.7051809210526315\n",
      "> 72 | 0.3128077983856201 | 0.643928050994873 | 0.8515941295546559 | 0.7049595141700404\n",
      "> 73 | 0.312944233417511 | 0.6441617608070374 | 0.851815536437247 | 0.7046432186234818\n",
      "> 74 | 0.31308022141456604 | 0.6443778276443481 | 0.8519736842105263 | 0.7044534412955465\n",
      "> 75 | 0.31321561336517334 | 0.644597589969635 | 0.8519736842105263 | 0.7042636639676113\n",
      "> 76 | 0.3133505582809448 | 0.6448158025741577 | 0.8519420546558705 | 0.704105516194332\n",
      "> 77 | 0.313484787940979 | 0.6450320482254028 | 0.851815536437247 | 0.703599443319838\n",
      "> 78 | 0.3136182129383087 | 0.645222008228302 | 0.8516890182186235 | 0.7036627024291497\n",
      "> 79 | 0.31375062465667725 | 0.6454319953918457 | 0.8515625 | 0.7032198886639676\n",
      "> 80 | 0.3138819634914398 | 0.645625114440918 | 0.8515941295546559 | 0.7030301113360324\n",
      "> 81 | 0.314012348651886 | 0.6458224058151245 | 0.8516573886639676 | 0.7027770748987854\n",
      "> 82 | 0.31414175033569336 | 0.6460089683532715 | 0.8517206477732794 | 0.7026821862348178\n",
      "> 83 | 0.3142699599266052 | 0.6461993455886841 | 0.8518471659919028 | 0.7027454453441295\n",
      "> 84 | 0.3143969774246216 | 0.6463790535926819 | 0.851815536437247 | 0.7024291497975709\n",
      "> 85 | 0.31452256441116333 | 0.6465603113174438 | 0.8518471659919028 | 0.702397520242915\n",
      "> 86 | 0.31464719772338867 | 0.6467334032058716 | 0.8519420546558705 | 0.7022710020242915\n",
      "> 87 | 0.3147701323032379 | 0.6469094157218933 | 0.852036943319838 | 0.7025872975708503\n",
      "> 88 | 0.3148914575576782 | 0.6471506357192993 | 0.8521002024291497 | 0.7025556680161943\n",
      "> 89 | 0.3150119185447693 | 0.6472476720809937 | 0.8521318319838057 | 0.7024291497975709\n",
      "> 90 | 0.31513068079948425 | 0.6474151611328125 | 0.8521318319838057 | 0.7023658906882592\n",
      "> 91 | 0.3152480721473694 | 0.6475656032562256 | 0.8521634615384616 | 0.7024607793522267\n",
      "> 92 | 0.31536394357681274 | 0.6477258205413818 | 0.8522267206477733 | 0.7023342611336032\n",
      "> 93 | 0.31547844409942627 | 0.6478782892227173 | 0.8521634615384616 | 0.7022710020242915\n",
      "> 94 | 0.3155912756919861 | 0.64802086353302 | 0.8520685728744939 | 0.7019863360323887\n",
      "> 95 | 0.3157026767730713 | 0.6481692790985107 | 0.8521318319838057 | 0.7017649291497976\n",
      "> 96 | 0.31581252813339233 | 0.6483154892921448 | 0.8520685728744939 | 0.7015118927125507\n",
      "> 97 | 0.315920889377594 | 0.6484756469726562 | 0.8520685728744939 | 0.7015751518218624\n",
      "> 98 | 0.3160276710987091 | 0.6485947966575623 | 0.8519104251012146 | 0.7017016700404858\n",
      "> 99 | 0.3161329925060272 | 0.648733913898468 | 0.8518787955465587 | 0.7017016700404858\n",
      "> 100 | 0.31623685359954834 | 0.6488656997680664 | 0.8518471659919028 | 0.7017332995951417\n",
      "> Evaluation\n",
      "> Class Acc = 0.8493779897689819\n",
      "> Adv Acc = 0.8493779897689819\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8119708448648453 | 0.8985057175159454 | 0.8782778978347778\n",
      "> Confusion Matrix \n",
      "TN: 9429.0 | FP: 729.0 \n",
      "FN: 1305.0 | TP: 2041.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3786.0 | FP: 83.0 \n",
      "FN: 252.0 | TP: 259.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5643.0 | FP: 646.0 \n",
      "FN: 1053.0 | TP: 1782.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.4596793055534363 | 0.7697738409042358 | 0.6885754048582996 | 0.3253732287449393\n",
      "> 2 | 0.4322158396244049 | 0.6591687798500061 | 0.8234438259109311 | 0.4771002024291498\n",
      "> 3 | 0.42655014991760254 | 0.6087287664413452 | 0.8286943319838057 | 0.7163777834008097\n",
      "> 4 | 0.42278510332107544 | 0.5855728983879089 | 0.8321735829959515 | 0.6914853238866396\n",
      "> 5 | 0.4189048707485199 | 0.5749304294586182 | 0.8343876518218624 | 0.677979504048583\n",
      "> 6 | 0.4150156080722809 | 0.5702522993087769 | 0.836664979757085 | 0.6760501012145749\n",
      "> 7 | 0.41133344173431396 | 0.5685659050941467 | 0.8380250506072875 | 0.6760501012145749\n",
      "> 8 | 0.40795642137527466 | 0.5687124729156494 | 0.8395748987854251 | 0.6766510627530364\n",
      "> 9 | 0.40491342544555664 | 0.5699425935745239 | 0.8405237854251012 | 0.6784855769230769\n",
      "> 10 | 0.4021965563297272 | 0.5720409154891968 | 0.8410298582995951 | 0.6811424595141701\n",
      "> 11 | 0.3997798562049866 | 0.5744906663894653 | 0.8412512651821862 | 0.6836095647773279\n",
      "> 12 | 0.3976302146911621 | 0.5774438381195068 | 0.8417573380566802 | 0.6878162955465587\n",
      "> 13 | 0.3957175314426422 | 0.5803874731063843 | 0.8424215587044535 | 0.69240258097166\n",
      "> 14 | 0.39401155710220337 | 0.5834660530090332 | 0.8426745951417004 | 0.6949013157894737\n",
      "> 15 | 0.39248573780059814 | 0.5864865779876709 | 0.8426745951417004 | 0.698001012145749\n",
      "> 16 | 0.3911166787147522 | 0.5893148183822632 | 0.8432439271255061 | 0.7011955971659919\n",
      "> 17 | 0.3898841142654419 | 0.5920178890228271 | 0.8435602226720648 | 0.7036627024291497\n",
      "> 18 | 0.3887701630592346 | 0.5944424271583557 | 0.8437816295546559 | 0.7045167004048583\n",
      "> 19 | 0.3877583146095276 | 0.5966715812683105 | 0.8440979251012146 | 0.7068889170040485\n",
      "> 20 | 0.3868338465690613 | 0.5987426042556763 | 0.8442877024291497 | 0.7081540991902834\n",
      "> 21 | 0.3859848976135254 | 0.6005630493164062 | 0.8449202935222672 | 0.7097355769230769\n",
      "> 22 | 0.385200560092926 | 0.6021296977996826 | 0.8450468117408907 | 0.7116017206477733\n",
      "> 23 | 0.3844720423221588 | 0.6036062836647034 | 0.8452365890688259 | 0.7128669028340081\n",
      "> 24 | 0.3837927579879761 | 0.6048833131790161 | 0.8453314777327935 | 0.7137841599190283\n",
      "> 25 | 0.38315722346305847 | 0.6060512661933899 | 0.845932439271255 | 0.7142586032388664\n",
      "> 26 | 0.38256093859672546 | 0.6070476770401001 | 0.8459008097165992 | 0.7143851214574899\n",
      "> 27 | 0.381999671459198 | 0.6079143285751343 | 0.8462803643724697 | 0.7138157894736842\n",
      "> 28 | 0.3814702033996582 | 0.6086694598197937 | 0.8466282894736842 | 0.7140371963562753\n",
      "> 29 | 0.3809698224067688 | 0.6093879342079163 | 0.846944585020243 | 0.7138157894736842\n",
      "> 30 | 0.38049572706222534 | 0.6098976731300354 | 0.8468180668016194 | 0.7135943825910931\n",
      "> 31 | 0.3800457715988159 | 0.6104212999343872 | 0.8469762145748988 | 0.7135627530364372\n",
      "> 32 | 0.37961795926094055 | 0.6108368635177612 | 0.8474506578947368 | 0.7133097165991903\n",
      "> 33 | 0.3792106509208679 | 0.6112173795700073 | 0.8476404352226721 | 0.7129301619433198\n",
      "> 34 | 0.3788217008113861 | 0.6114803552627563 | 0.848146508097166 | 0.7126771255060729\n",
      "> 35 | 0.3784504234790802 | 0.6117602586746216 | 0.8482413967611336 | 0.712171052631579\n",
      "> 36 | 0.3780950903892517 | 0.611958920955658 | 0.8485576923076923 | 0.711918016194332\n",
      "> 37 | 0.3777546286582947 | 0.6120631694793701 | 0.8489056174089069 | 0.7116017206477733\n",
      "> 38 | 0.37742817401885986 | 0.6121883392333984 | 0.8487790991902834 | 0.7115068319838057\n",
      "> 39 | 0.3771147131919861 | 0.6122620105743408 | 0.8487790991902834 | 0.7112537955465587\n",
      "> 40 | 0.3768135905265808 | 0.6123130321502686 | 0.8487790991902834 | 0.7112854251012146\n",
      "> 41 | 0.3765239715576172 | 0.6123653650283813 | 0.8490953947368421 | 0.7109375\n",
      "> 42 | 0.3762449622154236 | 0.6123479604721069 | 0.8491586538461539 | 0.7106528340080972\n",
      "> 43 | 0.3759758472442627 | 0.6123707890510559 | 0.8489056174089069 | 0.7107477226720648\n",
      "> 44 | 0.37571603059768677 | 0.6122977137565613 | 0.848873987854251 | 0.7105579453441295\n",
      "> 45 | 0.3754656910896301 | 0.6122663021087646 | 0.8491586538461539 | 0.7101783906882592\n",
      "> 46 | 0.3752237856388092 | 0.6122061014175415 | 0.8492851720647774 | 0.7096723178137652\n",
      "> 47 | 0.37499016523361206 | 0.61211758852005 | 0.849601467611336 | 0.708976467611336\n",
      "> 48 | 0.3747643530368805 | 0.6120524406433105 | 0.8498228744939271 | 0.708976467611336\n",
      "> 49 | 0.37454599142074585 | 0.6119883060455322 | 0.849854504048583 | 0.708755060728745\n",
      "> 50 | 0.374334454536438 | 0.6118807792663574 | 0.8499810222672065 | 0.708755060728745\n",
      "> 51 | 0.3741297721862793 | 0.6117643713951111 | 0.8502024291497976 | 0.7083122469635628\n",
      "> 52 | 0.373931348323822 | 0.6116670370101929 | 0.8504238360323887 | 0.7083755060728745\n",
      "> 53 | 0.3737393021583557 | 0.6115391850471497 | 0.8505503542510121 | 0.7082806174089069\n",
      "> 54 | 0.3735530376434326 | 0.6114287376403809 | 0.8507085020242915 | 0.7079643218623481\n",
      "> 55 | 0.37337273359298706 | 0.6112987995147705 | 0.850835020242915 | 0.7076480263157895\n",
      "> 56 | 0.37319767475128174 | 0.6112155318260193 | 0.8509931680161943 | 0.7074898785425101\n",
      "> 57 | 0.373027503490448 | 0.611056923866272 | 0.8509931680161943 | 0.7073001012145749\n",
      "> 58 | 0.37286245822906494 | 0.6109594106674194 | 0.8509615384615384 | 0.7073633603238867\n",
      "> 59 | 0.37270253896713257 | 0.6108531951904297 | 0.8510247975708503 | 0.7071103238866396\n",
      "> 60 | 0.37254688143730164 | 0.6107350587844849 | 0.8511513157894737 | 0.7069521761133604\n",
      "> 61 | 0.372395783662796 | 0.6106150150299072 | 0.851088056680162 | 0.7065093623481782\n",
      "> 62 | 0.3722487986087799 | 0.6104863882064819 | 0.8512462044534413 | 0.7064777327935222\n",
      "> 63 | 0.3721061646938324 | 0.6103764772415161 | 0.8514043522267206 | 0.7064777327935222\n",
      "> 64 | 0.3719675540924072 | 0.6102120876312256 | 0.8512462044534413 | 0.7064777327935222\n",
      "> 65 | 0.3718327283859253 | 0.6100862622261047 | 0.8512145748987854 | 0.7065093623481782\n",
      "> 66 | 0.37170177698135376 | 0.6099673509597778 | 0.8513410931174089 | 0.7061930668016194\n",
      "> 67 | 0.3715742230415344 | 0.6098813414573669 | 0.8514992408906883 | 0.7058451417004049\n",
      "> 68 | 0.3714500367641449 | 0.6097573637962341 | 0.8515625 | 0.7055288461538461\n",
      "> 69 | 0.371329128742218 | 0.6096710562705994 | 0.8515941295546559 | 0.7049911437246964\n",
      "> 70 | 0.37121152877807617 | 0.6095467209815979 | 0.8516890182186235 | 0.7045483299595142\n",
      "> 71 | 0.37109699845314026 | 0.6093934774398804 | 0.8515625 | 0.7043269230769231\n",
      "> 72 | 0.3709855079650879 | 0.6092979907989502 | 0.8515941295546559 | 0.7042004048582996\n",
      "> 73 | 0.37087708711624146 | 0.6092212200164795 | 0.8515941295546559 | 0.7036943319838057\n",
      "> 74 | 0.3707713484764099 | 0.6091046333312988 | 0.8516890182186235 | 0.7034412955465587\n",
      "> 75 | 0.3706682324409485 | 0.6089849472045898 | 0.8516257591093117 | 0.7033464068825911\n",
      "> 76 | 0.37056779861450195 | 0.6089032888412476 | 0.8517522773279352 | 0.7032198886639676\n",
      "> 77 | 0.370469868183136 | 0.6087889075279236 | 0.8516890182186235 | 0.7034096659919028\n",
      "> 78 | 0.3703746497631073 | 0.6086966395378113 | 0.8518471659919028 | 0.7035361842105263\n",
      "> 79 | 0.3702816963195801 | 0.6085624694824219 | 0.8517839068825911 | 0.7031882591093117\n",
      "> 80 | 0.3701910972595215 | 0.6085125207901001 | 0.8517839068825911 | 0.7031566295546559\n",
      "> 81 | 0.37010276317596436 | 0.6083738803863525 | 0.8519420546558705 | 0.7030933704453441\n",
      "> 82 | 0.37001654505729675 | 0.6082967519760132 | 0.8518787955465587 | 0.7029035931174089\n",
      "> 83 | 0.36993253231048584 | 0.6081945896148682 | 0.8517522773279352 | 0.7027138157894737\n",
      "> 84 | 0.3698505163192749 | 0.6081287860870361 | 0.8517206477732794 | 0.702650556680162\n",
      "> 85 | 0.3697703778743744 | 0.6080209016799927 | 0.8516890182186235 | 0.7022710020242915\n",
      "> 86 | 0.36969244480133057 | 0.6079298257827759 | 0.8517206477732794 | 0.7022393724696356\n",
      "> 87 | 0.3696163594722748 | 0.6078479290008545 | 0.8518471659919028 | 0.7020495951417004\n",
      "> 88 | 0.36954203248023987 | 0.6077724695205688 | 0.8518471659919028 | 0.7022393724696356\n",
      "> 89 | 0.369469553232193 | 0.6076825857162476 | 0.852036943319838 | 0.701891447368421\n",
      "> 90 | 0.3693987727165222 | 0.6075959801673889 | 0.8521002024291497 | 0.7022077429149798\n",
      "> 91 | 0.36932986974716187 | 0.6075387597084045 | 0.8521318319838057 | 0.7020495951417004\n",
      "> 92 | 0.3692626357078552 | 0.6074566841125488 | 0.8521002024291497 | 0.7019230769230769\n",
      "> 93 | 0.36919668316841125 | 0.6073907613754272 | 0.8521002024291497 | 0.7018598178137652\n",
      "> 94 | 0.36913275718688965 | 0.6073191165924072 | 0.8520685728744939 | 0.7016067813765182\n",
      "> 95 | 0.369069904088974 | 0.607223391532898 | 0.8519420546558705 | 0.7015118927125507\n",
      "> 96 | 0.36900871992111206 | 0.6071622371673584 | 0.8518787955465587 | 0.7013537449392713\n",
      "> 97 | 0.36894911527633667 | 0.6070705056190491 | 0.8519104251012146 | 0.7013221153846154\n",
      "> 98 | 0.36889082193374634 | 0.6070058941841125 | 0.8519420546558705 | 0.7008793016194332\n",
      "> 99 | 0.3688337504863739 | 0.6069480180740356 | 0.8519736842105263 | 0.7010374493927125\n",
      "> 100 | 0.36877816915512085 | 0.6068799495697021 | 0.8520685728744939 | 0.7010374493927125\n",
      "> Evaluation\n",
      "> Class Acc = 0.8502665758132935\n",
      "> Adv Acc = 0.8502665758132935\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8049846291542053 | 0.894027765840292 | 0.8737917840480804\n",
      "> Confusion Matrix \n",
      "TN: 9403.0 | FP: 753.0 \n",
      "FN: 1269.0 | TP: 2079.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3796.0 | FP: 82.0 \n",
      "FN: 246.0 | TP: 260.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5607.0 | FP: 671.0 \n",
      "FN: 1023.0 | TP: 1819.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.45050323009490967 | 0.7390446662902832 | 0.6843686740890689 | 0.32379175101214575\n",
      "> 2 | 0.4001466929912567 | 0.6300795078277588 | 0.8224000506072875 | 0.4761829453441296\n",
      "> 3 | 0.3835076689720154 | 0.5753833055496216 | 0.8292320344129555 | 0.7171052631578947\n",
      "> 4 | 0.3756217956542969 | 0.5471106171607971 | 0.8326480263157895 | 0.6894926619433198\n",
      "> 5 | 0.37094709277153015 | 0.5303214192390442 | 0.8348304655870445 | 0.6771887651821862\n",
      "> 6 | 0.3678438067436218 | 0.5186662673950195 | 0.8372343117408907 | 0.6765561740890689\n",
      "> 7 | 0.3656565546989441 | 0.5094509124755859 | 0.8387841599190283 | 0.6764612854251012\n",
      "> 8 | 0.3640615940093994 | 0.5015902519226074 | 0.8397646761133604 | 0.676492914979757\n",
      "> 9 | 0.3628673553466797 | 0.49467384815216064 | 0.840334008097166 | 0.6774101720647774\n",
      "> 10 | 0.3619384169578552 | 0.48852241039276123 | 0.8405870445344129 | 0.6788018724696356\n",
      "> 11 | 0.3611769676208496 | 0.4831383526325226 | 0.840555414979757 | 0.6819015688259109\n",
      "> 12 | 0.36051663756370544 | 0.4784351885318756 | 0.8409033400809717 | 0.6854440789473685\n",
      "> 13 | 0.3599100708961487 | 0.4743843674659729 | 0.8418838562753036 | 0.6898089574898786\n",
      "> 14 | 0.3593292534351349 | 0.47097140550613403 | 0.8423899291497976 | 0.6937942813765182\n",
      "> 15 | 0.358756422996521 | 0.4681493639945984 | 0.8428011133603239 | 0.6984438259109311\n",
      "> 16 | 0.3581826388835907 | 0.4658260941505432 | 0.843496963562753 | 0.7013221153846154\n",
      "> 17 | 0.3576040267944336 | 0.4639614224433899 | 0.8436867408906883 | 0.7051176619433198\n",
      "> 18 | 0.3570205569267273 | 0.462475448846817 | 0.844003036437247 | 0.7084387651821862\n",
      "> 19 | 0.3564341068267822 | 0.4613111913204193 | 0.8443193319838057 | 0.7099253542510121\n",
      "> 20 | 0.35584619641304016 | 0.4604102373123169 | 0.8444458502024291 | 0.7125189777327935\n",
      "> 21 | 0.35525935888290405 | 0.4597383439540863 | 0.8447621457489879 | 0.7127403846153846\n",
      "> 22 | 0.35467684268951416 | 0.45924487709999084 | 0.844983552631579 | 0.7132148279352226\n",
      "> 23 | 0.3541003167629242 | 0.45890945196151733 | 0.8452365890688259 | 0.7147646761133604\n",
      "> 24 | 0.3535315990447998 | 0.45869874954223633 | 0.8451100708502024 | 0.7147330465587044\n",
      "> 25 | 0.35297226905822754 | 0.458595335483551 | 0.8454263663967612 | 0.7148279352226721\n",
      "> 26 | 0.35242390632629395 | 0.4585745334625244 | 0.8453947368421053 | 0.7153972672064778\n",
      "> 27 | 0.3518872857093811 | 0.4586293399333954 | 0.8453314777327935 | 0.7156503036437247\n",
      "> 28 | 0.35136348009109497 | 0.4587457478046417 | 0.8452049595141701 | 0.7157768218623481\n",
      "> 29 | 0.3508526086807251 | 0.4589087665081024 | 0.845711032388664 | 0.7155870445344129\n",
      "> 30 | 0.3503548204898834 | 0.45911723375320435 | 0.8455528846153846 | 0.7151758603238867\n",
      "> 31 | 0.34987056255340576 | 0.45935967564582825 | 0.8459008097165992 | 0.7152707489878543\n",
      "> 32 | 0.3493999242782593 | 0.45962783694267273 | 0.8462803643724697 | 0.7153656376518218\n",
      "> 33 | 0.34894245862960815 | 0.4599211812019348 | 0.8462803643724697 | 0.7151758603238867\n",
      "> 34 | 0.34849828481674194 | 0.4602336883544922 | 0.846185475708502 | 0.7147646761133604\n",
      "> 35 | 0.3480673134326935 | 0.4605608284473419 | 0.8463752530364372 | 0.7140688259109311\n",
      "> 36 | 0.3476496636867523 | 0.4608990550041199 | 0.8465334008097166 | 0.71384741902834\n",
      "> 37 | 0.3472447395324707 | 0.4612465798854828 | 0.8465650303643725 | 0.7133097165991903\n",
      "> 38 | 0.3468524217605591 | 0.4615997076034546 | 0.8468813259109311 | 0.7132148279352226\n",
      "> 39 | 0.3464724123477936 | 0.46195751428604126 | 0.8469762145748988 | 0.7130250506072875\n",
      "> 40 | 0.34610429406166077 | 0.4623182415962219 | 0.8471343623481782 | 0.7129301619433198\n",
      "> 41 | 0.34574782848358154 | 0.4626804292201996 | 0.8471027327935222 | 0.7125822368421053\n",
      "> 42 | 0.34540271759033203 | 0.4630420207977295 | 0.8471976214574899 | 0.712171052631579\n",
      "> 43 | 0.3450685739517212 | 0.4634019434452057 | 0.8473873987854251 | 0.7120445344129555\n",
      "> 44 | 0.3447452187538147 | 0.46375972032546997 | 0.8475139170040485 | 0.7117282388663968\n",
      "> 45 | 0.34443241357803345 | 0.46411430835723877 | 0.8475455465587044 | 0.7111589068825911\n",
      "> 46 | 0.3441295623779297 | 0.4644651412963867 | 0.8476720647773279 | 0.7112537955465587\n",
      "> 47 | 0.34383612871170044 | 0.4648115634918213 | 0.8476720647773279 | 0.7108109817813765\n",
      "> 48 | 0.34355202317237854 | 0.4651529788970947 | 0.8478618421052632 | 0.7108109817813765\n",
      "> 49 | 0.34327712655067444 | 0.4654895067214966 | 0.8480199898785425 | 0.7105579453441295\n",
      "> 50 | 0.34301111102104187 | 0.4658205509185791 | 0.8481781376518218 | 0.7100835020242915\n",
      "> 51 | 0.3427533507347107 | 0.4661453664302826 | 0.8483362854251012 | 0.7100518724696356\n",
      "> 52 | 0.34250372648239136 | 0.4664640724658966 | 0.8483046558704453 | 0.7092611336032388\n",
      "> 53 | 0.3422620892524719 | 0.46677660942077637 | 0.8484628036437247 | 0.7087866902834008\n",
      "> 54 | 0.34202831983566284 | 0.4670833945274353 | 0.8483362854251012 | 0.7085969129554656\n",
      "> 55 | 0.34180158376693726 | 0.4673836827278137 | 0.848367914979757 | 0.7085336538461539\n",
      "> 56 | 0.3415817618370056 | 0.46767744421958923 | 0.848367914979757 | 0.7085652834008097\n",
      "> 57 | 0.3413691222667694 | 0.4679650366306305 | 0.8484628036437247 | 0.7079326923076923\n",
      "> 58 | 0.3411629796028137 | 0.4682468771934509 | 0.8485260627530364 | 0.7077112854251012\n",
      "> 59 | 0.34096288681030273 | 0.46852120757102966 | 0.8484628036437247 | 0.7075847672064778\n",
      "> 60 | 0.3407691717147827 | 0.468789666891098 | 0.8485576923076923 | 0.7071735829959515\n",
      "> 61 | 0.3405812382698059 | 0.46905240416526794 | 0.8485260627530364 | 0.7070470647773279\n",
      "> 62 | 0.34039920568466187 | 0.46930915117263794 | 0.8486842105263158 | 0.7063828441295547\n",
      "> 63 | 0.3402225375175476 | 0.46955931186676025 | 0.8488107287449392 | 0.7062879554655871\n",
      "> 64 | 0.34005147218704224 | 0.46980464458465576 | 0.8489056174089069 | 0.7060981781376519\n",
      "> 65 | 0.3398855924606323 | 0.47004276514053345 | 0.8489372469635628 | 0.7055921052631579\n",
      "> 66 | 0.3397246301174164 | 0.47027575969696045 | 0.8490005060728745 | 0.705560475708502\n",
      "> 67 | 0.33956852555274963 | 0.47050508856773376 | 0.8490321356275303 | 0.7054339574898786\n",
      "> 68 | 0.3394169807434082 | 0.4707270860671997 | 0.8489372469635628 | 0.7053390688259109\n",
      "> 69 | 0.3392699062824249 | 0.4709433913230896 | 0.8489688765182186 | 0.7055921052631579\n",
      "> 70 | 0.3391270041465759 | 0.4711553752422333 | 0.8489688765182186 | 0.7055921052631579\n",
      "> 71 | 0.3389885425567627 | 0.47136327624320984 | 0.8490321356275303 | 0.7054972165991903\n",
      "> 72 | 0.33885401487350464 | 0.4715633988380432 | 0.8491902834008097 | 0.7052758097165992\n",
      "> 73 | 0.33872371912002563 | 0.47176092863082886 | 0.849127024291498 | 0.7051176619433198\n",
      "> 74 | 0.3385971784591675 | 0.4719539284706116 | 0.8491586538461539 | 0.7054023279352226\n",
      "> 75 | 0.33847445249557495 | 0.47214218974113464 | 0.8492219129554656 | 0.7054972165991903\n",
      "> 76 | 0.3383549153804779 | 0.4723256826400757 | 0.8491902834008097 | 0.7051809210526315\n",
      "> 77 | 0.3382389545440674 | 0.4725051522254944 | 0.8493484311740891 | 0.7052758097165992\n",
      "> 78 | 0.3381260633468628 | 0.47267913818359375 | 0.8491902834008097 | 0.7050544028340081\n",
      "> 79 | 0.33801668882369995 | 0.47285211086273193 | 0.8492851720647774 | 0.7051176619433198\n",
      "> 80 | 0.3379102945327759 | 0.4730179011821747 | 0.8493168016194332 | 0.7051492914979757\n",
      "> 81 | 0.33780717849731445 | 0.4731813967227936 | 0.8492219129554656 | 0.7049911437246964\n",
      "> 82 | 0.33770671486854553 | 0.47334176301956177 | 0.8493484311740891 | 0.7050544028340081\n",
      "> 83 | 0.33760929107666016 | 0.47349682450294495 | 0.8494116902834008 | 0.7049595141700404\n",
      "> 84 | 0.3375144600868225 | 0.47364944219589233 | 0.8495698380566802 | 0.7047064777327935\n",
      "> 85 | 0.3374221622943878 | 0.4737982749938965 | 0.8496330971659919 | 0.7046432186234818\n",
      "> 86 | 0.3373326361179352 | 0.4739442467689514 | 0.849854504048583 | 0.7044218117408907\n",
      "> 87 | 0.33724555373191833 | 0.47408682107925415 | 0.8497596153846154 | 0.704105516194332\n",
      "> 88 | 0.3371609151363373 | 0.4742256700992584 | 0.8498861336032388 | 0.7041371457489879\n",
      "> 89 | 0.3370785117149353 | 0.4743635058403015 | 0.8498861336032388 | 0.7041371457489879\n",
      "> 90 | 0.3369986116886139 | 0.47449541091918945 | 0.8499493927125507 | 0.7040738866396761\n",
      "> 91 | 0.3369206190109253 | 0.4746255874633789 | 0.8499177631578947 | 0.7039473684210527\n",
      "> 92 | 0.33684489130973816 | 0.4747526943683624 | 0.8499493927125507 | 0.703852479757085\n",
      "> 93 | 0.3367709815502167 | 0.4748786985874176 | 0.8499810222672065 | 0.7036627024291497\n",
      "> 94 | 0.3366994857788086 | 0.4749991297721863 | 0.8500759109311741 | 0.7033464068825911\n",
      "> 95 | 0.3366296887397766 | 0.4751196801662445 | 0.8500759109311741 | 0.7030933704453441\n",
      "> 96 | 0.33656203746795654 | 0.47523579001426697 | 0.8501075404858299 | 0.7030301113360324\n",
      "> 97 | 0.3364959955215454 | 0.47535085678100586 | 0.8500759109311741 | 0.7029668522267206\n",
      "> 98 | 0.3364317715167999 | 0.47546225786209106 | 0.8500442813765182 | 0.7026821862348178\n",
      "> 99 | 0.3363690972328186 | 0.47557252645492554 | 0.8500442813765182 | 0.7024291497975709\n",
      "> 100 | 0.33630824089050293 | 0.4756784439086914 | 0.8499177631578947 | 0.7022077429149798\n",
      "> Evaluation\n",
      "> Class Acc = 0.8554502129554749\n",
      "> Adv Acc = 0.8554502129554749\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8109594583511353 | 0.9111090712249279 | 0.8987425863742828\n",
      "> Confusion Matrix \n",
      "TN: 9451.0 | FP: 693.0 \n",
      "FN: 1259.0 | TP: 2101.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3841.0 | FP: 84.0 \n",
      "FN: 230.0 | TP: 269.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5610.0 | FP: 609.0 \n",
      "FN: 1029.0 | TP: 1832.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.33655276894569397 | 0.741798996925354 | 0.6892712550607287 | 0.3261007085020243\n",
      "> 2 | 0.27675962448120117 | 0.6580163836479187 | 0.8243927125506073 | 0.4718496963562753\n",
      "> 3 | 0.2582322359085083 | 0.6210532784461975 | 0.830307439271255 | 0.7147014170040485\n",
      "> 4 | 0.2505861520767212 | 0.6036715507507324 | 0.8332806174089069 | 0.6863613360323887\n",
      "> 5 | 0.247258722782135 | 0.5941875576972961 | 0.8363170546558705 | 0.6763031376518218\n",
      "> 6 | 0.2458159327507019 | 0.5878854393959045 | 0.8374240890688259 | 0.6747532894736842\n",
      "> 7 | 0.24520529806613922 | 0.5829286575317383 | 0.838626012145749 | 0.674563512145749\n",
      "> 8 | 0.2449779063463211 | 0.5786311626434326 | 0.8394800101214575 | 0.6752277327935222\n",
      "> 9 | 0.2449171394109726 | 0.5748153328895569 | 0.8400177125506073 | 0.6766826923076923\n",
      "> 10 | 0.24492251873016357 | 0.5713503360748291 | 0.8406819331983806 | 0.6779478744939271\n",
      "> 11 | 0.24494126439094543 | 0.5682826042175293 | 0.840808451417004 | 0.6796875\n",
      "> 12 | 0.24494414031505585 | 0.5655760765075684 | 0.8414094129554656 | 0.6821862348178138\n",
      "> 13 | 0.24491864442825317 | 0.5632447004318237 | 0.8415043016194332 | 0.6853491902834008\n",
      "> 14 | 0.24485740065574646 | 0.5612698793411255 | 0.8421685222672065 | 0.6923393218623481\n",
      "> 15 | 0.2447589933872223 | 0.5596163272857666 | 0.8426745951417004 | 0.6963246457489879\n",
      "> 16 | 0.24462397396564484 | 0.5582625269889832 | 0.8434653340080972 | 0.7005946356275303\n",
      "> 17 | 0.2444545179605484 | 0.5571593642234802 | 0.8438765182186235 | 0.7047381072874493\n",
      "> 18 | 0.24425405263900757 | 0.5562829375267029 | 0.8440662955465587 | 0.7076480263157895\n",
      "> 19 | 0.24402789771556854 | 0.5555759072303772 | 0.844730516194332 | 0.7101467611336032\n",
      "> 20 | 0.24377970397472382 | 0.5550144910812378 | 0.8451417004048583 | 0.7120129048582996\n",
      "> 21 | 0.2435133010149002 | 0.5545675754547119 | 0.8455212550607287 | 0.7133413461538461\n",
      "> 22 | 0.24323362112045288 | 0.5542293787002563 | 0.8456794028340081 | 0.7133097165991903\n",
      "> 23 | 0.2429436892271042 | 0.5539555549621582 | 0.845932439271255 | 0.7140688259109311\n",
      "> 24 | 0.2426462471485138 | 0.5537542104721069 | 0.8461538461538461 | 0.7151126012145749\n",
      "> 25 | 0.24234431982040405 | 0.5536066293716431 | 0.8462487348178138 | 0.7155870445344129\n",
      "> 26 | 0.2420399785041809 | 0.5535141229629517 | 0.846438512145749 | 0.7155237854251012\n",
      "> 27 | 0.24173426628112793 | 0.5534247159957886 | 0.8463436234817814 | 0.7159665991902834\n",
      "> 28 | 0.24142883718013763 | 0.5533971786499023 | 0.8464701417004049 | 0.7159033400809717\n",
      "> 29 | 0.24112531542778015 | 0.5533590316772461 | 0.8467548076923077 | 0.7148911943319838\n",
      "> 30 | 0.24082350730895996 | 0.5533757209777832 | 0.8470394736842105 | 0.7145432692307693\n",
      "> 31 | 0.2405252605676651 | 0.5533674955368042 | 0.8471027327935222 | 0.714353491902834\n",
      "> 32 | 0.24023066461086273 | 0.5534048080444336 | 0.8471976214574899 | 0.7146697874493927\n",
      "> 33 | 0.23994103074073792 | 0.5534454584121704 | 0.8471976214574899 | 0.7145116396761133\n",
      "> 34 | 0.23965558409690857 | 0.5534830093383789 | 0.8474506578947368 | 0.7143218623481782\n",
      "> 35 | 0.23937523365020752 | 0.5535374879837036 | 0.8474506578947368 | 0.7141004554655871\n",
      "> 36 | 0.23910030722618103 | 0.5535956025123596 | 0.8474506578947368 | 0.7138157894736842\n",
      "> 37 | 0.23883092403411865 | 0.5536647439002991 | 0.8476404352226721 | 0.7134678643724697\n",
      "> 38 | 0.2385675013065338 | 0.5537343621253967 | 0.847893471659919 | 0.7129301619433198\n",
      "> 39 | 0.23831027746200562 | 0.5538049340248108 | 0.847893471659919 | 0.7128352732793523\n",
      "> 40 | 0.23805898427963257 | 0.5538865327835083 | 0.8481148785425101 | 0.7122975708502024\n",
      "> 41 | 0.23781386017799377 | 0.5539579391479492 | 0.8482097672064778 | 0.7119812753036437\n",
      "> 42 | 0.23757484555244446 | 0.554023027420044 | 0.8483995445344129 | 0.7118547570850202\n",
      "> 43 | 0.23734208941459656 | 0.5541173815727234 | 0.8484311740890689 | 0.7115700910931174\n",
      "> 44 | 0.23711524903774261 | 0.5542003512382507 | 0.848620951417004 | 0.7112854251012146\n",
      "> 45 | 0.23689472675323486 | 0.5542720556259155 | 0.8487474696356275 | 0.7111589068825911\n",
      "> 46 | 0.23668023943901062 | 0.554360032081604 | 0.8487158400809717 | 0.7109058704453441\n",
      "> 47 | 0.23647165298461914 | 0.5544543266296387 | 0.8489688765182186 | 0.7110007591093117\n",
      "> 48 | 0.23626887798309326 | 0.5545326471328735 | 0.8489372469635628 | 0.7107793522267206\n",
      "> 49 | 0.23607175052165985 | 0.5546164512634277 | 0.8490953947368421 | 0.7102732793522267\n",
      "> 50 | 0.23588041961193085 | 0.554705023765564 | 0.8491902834008097 | 0.7098937246963563\n",
      "> 51 | 0.23569445312023163 | 0.5547841191291809 | 0.8493168016194332 | 0.7095457995951417\n",
      "> 52 | 0.2355138063430786 | 0.5548603534698486 | 0.8494433198380567 | 0.7094509109311741\n",
      "> 53 | 0.23533841967582703 | 0.554959774017334 | 0.8494749493927125 | 0.7093243927125507\n",
      "> 54 | 0.23516827821731567 | 0.5550279021263123 | 0.8496330971659919 | 0.708755060728745\n",
      "> 55 | 0.2350030243396759 | 0.5551067590713501 | 0.8497596153846154 | 0.7087234311740891\n",
      "> 56 | 0.23484253883361816 | 0.5551908612251282 | 0.8497279858299596 | 0.7084387651821862\n",
      "> 57 | 0.2346864640712738 | 0.5552582740783691 | 0.8497912449392713 | 0.7081540991902834\n",
      "> 58 | 0.2345350980758667 | 0.5553442239761353 | 0.8498228744939271 | 0.70802758097166\n",
      "> 59 | 0.2343883067369461 | 0.5554195642471313 | 0.8500126518218624 | 0.7079010627530364\n",
      "> 60 | 0.2342456877231598 | 0.5554931163787842 | 0.8500442813765182 | 0.7075847672064778\n",
      "> 61 | 0.23410695791244507 | 0.5555580854415894 | 0.8500442813765182 | 0.7073949898785425\n",
      "> 62 | 0.2339722365140915 | 0.5556260943412781 | 0.8500442813765182 | 0.7074582489878543\n",
      "> 63 | 0.23384125530719757 | 0.5556963086128235 | 0.8501075404858299 | 0.7071103238866396\n",
      "> 64 | 0.23371416330337524 | 0.5557700991630554 | 0.8501391700404858 | 0.7069205465587044\n",
      "> 65 | 0.23359057307243347 | 0.5558476448059082 | 0.8500442813765182 | 0.706540991902834\n",
      "> 66 | 0.23347054421901703 | 0.5559196472167969 | 0.8500759109311741 | 0.7064461032388664\n",
      "> 67 | 0.23335377871990204 | 0.5559737682342529 | 0.8501391700404858 | 0.7065726214574899\n",
      "> 68 | 0.23324045538902283 | 0.5560509562492371 | 0.8502973178137652 | 0.7062563259109311\n",
      "> 69 | 0.23313003778457642 | 0.5561008453369141 | 0.8502656882591093 | 0.7060032894736842\n",
      "> 70 | 0.23302266001701355 | 0.5561748147010803 | 0.850328947368421 | 0.7057186234817814\n",
      "> 71 | 0.2329183965921402 | 0.5562353134155273 | 0.8501707995951417 | 0.7054339574898786\n",
      "> 72 | 0.23281702399253845 | 0.5563002824783325 | 0.8502340587044535 | 0.7051492914979757\n",
      "> 73 | 0.23271852731704712 | 0.5563592314720154 | 0.8502340587044535 | 0.7049595141700404\n",
      "> 74 | 0.23262238502502441 | 0.5564306378364563 | 0.8503605769230769 | 0.7047381072874493\n",
      "> 75 | 0.23252910375595093 | 0.5564714074134827 | 0.8504238360323887 | 0.7043901821862348\n",
      "> 76 | 0.2324383556842804 | 0.5565309524536133 | 0.8503922064777328 | 0.7041371457489879\n",
      "> 77 | 0.23234978318214417 | 0.5565934181213379 | 0.8504238360323887 | 0.7042004048582996\n",
      "> 78 | 0.23226389288902283 | 0.556641697883606 | 0.8503922064777328 | 0.7044218117408907\n",
      "> 79 | 0.23218023777008057 | 0.5566980838775635 | 0.8504238360323887 | 0.704358552631579\n",
      "> 80 | 0.2320987731218338 | 0.5567529797554016 | 0.8505187246963563 | 0.704105516194332\n",
      "> 81 | 0.23201923072338104 | 0.5568164587020874 | 0.8507401315789473 | 0.7040738866396761\n",
      "> 82 | 0.23194195330142975 | 0.5568699836730957 | 0.8507085020242915 | 0.704105516194332\n",
      "> 83 | 0.2318667471408844 | 0.5569062232971191 | 0.8506768724696356 | 0.7039789979757085\n",
      "> 84 | 0.23179340362548828 | 0.5569722652435303 | 0.8508033906882592 | 0.7039157388663968\n",
      "> 85 | 0.23172202706336975 | 0.5570181608200073 | 0.8508666497975709 | 0.7036627024291497\n",
      "> 86 | 0.23165246844291687 | 0.5570721626281738 | 0.8509299089068826 | 0.7036310728744939\n",
      "> 87 | 0.23158463835716248 | 0.5571203231811523 | 0.8511196862348178 | 0.7033464068825911\n",
      "> 88 | 0.23151838779449463 | 0.5571608543395996 | 0.8511829453441295 | 0.7032515182186235\n",
      "> 89 | 0.23145397007465363 | 0.5572038292884827 | 0.8511829453441295 | 0.7031882591093117\n",
      "> 90 | 0.23139110207557678 | 0.5572586059570312 | 0.851088056680162 | 0.7029668522267206\n",
      "> 91 | 0.2313300371170044 | 0.5573011636734009 | 0.8511196862348178 | 0.7029984817813765\n",
      "> 92 | 0.23127014935016632 | 0.5573453903198242 | 0.8511513157894737 | 0.702871963562753\n",
      "> 93 | 0.23121197521686554 | 0.5574031472206116 | 0.8512778340080972 | 0.7028403340080972\n",
      "> 94 | 0.23115509748458862 | 0.5574529767036438 | 0.8512145748987854 | 0.7029668522267206\n",
      "> 95 | 0.23109963536262512 | 0.5574990510940552 | 0.8513410931174089 | 0.7029984817813765\n",
      "> 96 | 0.2310454398393631 | 0.5575224757194519 | 0.8512778340080972 | 0.7028403340080972\n",
      "> 97 | 0.23099267482757568 | 0.557586133480072 | 0.8513727226720648 | 0.7028403340080972\n",
      "> 98 | 0.2309408336877823 | 0.5576093792915344 | 0.8514043522267206 | 0.7028087044534413\n",
      "> 99 | 0.23089058697223663 | 0.557668924331665 | 0.8514359817813765 | 0.7028087044534413\n",
      "> 100 | 0.23084154725074768 | 0.5576895475387573 | 0.8514676113360324 | 0.7025872975708503\n",
      "> Evaluation\n",
      "> Class Acc = 0.8506368398666382\n",
      "> Adv Acc = 0.8506368398666382\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8131016790866852 | 0.899535097181797 | 0.8726773262023926\n",
      "> Confusion Matrix \n",
      "TN: 9418.0 | FP: 692.0 \n",
      "FN: 1325.0 | TP: 2069.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3761.0 | FP: 88.0 \n",
      "FN: 249.0 | TP: 250.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5657.0 | FP: 604.0 \n",
      "FN: 1076.0 | TP: 1819.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.405682235956192 | 0.771806001663208 | 0.6850961538461539 | 0.32632211538461536\n",
      "> 2 | 0.35319191217422485 | 0.658852219581604 | 0.8243610829959515 | 0.4673582995951417\n",
      "> 3 | 0.33594876527786255 | 0.6032298803329468 | 0.8301492914979757 | 0.7139739372469636\n",
      "> 4 | 0.32760775089263916 | 0.5743229389190674 | 0.8334387651821862 | 0.6866143724696356\n",
      "> 5 | 0.32296162843704224 | 0.5580110549926758 | 0.8363803137651822 | 0.6757338056680162\n",
      "> 6 | 0.3202672004699707 | 0.5478905439376831 | 0.838372975708502 | 0.6744686234817814\n",
      "> 7 | 0.31871718168258667 | 0.5410536527633667 | 0.8393851214574899 | 0.674310475708502\n",
      "> 8 | 0.3178544342517853 | 0.5361392498016357 | 0.8405870445344129 | 0.6746267712550608\n",
      "> 9 | 0.31739699840545654 | 0.5324816703796387 | 0.8415991902834008 | 0.6758919534412956\n",
      "> 10 | 0.3171693980693817 | 0.5297263860702515 | 0.8424215587044535 | 0.6770622469635628\n",
      "> 11 | 0.31706610321998596 | 0.527646541595459 | 0.8428643724696356 | 0.6781060222672065\n",
      "> 12 | 0.31702449917793274 | 0.5261514186859131 | 0.8433704453441295 | 0.6802884615384616\n",
      "> 13 | 0.3170107901096344 | 0.5251032710075378 | 0.8436551113360324 | 0.6846849696356275\n",
      "> 14 | 0.3170045018196106 | 0.5244461297988892 | 0.844224443319838 | 0.6902517712550608\n",
      "> 15 | 0.31699466705322266 | 0.5240777134895325 | 0.8448254048582996 | 0.6967990890688259\n",
      "> 16 | 0.3169757127761841 | 0.5239740610122681 | 0.8454896255060729 | 0.7007211538461539\n",
      "> 17 | 0.31694528460502625 | 0.5240312814712524 | 0.8459640688259109 | 0.7034412955465587\n",
      "> 18 | 0.31690287590026855 | 0.5242322683334351 | 0.8465650303643725 | 0.7057502530364372\n",
      "> 19 | 0.31684863567352295 | 0.5245195031166077 | 0.8471027327935222 | 0.7068572874493927\n",
      "> 20 | 0.3167843520641327 | 0.5248826742172241 | 0.8476404352226721 | 0.7083438765182186\n",
      "> 21 | 0.31671127676963806 | 0.5252426266670227 | 0.8479567307692307 | 0.7094509109311741\n",
      "> 22 | 0.3166310489177704 | 0.5256420373916626 | 0.8485260627530364 | 0.710684463562753\n",
      "> 23 | 0.3165445923805237 | 0.5260725617408752 | 0.848620951417004 | 0.711190536437247\n",
      "> 24 | 0.31645312905311584 | 0.5264521837234497 | 0.8489688765182186 | 0.7128036437246964\n",
      "> 25 | 0.3163567781448364 | 0.5268626809120178 | 0.849380060728745 | 0.7133097165991903\n",
      "> 26 | 0.3162558674812317 | 0.5272535085678101 | 0.849601467611336 | 0.7133413461538461\n",
      "> 27 | 0.31615132093429565 | 0.5276196599006653 | 0.8497596153846154 | 0.7132148279352226\n",
      "> 28 | 0.3160434067249298 | 0.5279553532600403 | 0.8500759109311741 | 0.713372975708502\n",
      "> 29 | 0.3159327208995819 | 0.5282754898071289 | 0.8502340587044535 | 0.7132148279352226\n",
      "> 30 | 0.3158198893070221 | 0.5286192297935486 | 0.850328947368421 | 0.713119939271255\n",
      "> 31 | 0.31570643186569214 | 0.5288999080657959 | 0.8503605769230769 | 0.7130566801619433\n",
      "> 32 | 0.3155921697616577 | 0.5291821956634521 | 0.8503922064777328 | 0.7127087550607287\n",
      "> 33 | 0.3154779076576233 | 0.5294865369796753 | 0.850581983805668 | 0.7122975708502024\n",
      "> 34 | 0.31536468863487244 | 0.5297129154205322 | 0.850835020242915 | 0.7120445344129555\n",
      "> 35 | 0.31525224447250366 | 0.5299630761146545 | 0.8510247975708503 | 0.7118863866396761\n",
      "> 36 | 0.3151414692401886 | 0.5301928520202637 | 0.851088056680162 | 0.7115700910931174\n",
      "> 37 | 0.3150330185890198 | 0.5304402709007263 | 0.8512145748987854 | 0.7113803137651822\n",
      "> 38 | 0.3149269223213196 | 0.5306491851806641 | 0.8514676113360324 | 0.711190536437247\n",
      "> 39 | 0.31482362747192383 | 0.5308557748794556 | 0.8514992408906883 | 0.7109691295546559\n",
      "> 40 | 0.3147231936454773 | 0.5310461521148682 | 0.8516257591093117 | 0.7106528340080972\n",
      "> 41 | 0.31462615728378296 | 0.5312285423278809 | 0.8516257591093117 | 0.7102416497975709\n",
      "> 42 | 0.31453216075897217 | 0.5314121246337891 | 0.8515625 | 0.7100518724696356\n",
      "> 43 | 0.31444185972213745 | 0.531592845916748 | 0.8517522773279352 | 0.7098620951417004\n",
      "> 44 | 0.31435492634773254 | 0.5317546129226685 | 0.8514992408906883 | 0.7095141700404858\n",
      "> 45 | 0.3142717182636261 | 0.5319057703018188 | 0.8514676113360324 | 0.7095774291497976\n",
      "> 46 | 0.3141920268535614 | 0.5320773124694824 | 0.8513410931174089 | 0.7095774291497976\n",
      "> 47 | 0.31411612033843994 | 0.5322088003158569 | 0.8516257591093117 | 0.7092611336032388\n",
      "> 48 | 0.3140437602996826 | 0.5323444604873657 | 0.8517522773279352 | 0.709229504048583\n",
      "> 49 | 0.31397509574890137 | 0.5324896574020386 | 0.8517206477732794 | 0.7088815789473685\n",
      "> 50 | 0.3139098584651947 | 0.5326132774353027 | 0.8519420546558705 | 0.7086285425101214\n",
      "> 51 | 0.3138483762741089 | 0.5327484607696533 | 0.852036943319838 | 0.7084071356275303\n",
      "> 52 | 0.3137902319431305 | 0.5328867435455322 | 0.8521950910931174 | 0.7081857287449392\n",
      "> 53 | 0.3137355446815491 | 0.5329948663711548 | 0.852289979757085 | 0.708248987854251\n",
      "> 54 | 0.3136841058731079 | 0.5331032872200012 | 0.8524164979757085 | 0.7081857287449392\n",
      "> 55 | 0.31363603472709656 | 0.5332146883010864 | 0.8526695344129555 | 0.7081857287449392\n",
      "> 56 | 0.3135911226272583 | 0.5333166122436523 | 0.8527011639676113 | 0.7075531376518218\n",
      "> 57 | 0.3135492205619812 | 0.5334229469299316 | 0.8527644230769231 | 0.7073001012145749\n",
      "> 58 | 0.3135102391242981 | 0.5335276126861572 | 0.852796052631579 | 0.7068572874493927\n",
      "> 59 | 0.3134741187095642 | 0.5336289405822754 | 0.8527644230769231 | 0.7070470647773279\n",
      "> 60 | 0.31344074010849 | 0.533728837966919 | 0.8527327935222672 | 0.7069521761133604\n",
      "> 61 | 0.31341007351875305 | 0.5338481664657593 | 0.8529225708502024 | 0.7064777327935222\n",
      "> 62 | 0.3133816421031952 | 0.533933162689209 | 0.8530490890688259 | 0.7059084008097166\n",
      "> 63 | 0.3133559226989746 | 0.5340166091918945 | 0.8529542004048583 | 0.7059084008097166\n",
      "> 64 | 0.31333261728286743 | 0.534103512763977 | 0.8530174595141701 | 0.7057502530364372\n",
      "> 65 | 0.3133115768432617 | 0.5341923236846924 | 0.8530490890688259 | 0.7059716599190283\n",
      "> 66 | 0.3132924437522888 | 0.5342593193054199 | 0.8530174595141701 | 0.7057818825910931\n",
      "> 67 | 0.31327545642852783 | 0.534347653388977 | 0.8530174595141701 | 0.7057186234817814\n",
      "> 68 | 0.31326034665107727 | 0.5344177484512329 | 0.8529858299595142 | 0.7055921052631579\n",
      "> 69 | 0.31324702501296997 | 0.5345034003257751 | 0.8531439777327935 | 0.7056237348178138\n",
      "> 70 | 0.3132355511188507 | 0.5345726013183594 | 0.8530807186234818 | 0.7057502530364372\n",
      "> 71 | 0.3132258653640747 | 0.5346438884735107 | 0.8531123481781376 | 0.7054023279352226\n",
      "> 72 | 0.31321752071380615 | 0.5347091555595398 | 0.8530807186234818 | 0.7051809210526315\n",
      "> 73 | 0.31321102380752563 | 0.5347933769226074 | 0.8531439777327935 | 0.705307439271255\n",
      "> 74 | 0.31320586800575256 | 0.5348476767539978 | 0.8531439777327935 | 0.704832995951417\n",
      "> 75 | 0.3132023513317108 | 0.5349441766738892 | 0.8531439777327935 | 0.7046748481781376\n",
      "> 76 | 0.3131999373435974 | 0.5349870920181274 | 0.853270495951417 | 0.7043269230769231\n",
      "> 77 | 0.31319859623908997 | 0.5350574254989624 | 0.8532388663967612 | 0.7042636639676113\n",
      "> 78 | 0.31319838762283325 | 0.5351073741912842 | 0.8533337550607287 | 0.7040106275303644\n",
      "> 79 | 0.313199520111084 | 0.5351840853691101 | 0.8533337550607287 | 0.7040106275303644\n",
      "> 80 | 0.31320175528526306 | 0.5352349281311035 | 0.853523532388664 | 0.7038841093117408\n",
      "> 81 | 0.3132047951221466 | 0.5352871417999268 | 0.8534919028340081 | 0.7036943319838057\n",
      "> 82 | 0.3132086396217346 | 0.5353356599807739 | 0.853523532388664 | 0.7034729251012146\n",
      "> 83 | 0.3132134675979614 | 0.5354101061820984 | 0.853523532388664 | 0.703378036437247\n",
      "> 84 | 0.3132191300392151 | 0.5354474782943726 | 0.853523532388664 | 0.7030301113360324\n",
      "> 85 | 0.3132256269454956 | 0.5355195999145508 | 0.8535867914979757 | 0.7027770748987854\n",
      "> 86 | 0.3132328391075134 | 0.5355622172355652 | 0.853744939271255 | 0.7027454453441295\n",
      "> 87 | 0.31324058771133423 | 0.5356104373931885 | 0.8538081983805668 | 0.7025556680161943\n",
      "> 88 | 0.31324928998947144 | 0.5356537699699402 | 0.8538398279352226 | 0.7024607793522267\n",
      "> 89 | 0.3132585287094116 | 0.5356992483139038 | 0.8539347165991903 | 0.7022710020242915\n",
      "> 90 | 0.31326818466186523 | 0.5357440710067749 | 0.8539663461538461 | 0.7019863360323887\n",
      "> 91 | 0.31327807903289795 | 0.535803496837616 | 0.8540612348178138 | 0.701891447368421\n",
      "> 92 | 0.31328874826431274 | 0.5358392000198364 | 0.8541561234817814 | 0.7018281882591093\n",
      "> 93 | 0.3132997155189514 | 0.5358827114105225 | 0.8541561234817814 | 0.7016384109311741\n",
      "> 94 | 0.3133109509944916 | 0.535925030708313 | 0.8540928643724697 | 0.7016067813765182\n",
      "> 95 | 0.31332260370254517 | 0.5359681844711304 | 0.8540928643724697 | 0.7012588562753036\n",
      "> 96 | 0.313334584236145 | 0.5360187292098999 | 0.8540928643724697 | 0.701163967611336\n",
      "> 97 | 0.31334662437438965 | 0.5360500812530518 | 0.8540612348178138 | 0.7012904858299596\n",
      "> 98 | 0.31335899233818054 | 0.5361005067825317 | 0.853997975708502 | 0.7011007085020243\n",
      "> 99 | 0.3133716285228729 | 0.5361312627792358 | 0.8540296052631579 | 0.7013221153846154\n",
      "> 100 | 0.31338441371917725 | 0.5361603498458862 | 0.853997975708502 | 0.701163967611336\n",
      "> Evaluation\n",
      "> Class Acc = 0.8476747870445251\n",
      "> Adv Acc = 0.8476747870445251\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.799657940864563 | 0.8937163278460503 | 0.8713538646697998\n",
      "> Confusion Matrix \n",
      "TN: 9335.0 | FP: 757.0 \n",
      "FN: 1300.0 | TP: 2112.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3779.0 | FP: 90.0 \n",
      "FN: 235.0 | TP: 243.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5556.0 | FP: 667.0 \n",
      "FN: 1065.0 | TP: 1869.0\n"
     ]
    }
   ],
   "source": [
    "fairdef = 'DemPar'\n",
    "\n",
    "for cv_seed in cv_seeds:\n",
    "    x_train, x_test, y_train, y_test, a_train, a_test = train_test_split(\n",
    "        x, y, a, test_size=0.3, random_state=cv_seed)\n",
    "\n",
    "    train_data = Dataset.from_tensor_slices((x_train, y_train, a_train))\n",
    "    train_data = train_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    test_data = Dataset.from_tensor_slices((x_test, y_test, a_test))\n",
    "    test_data = test_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    # train below\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "    \n",
    "    model = FairLogisticRegression(xdim, ydim, adim, batch_size, fairdef)\n",
    "    zhang_train(model, raw_data, train_data, epochs, opt)\n",
    "\n",
    "    Y, A, Y_hat, A_hat = fair_evaluation(model, test_data)\n",
    "    clas_acc, dp, deqodds, deqopp, confusion_matrix, metrics_a0, metrics_a1 = compute_metrics(Y, A, Y_hat, A_hat, adim)\n",
    "\n",
    "    fair_metrics = (dp, deqodds, deqopp)\n",
    "    tradeoff = []\n",
    "    for fair_metric in fair_metrics:\n",
    "        tradeoff.append(compute_tradeoff(clas_acc, fair_metric))\n",
    "\n",
    "    result = ['Zhang4DP', cv_seed, clas_acc, dp, deqodds, deqopp, tradeoff[0], tradeoff[1], tradeoff[2]] + metrics_a0 + metrics_a1\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    del(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhang for Eq Odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.4332188367843628 | 0.6937553286552429 | 0.6973051619433198 | 0.3402074898785425\n",
      "> 2 | 0.37514346837997437 | 0.609142541885376 | 0.8218939777327935 | 0.6475202429149798\n",
      "> 3 | 0.35245925188064575 | 0.5828326940536499 | 0.8273026315789473 | 0.7266573886639676\n",
      "> 4 | 0.3406107425689697 | 0.5754573345184326 | 0.8298962550607287 | 0.7304213056680162\n",
      "> 5 | 0.33302468061447144 | 0.575050950050354 | 0.832268471659919 | 0.7260564271255061\n",
      "> 6 | 0.3278496265411377 | 0.5773186683654785 | 0.8343243927125507 | 0.7206477732793523\n",
      "> 7 | 0.32416990399360657 | 0.580694317817688 | 0.8362854251012146 | 0.719730516194332\n",
      "> 8 | 0.32146432995796204 | 0.5845776796340942 | 0.8374873481781376 | 0.7202365890688259\n",
      "> 9 | 0.3194071352481842 | 0.5886556506156921 | 0.8385943825910931 | 0.7215334008097166\n",
      "> 10 | 0.31779399514198303 | 0.5927678346633911 | 0.8395748987854251 | 0.7226720647773279\n",
      "> 11 | 0.3164890706539154 | 0.596808910369873 | 0.8409349696356275 | 0.7233995445344129\n",
      "> 12 | 0.31540772318840027 | 0.6006931662559509 | 0.8416308198380567 | 0.7240321356275303\n",
      "> 13 | 0.3144950270652771 | 0.6043853759765625 | 0.8420103744939271 | 0.724601467611336\n",
      "> 14 | 0.31371214985847473 | 0.6078985929489136 | 0.8426745951417004 | 0.7249493927125507\n",
      "> 15 | 0.3130379021167755 | 0.6112143993377686 | 0.8431806680161943 | 0.7251707995951417\n",
      "> 16 | 0.31245410442352295 | 0.61429762840271 | 0.8437183704453441 | 0.7256768724696356\n",
      "> 17 | 0.311948299407959 | 0.6172128915786743 | 0.8440662955465587 | 0.7257401315789473\n",
      "> 18 | 0.3115116357803345 | 0.619970977306366 | 0.8446672570850202 | 0.7252973178137652\n",
      "> 19 | 0.3111337423324585 | 0.6225255727767944 | 0.8451733299595142 | 0.7244749493927125\n",
      "> 20 | 0.31080684065818787 | 0.6249379515647888 | 0.8453631072874493 | 0.7240637651821862\n",
      "> 21 | 0.3105241656303406 | 0.6271953582763672 | 0.8455528846153846 | 0.7234628036437247\n",
      "> 22 | 0.3102794587612152 | 0.6293084621429443 | 0.845932439271255 | 0.7232097672064778\n",
      "> 23 | 0.3100677728652954 | 0.6312931776046753 | 0.8461538461538461 | 0.7226088056680162\n",
      "> 24 | 0.30988478660583496 | 0.6331560611724854 | 0.8460589574898786 | 0.7222608805668016\n",
      "> 25 | 0.3097277581691742 | 0.6349450349807739 | 0.8460905870445344 | 0.7215966599190283\n",
      "> 26 | 0.30959466099739075 | 0.6365926265716553 | 0.8462171052631579 | 0.7211222165991903\n",
      "> 27 | 0.309482216835022 | 0.6381435394287109 | 0.846438512145749 | 0.720932439271255\n",
      "> 28 | 0.30938971042633057 | 0.6395946741104126 | 0.8465017712550608 | 0.7203947368421053\n",
      "> 29 | 0.30931419134140015 | 0.6410184502601624 | 0.8466282894736842 | 0.7197621457489879\n",
      "> 30 | 0.3092561364173889 | 0.6423025131225586 | 0.8464701417004049 | 0.7193509615384616\n",
      "> 31 | 0.3092135488986969 | 0.6435498595237732 | 0.8466282894736842 | 0.7188448886639676\n",
      "> 32 | 0.3091840147972107 | 0.6447405815124512 | 0.8470078441295547 | 0.7185285931174089\n",
      "> 33 | 0.3091680407524109 | 0.6458483338356018 | 0.8469129554655871 | 0.7184337044534413\n",
      "> 34 | 0.30916351079940796 | 0.6469343900680542 | 0.8471027327935222 | 0.7179592611336032\n",
      "> 35 | 0.30916982889175415 | 0.647951602935791 | 0.8472292510121457 | 0.717769483805668\n",
      "> 36 | 0.30918604135513306 | 0.6489133834838867 | 0.8475455465587044 | 0.7172634109311741\n",
      "> 37 | 0.309211790561676 | 0.6498675346374512 | 0.847893471659919 | 0.7167573380566802\n",
      "> 38 | 0.3092457950115204 | 0.650765061378479 | 0.8480516194331984 | 0.7162828947368421\n",
      "> 39 | 0.3092877268791199 | 0.6516058444976807 | 0.8481781376518218 | 0.7156503036437247\n",
      "> 40 | 0.309337317943573 | 0.6524361371994019 | 0.848146508097166 | 0.7150493421052632\n",
      "> 41 | 0.3093932569026947 | 0.6532531976699829 | 0.848367914979757 | 0.7147646761133604\n",
      "> 42 | 0.3094556927680969 | 0.6540082693099976 | 0.8484311740890689 | 0.714353491902834\n",
      "> 43 | 0.3095239996910095 | 0.6547755002975464 | 0.8485576923076923 | 0.7144800101214575\n",
      "> 44 | 0.30959826707839966 | 0.6554919481277466 | 0.84865258097166 | 0.7144800101214575\n",
      "> 45 | 0.30967748165130615 | 0.6562001705169678 | 0.848873987854251 | 0.7139106781376519\n",
      "> 46 | 0.3097614645957947 | 0.6569064855575562 | 0.8492535425101214 | 0.7133413461538461\n",
      "> 47 | 0.30984973907470703 | 0.6576123237609863 | 0.8495382085020243 | 0.7131515688259109\n",
      "> 48 | 0.30994266271591187 | 0.6582224369049072 | 0.8498228744939271 | 0.7129617914979757\n",
      "> 49 | 0.3100394606590271 | 0.6589462757110596 | 0.8501075404858299 | 0.7127403846153846\n",
      "> 50 | 0.31014031171798706 | 0.6595076322555542 | 0.8502656882591093 | 0.7122659412955465\n",
      "> 51 | 0.3102448582649231 | 0.6601943969726562 | 0.8503922064777328 | 0.7120761639676113\n",
      "> 52 | 0.3103528618812561 | 0.660709023475647 | 0.8504554655870445 | 0.7117282388663968\n",
      "> 53 | 0.3104637861251831 | 0.6613035202026367 | 0.8504238360323887 | 0.7119496457489879\n",
      "> 54 | 0.31057778000831604 | 0.6618852615356445 | 0.8503605769230769 | 0.7116966093117408\n",
      "> 55 | 0.3106946349143982 | 0.6624577641487122 | 0.8505503542510121 | 0.7113170546558705\n",
      "> 56 | 0.3108143210411072 | 0.6630128622055054 | 0.8506452429149798 | 0.7110640182186235\n",
      "> 57 | 0.31093597412109375 | 0.663558840751648 | 0.8507401315789473 | 0.7109691295546559\n",
      "> 58 | 0.31105974316596985 | 0.6640973687171936 | 0.850835020242915 | 0.7110323886639676\n",
      "> 59 | 0.31118565797805786 | 0.6646219491958618 | 0.8509615384615384 | 0.7105263157894737\n",
      "> 60 | 0.31131330132484436 | 0.6651498079299927 | 0.8510564271255061 | 0.7104314271255061\n",
      "> 61 | 0.3114427328109741 | 0.6656522154808044 | 0.8512145748987854 | 0.7100518724696356\n",
      "> 62 | 0.31157371401786804 | 0.6662150621414185 | 0.8511829453441295 | 0.7097988360323887\n",
      "> 63 | 0.3117058277130127 | 0.6666507720947266 | 0.8510564271255061 | 0.7097988360323887\n",
      "> 64 | 0.31183889508247375 | 0.6671957969665527 | 0.8512778340080972 | 0.7096723178137652\n",
      "> 65 | 0.3119731545448303 | 0.6676270365715027 | 0.8514359817813765 | 0.7095774291497976\n",
      "> 66 | 0.3121081590652466 | 0.6680810451507568 | 0.8513727226720648 | 0.7092611336032388\n",
      "> 67 | 0.31224364042282104 | 0.668541431427002 | 0.8513410931174089 | 0.7090713562753036\n",
      "> 68 | 0.31237947940826416 | 0.6689844727516174 | 0.8515308704453441 | 0.7091978744939271\n",
      "> 69 | 0.31251537799835205 | 0.6694296002388 | 0.8515308704453441 | 0.7090080971659919\n",
      "> 70 | 0.31265145540237427 | 0.6698649525642395 | 0.8515625 | 0.7089448380566802\n",
      "> 71 | 0.3127870559692383 | 0.6702871918678284 | 0.8514992408906883 | 0.7086601720647774\n",
      "> 72 | 0.31292277574539185 | 0.6707258224487305 | 0.8516573886639676 | 0.7086285425101214\n",
      "> 73 | 0.31305789947509766 | 0.6711650490760803 | 0.8517206477732794 | 0.708248987854251\n",
      "> 74 | 0.3131926655769348 | 0.6715417504310608 | 0.8518471659919028 | 0.7079326923076923\n",
      "> 75 | 0.3133269250392914 | 0.6719884872436523 | 0.8518787955465587 | 0.7076480263157895\n",
      "> 76 | 0.3134605288505554 | 0.6723124384880066 | 0.8517839068825911 | 0.7073001012145749\n",
      "> 77 | 0.31359294056892395 | 0.6726945638656616 | 0.8517839068825911 | 0.7069205465587044\n",
      "> 78 | 0.3137241005897522 | 0.6731139421463013 | 0.8517839068825911 | 0.7068256578947368\n",
      "> 79 | 0.31385523080825806 | 0.6734343767166138 | 0.8517522773279352 | 0.7067307692307693\n",
      "> 80 | 0.3139846920967102 | 0.6737916469573975 | 0.8517206477732794 | 0.7065726214574899\n",
      "> 81 | 0.3141134977340698 | 0.6741894483566284 | 0.851815536437247 | 0.7064777327935222\n",
      "> 82 | 0.31424158811569214 | 0.6744849681854248 | 0.8518787955465587 | 0.7063512145748988\n",
      "> 83 | 0.31436777114868164 | 0.6748876571655273 | 0.851815536437247 | 0.7059716599190283\n",
      "> 84 | 0.31449276208877563 | 0.6751458644866943 | 0.8518471659919028 | 0.7059084008097166\n",
      "> 85 | 0.3146161735057831 | 0.6754679083824158 | 0.8519104251012146 | 0.7058451417004049\n",
      "> 86 | 0.31473851203918457 | 0.6757869720458984 | 0.8518787955465587 | 0.7058767712550608\n",
      "> 87 | 0.31485918164253235 | 0.6760875582695007 | 0.8519420546558705 | 0.7058451417004049\n",
      "> 88 | 0.31497853994369507 | 0.6764667630195618 | 0.8519736842105263 | 0.7057818825910931\n",
      "> 89 | 0.31509679555892944 | 0.6767675876617432 | 0.8518787955465587 | 0.7056869939271255\n",
      "> 90 | 0.3152138590812683 | 0.6770423650741577 | 0.851815536437247 | 0.7055921052631579\n",
      "> 91 | 0.3153288960456848 | 0.6773388385772705 | 0.8519104251012146 | 0.7056237348178138\n",
      "> 92 | 0.31544291973114014 | 0.6775446534156799 | 0.851815536437247 | 0.7057186234817814\n",
      "> 93 | 0.31555548310279846 | 0.6778457164764404 | 0.8519420546558705 | 0.7056237348178138\n",
      "> 94 | 0.31566640734672546 | 0.6781105995178223 | 0.8519104251012146 | 0.7056237348178138\n",
      "> 95 | 0.31577596068382263 | 0.6784079074859619 | 0.8520053137651822 | 0.7054972165991903\n",
      "> 96 | 0.31588396430015564 | 0.6786234378814697 | 0.8519420546558705 | 0.7056869939271255\n",
      "> 97 | 0.31599050760269165 | 0.6788505911827087 | 0.8519420546558705 | 0.7056869939271255\n",
      "> 98 | 0.31609582901000977 | 0.6791161894798279 | 0.8519104251012146 | 0.7055288461538461\n",
      "> 99 | 0.31619971990585327 | 0.679323673248291 | 0.8520053137651822 | 0.7054655870445344\n",
      "> 100 | 0.3163020610809326 | 0.6795570850372314 | 0.8518787955465587 | 0.705307439271255\n",
      "> Evaluation\n",
      "> Class Acc = 0.8499704003334045\n",
      "> Adv Acc = 0.8499704003334045\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.811158075928688 | 0.8971519619226456 | 0.8759682178497314\n",
      "> Confusion Matrix \n",
      "TN: 9437.0 | FP: 721.0 \n",
      "FN: 1305.0 | TP: 2041.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3790.0 | FP: 79.0 \n",
      "FN: 253.0 | TP: 258.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5647.0 | FP: 642.0 \n",
      "FN: 1052.0 | TP: 1783.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.4596228003501892 | 0.7111940979957581 | 0.7000253036437247 | 0.342042004048583\n",
      "> 2 | 0.43159055709838867 | 0.6053827404975891 | 0.8214827935222672 | 0.6500506072874493\n",
      "> 3 | 0.42569679021835327 | 0.5687546133995056 | 0.8269547064777328 | 0.7269420546558705\n",
      "> 4 | 0.42142152786254883 | 0.5573660731315613 | 0.8303390688259109 | 0.7311171558704453\n",
      "> 5 | 0.41728049516677856 | 0.5553532242774963 | 0.8328378036437247 | 0.7215650303643725\n",
      "> 6 | 0.41332751512527466 | 0.5571285486221313 | 0.8347355769230769 | 0.7176429655870445\n",
      "> 7 | 0.4096885919570923 | 0.5606077909469604 | 0.8368231275303644 | 0.7166940789473685\n",
      "> 8 | 0.40641117095947266 | 0.5646539926528931 | 0.8381831983805668 | 0.7171685222672065\n",
      "> 9 | 0.40348708629608154 | 0.5687392950057983 | 0.8390055668016194 | 0.7181174089068826\n",
      "> 10 | 0.4008919894695282 | 0.5726133584976196 | 0.8396697874493927 | 0.7200784412955465\n",
      "> 11 | 0.39858925342559814 | 0.5760436058044434 | 0.8403023785425101 | 0.7215650303643725\n",
      "> 12 | 0.39654362201690674 | 0.5791742205619812 | 0.8413777834008097 | 0.7236842105263158\n",
      "> 13 | 0.39471954107284546 | 0.5818561315536499 | 0.8417257085020243 | 0.7242851720647774\n",
      "> 14 | 0.39308542013168335 | 0.5843478441238403 | 0.8422317813765182 | 0.7241902834008097\n",
      "> 15 | 0.3916160762310028 | 0.5865619778633118 | 0.8426745951417004 | 0.7252024291497976\n",
      "> 16 | 0.3902885317802429 | 0.5885034799575806 | 0.8432122975708503 | 0.7253922064777328\n",
      "> 17 | 0.38908347487449646 | 0.590319037437439 | 0.8433071862348178 | 0.7253605769230769\n",
      "> 18 | 0.3879851698875427 | 0.5920250415802002 | 0.8439397773279352 | 0.7250126518218624\n",
      "> 19 | 0.38697975873947144 | 0.5934889912605286 | 0.8440979251012146 | 0.7244433198380567\n",
      "> 20 | 0.3860546052455902 | 0.5948233604431152 | 0.8446039979757085 | 0.7239372469635628\n",
      "> 21 | 0.38519999384880066 | 0.5960514545440674 | 0.8452682186234818 | 0.7232413967611336\n",
      "> 22 | 0.3844067454338074 | 0.5971498489379883 | 0.8451733299595142 | 0.7227985829959515\n",
      "> 23 | 0.38366782665252686 | 0.5981553792953491 | 0.8457426619433198 | 0.7224506578947368\n",
      "> 24 | 0.38297754526138306 | 0.5990200042724609 | 0.8459956983805668 | 0.7220394736842105\n",
      "> 25 | 0.3823309540748596 | 0.5997222661972046 | 0.8461538461538461 | 0.7215017712550608\n",
      "> 26 | 0.38172411918640137 | 0.6004241108894348 | 0.846438512145749 | 0.7212171052631579\n",
      "> 27 | 0.381152868270874 | 0.6009841561317444 | 0.8468180668016194 | 0.7209008097165992\n",
      "> 28 | 0.3806147575378418 | 0.6014993190765381 | 0.8468813259109311 | 0.7203947368421053\n",
      "> 29 | 0.38010644912719727 | 0.6019256114959717 | 0.8468180668016194 | 0.7198886639676113\n",
      "> 30 | 0.37962576746940613 | 0.6023601293563843 | 0.8470078441295547 | 0.7195723684210527\n",
      "> 31 | 0.37917035818099976 | 0.6026777029037476 | 0.8471976214574899 | 0.7190662955465587\n",
      "> 32 | 0.37873780727386475 | 0.6029367446899414 | 0.8474506578947368 | 0.7186234817813765\n",
      "> 33 | 0.378326416015625 | 0.6031054258346558 | 0.8474822874493927 | 0.7183704453441295\n",
      "> 34 | 0.3779348134994507 | 0.6033004522323608 | 0.8475139170040485 | 0.718022520242915\n",
      "> 35 | 0.37756115198135376 | 0.6034239530563354 | 0.8477036943319838 | 0.7178011133603239\n",
      "> 36 | 0.3772047758102417 | 0.6035904884338379 | 0.8478618421052632 | 0.7171052631578947\n",
      "> 37 | 0.3768642246723175 | 0.6036276817321777 | 0.848146508097166 | 0.7165359311740891\n",
      "> 38 | 0.376537948846817 | 0.60370272397995 | 0.8483362854251012 | 0.7161247469635628\n",
      "> 39 | 0.37622472643852234 | 0.603731632232666 | 0.848367914979757 | 0.71584008097166\n",
      "> 40 | 0.37592431902885437 | 0.6037718653678894 | 0.8484944331983806 | 0.7154921558704453\n",
      "> 41 | 0.37563556432724 | 0.6037738919258118 | 0.8485893218623481 | 0.7152074898785425\n",
      "> 42 | 0.3753582537174225 | 0.6037559509277344 | 0.848873987854251 | 0.7151758603238867\n",
      "> 43 | 0.375091016292572 | 0.6037753820419312 | 0.848873987854251 | 0.7146381578947368\n",
      "> 44 | 0.37483394145965576 | 0.6036696434020996 | 0.8489372469635628 | 0.7139739372469636\n",
      "> 45 | 0.37458598613739014 | 0.6036087274551392 | 0.8490637651821862 | 0.7135943825910931\n",
      "> 46 | 0.37434685230255127 | 0.6035381555557251 | 0.8491586538461539 | 0.7131831983805668\n",
      "> 47 | 0.37411585450172424 | 0.6034736633300781 | 0.849380060728745 | 0.712898532388664\n",
      "> 48 | 0.37389254570007324 | 0.6033949851989746 | 0.8493484311740891 | 0.7128669028340081\n",
      "> 49 | 0.3736768364906311 | 0.6032886505126953 | 0.8494433198380567 | 0.7123292004048583\n",
      "> 50 | 0.37346816062927246 | 0.6032168865203857 | 0.8497279858299596 | 0.7122975708502024\n",
      "> 51 | 0.37326639890670776 | 0.6031543016433716 | 0.8497912449392713 | 0.7120129048582996\n",
      "> 52 | 0.37307095527648926 | 0.6030320525169373 | 0.8500442813765182 | 0.7114752024291497\n",
      "> 53 | 0.3728819787502289 | 0.6029418706893921 | 0.8502340587044535 | 0.7111272773279352\n",
      "> 54 | 0.3726980984210968 | 0.6028722524642944 | 0.8502656882591093 | 0.7106528340080972\n",
      "> 55 | 0.37252044677734375 | 0.6027320623397827 | 0.850328947368421 | 0.7105895748987854\n",
      "> 56 | 0.37234801054000854 | 0.6026550531387329 | 0.850581983805668 | 0.7103365384615384\n",
      "> 57 | 0.3721809983253479 | 0.6025543212890625 | 0.8507085020242915 | 0.7100835020242915\n",
      "> 58 | 0.3720187246799469 | 0.6024292707443237 | 0.8506452429149798 | 0.7097988360323887\n",
      "> 59 | 0.3718613088130951 | 0.6023421287536621 | 0.8509299089068826 | 0.7096406882591093\n",
      "> 60 | 0.37170863151550293 | 0.6022363901138306 | 0.851088056680162 | 0.7093243927125507\n",
      "> 61 | 0.37156015634536743 | 0.6021381616592407 | 0.8511513157894737 | 0.7093243927125507\n",
      "> 62 | 0.37141597270965576 | 0.6020099520683289 | 0.8512462044534413 | 0.7090713562753036\n",
      "> 63 | 0.37127548456192017 | 0.601948082447052 | 0.8511196862348178 | 0.7089132085020243\n",
      "> 64 | 0.3711393177509308 | 0.601828932762146 | 0.8511513157894737 | 0.7088499493927125\n",
      "> 65 | 0.37100687623023987 | 0.6017293334007263 | 0.8511829453441295 | 0.708976467611336\n",
      "> 66 | 0.3708778917789459 | 0.6016157269477844 | 0.851309463562753 | 0.7088815789473685\n",
      "> 67 | 0.3707526624202728 | 0.6015297174453735 | 0.8512778340080972 | 0.7086285425101214\n",
      "> 68 | 0.37063056230545044 | 0.6014089584350586 | 0.8511513157894737 | 0.7084071356275303\n",
      "> 69 | 0.37051185965538025 | 0.6013444066047668 | 0.851309463562753 | 0.7085969129554656\n",
      "> 70 | 0.3703959882259369 | 0.6012349128723145 | 0.8513410931174089 | 0.7081857287449392\n",
      "> 71 | 0.3702830374240875 | 0.6011399030685425 | 0.8513410931174089 | 0.7077745445344129\n",
      "> 72 | 0.37017330527305603 | 0.601048469543457 | 0.8512778340080972 | 0.7078378036437247\n",
      "> 73 | 0.3700663447380066 | 0.600939929485321 | 0.8513727226720648 | 0.7078378036437247\n",
      "> 74 | 0.369962215423584 | 0.6008799076080322 | 0.8513410931174089 | 0.7076163967611336\n",
      "> 75 | 0.3698608875274658 | 0.6007794141769409 | 0.8513410931174089 | 0.7073633603238867\n",
      "> 76 | 0.3697620630264282 | 0.6007100343704224 | 0.8513410931174089 | 0.7073317307692307\n",
      "> 77 | 0.36966565251350403 | 0.6006085276603699 | 0.8514043522267206 | 0.7073317307692307\n",
      "> 78 | 0.3695715665817261 | 0.6005076766014099 | 0.8513410931174089 | 0.707268471659919\n",
      "> 79 | 0.36948010325431824 | 0.6004353761672974 | 0.8511829453441295 | 0.7070470647773279\n",
      "> 80 | 0.369390606880188 | 0.6003654599189758 | 0.8512145748987854 | 0.7068572874493927\n",
      "> 81 | 0.3693036437034607 | 0.6002792119979858 | 0.8512462044534413 | 0.7068889170040485\n",
      "> 82 | 0.36921870708465576 | 0.6002285480499268 | 0.8512145748987854 | 0.706794028340081\n",
      "> 83 | 0.36913585662841797 | 0.6001089811325073 | 0.8512462044534413 | 0.7066358805668016\n",
      "> 84 | 0.36905473470687866 | 0.6000514030456543 | 0.8513410931174089 | 0.7064777327935222\n",
      "> 85 | 0.36897581815719604 | 0.5999659299850464 | 0.851309463562753 | 0.7061614372469636\n",
      "> 86 | 0.36889901757240295 | 0.5999314785003662 | 0.8514676113360324 | 0.7059084008097166\n",
      "> 87 | 0.36882397532463074 | 0.599818229675293 | 0.8515308704453441 | 0.7059084008097166\n",
      "> 88 | 0.3687507212162018 | 0.5997866988182068 | 0.8515625 | 0.7057818825910931\n",
      "> 89 | 0.3686792850494385 | 0.5997169017791748 | 0.8518471659919028 | 0.7057502530364372\n",
      "> 90 | 0.3686094880104065 | 0.5996373891830444 | 0.8519420546558705 | 0.7054339574898786\n",
      "> 91 | 0.3685413897037506 | 0.5995835661888123 | 0.8519420546558705 | 0.7054339574898786\n",
      "> 92 | 0.368475079536438 | 0.5995138883590698 | 0.8519736842105263 | 0.7052441801619433\n",
      "> 93 | 0.3684101700782776 | 0.5994585752487183 | 0.8519736842105263 | 0.7052441801619433\n",
      "> 94 | 0.3683468699455261 | 0.5993795394897461 | 0.852036943319838 | 0.7052758097165992\n",
      "> 95 | 0.3682846426963806 | 0.5993094444274902 | 0.8519104251012146 | 0.7052441801619433\n",
      "> 96 | 0.3682243227958679 | 0.5992724299430847 | 0.8518787955465587 | 0.7050544028340081\n",
      "> 97 | 0.3681652843952179 | 0.5992116928100586 | 0.8518787955465587 | 0.7049595141700404\n",
      "> 98 | 0.368107408285141 | 0.5991432070732117 | 0.8519736842105263 | 0.7049278846153846\n",
      "> 99 | 0.3680512607097626 | 0.5991020202636719 | 0.8520053137651822 | 0.7046432186234818\n",
      "> 100 | 0.3679962456226349 | 0.5990357995033264 | 0.8521002024291497 | 0.7047064777327935\n",
      "> Evaluation\n",
      "> Class Acc = 0.8498963117599487\n",
      "> Adv Acc = 0.8498963117599487\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.803760901093483 | 0.8922568969428539 | 0.8714636266231537\n",
      "> Confusion Matrix \n",
      "TN: 9398.0 | FP: 758.0 \n",
      "FN: 1269.0 | TP: 2079.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3797.0 | FP: 81.0 \n",
      "FN: 247.0 | TP: 259.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5601.0 | FP: 677.0 \n",
      "FN: 1022.0 | TP: 1820.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.44134604930877686 | 0.6611076593399048 | 0.6964827935222672 | 0.3402074898785425\n",
      "> 2 | 0.3953996002674103 | 0.5472602844238281 | 0.8224633097165992 | 0.6460336538461539\n",
      "> 3 | 0.3813907206058502 | 0.5005918145179749 | 0.8277454453441295 | 0.7301366396761133\n",
      "> 4 | 0.3743615746498108 | 0.4779013395309448 | 0.831066548582996 | 0.732192560728745\n",
      "> 5 | 0.37012284994125366 | 0.4655665159225464 | 0.8333122469635628 | 0.7256768724696356\n",
      "> 6 | 0.36725807189941406 | 0.4578500986099243 | 0.8359058704453441 | 0.7219762145748988\n",
      "> 7 | 0.3652023673057556 | 0.45265993475914 | 0.8377720141700404 | 0.7205845141700404\n",
      "> 8 | 0.36366862058639526 | 0.4491032361984253 | 0.8387209008097166 | 0.7220711032388664\n",
      "> 9 | 0.36248087882995605 | 0.4467718303203583 | 0.8391953441295547 | 0.7229251012145749\n",
      "> 10 | 0.3615148663520813 | 0.44537854194641113 | 0.839606528340081 | 0.7243484311740891\n",
      "> 11 | 0.3606858253479004 | 0.44477567076683044 | 0.8397330465587044 | 0.7252024291497976\n",
      "> 12 | 0.35993504524230957 | 0.44474005699157715 | 0.8404288967611336 | 0.7261196862348178\n",
      "> 13 | 0.359224796295166 | 0.44513818621635437 | 0.8413777834008097 | 0.727289979757085\n",
      "> 14 | 0.3585340082645416 | 0.4458754360675812 | 0.8419471153846154 | 0.7274164979757085\n",
      "> 15 | 0.3578526973724365 | 0.4468080997467041 | 0.8424215587044535 | 0.7273216093117408\n",
      "> 16 | 0.3571764826774597 | 0.44788306951522827 | 0.8428960020242915 | 0.7266257591093117\n",
      "> 17 | 0.3565039038658142 | 0.44901198148727417 | 0.8431174089068826 | 0.7264359817813765\n",
      "> 18 | 0.35583627223968506 | 0.4501723051071167 | 0.8435285931174089 | 0.7261829453441295\n",
      "> 19 | 0.35517629981040955 | 0.4513242244720459 | 0.8441611842105263 | 0.7259615384615384\n",
      "> 20 | 0.35452497005462646 | 0.45244795083999634 | 0.8444458502024291 | 0.7250442813765182\n",
      "> 21 | 0.3538854122161865 | 0.45354145765304565 | 0.8446672570850202 | 0.724854504048583\n",
      "> 22 | 0.3532593548297882 | 0.45459234714508057 | 0.8449519230769231 | 0.7244749493927125\n",
      "> 23 | 0.3526468276977539 | 0.45559680461883545 | 0.8451733299595142 | 0.7242851720647774\n",
      "> 24 | 0.3520500659942627 | 0.4565677344799042 | 0.8452365890688259 | 0.7239688765182186\n",
      "> 25 | 0.35146966576576233 | 0.4574839770793915 | 0.845457995951417 | 0.7235260627530364\n",
      "> 26 | 0.3509063124656677 | 0.4583667814731598 | 0.8452998481781376 | 0.7229883603238867\n",
      "> 27 | 0.3503596782684326 | 0.4592069685459137 | 0.8453631072874493 | 0.7223557692307693\n",
      "> 28 | 0.3498300313949585 | 0.4600135087966919 | 0.8456477732793523 | 0.7217864372469636\n",
      "> 29 | 0.34931680560112 | 0.4607793688774109 | 0.845932439271255 | 0.7211222165991903\n",
      "> 30 | 0.34882065653800964 | 0.46151286363601685 | 0.8459008097165992 | 0.7205528846153846\n",
      "> 31 | 0.34834080934524536 | 0.4622141718864441 | 0.845932439271255 | 0.7201100708502024\n",
      "> 32 | 0.3478766977787018 | 0.4628886282444 | 0.8459640688259109 | 0.7196672570850202\n",
      "> 33 | 0.34742772579193115 | 0.46353408694267273 | 0.8459008097165992 | 0.7191928137651822\n",
      "> 34 | 0.34699395298957825 | 0.464145302772522 | 0.8459640688259109 | 0.7185918522267206\n",
      "> 35 | 0.3465745151042938 | 0.46473926305770874 | 0.8460905870445344 | 0.7181174089068826\n",
      "> 36 | 0.34616902470588684 | 0.4653059244155884 | 0.8462487348178138 | 0.717516447368421\n",
      "> 37 | 0.34577804803848267 | 0.465850293636322 | 0.8464701417004049 | 0.7166940789473685\n",
      "> 38 | 0.3453998863697052 | 0.46638399362564087 | 0.8464701417004049 | 0.7161247469635628\n",
      "> 39 | 0.34503406286239624 | 0.46688956022262573 | 0.8465650303643725 | 0.715808451417004\n",
      "> 40 | 0.3446809649467468 | 0.4673702120780945 | 0.8465650303643725 | 0.7155237854251012\n",
      "> 41 | 0.3443397283554077 | 0.4678384065628052 | 0.8469762145748988 | 0.7151126012145749\n",
      "> 42 | 0.3440094590187073 | 0.4682949185371399 | 0.846944585020243 | 0.7150177125506073\n",
      "> 43 | 0.34369081258773804 | 0.46872174739837646 | 0.8472292510121457 | 0.7148595647773279\n",
      "> 44 | 0.34338194131851196 | 0.4691483974456787 | 0.8474506578947368 | 0.7143851214574899\n",
      "> 45 | 0.34308403730392456 | 0.46955063939094543 | 0.8476404352226721 | 0.7141637145748988\n",
      "> 46 | 0.3427956700325012 | 0.4699424207210541 | 0.8479567307692307 | 0.7135943825910931\n",
      "> 47 | 0.34251639246940613 | 0.47032231092453003 | 0.8479883603238867 | 0.7133097165991903\n",
      "> 48 | 0.3422468304634094 | 0.4706892967224121 | 0.8481781376518218 | 0.7132780870445344\n",
      "> 49 | 0.3419858515262604 | 0.47104352712631226 | 0.8482097672064778 | 0.7128669028340081\n",
      "> 50 | 0.34173354506492615 | 0.47138115763664246 | 0.848367914979757 | 0.7128036437246964\n",
      "> 51 | 0.34148961305618286 | 0.47171249985694885 | 0.8484628036437247 | 0.7125506072874493\n",
      "> 52 | 0.34125247597694397 | 0.47203701734542847 | 0.8484311740890689 | 0.7126138663967612\n",
      "> 53 | 0.3410238027572632 | 0.4723421335220337 | 0.8487158400809717 | 0.712645495951417\n",
      "> 54 | 0.3408016860485077 | 0.4726470112800598 | 0.8485260627530364 | 0.7123608299595142\n",
      "> 55 | 0.3405865728855133 | 0.47293728590011597 | 0.8484311740890689 | 0.7117914979757085\n",
      "> 56 | 0.3403785824775696 | 0.4732200503349304 | 0.8485893218623481 | 0.7114435728744939\n",
      "> 57 | 0.3401767313480377 | 0.4734984040260315 | 0.84865258097166 | 0.7112537955465587\n",
      "> 58 | 0.3399811089038849 | 0.47376030683517456 | 0.8487474696356275 | 0.7109058704453441\n",
      "> 59 | 0.3397917151451111 | 0.4740232825279236 | 0.8488423582995951 | 0.7107477226720648\n",
      "> 60 | 0.339607834815979 | 0.4742635488510132 | 0.8487474696356275 | 0.7105579453441295\n",
      "> 61 | 0.33943039178848267 | 0.474511981010437 | 0.8490005060728745 | 0.7104314271255061\n",
      "> 62 | 0.3392583429813385 | 0.47474730014801025 | 0.8490321356275303 | 0.7102732793522267\n",
      "> 63 | 0.3390902876853943 | 0.47498631477355957 | 0.8490321356275303 | 0.7100518724696356\n",
      "> 64 | 0.3389282822608948 | 0.4752100110054016 | 0.8490953947368421 | 0.7098304655870445\n",
      "> 65 | 0.3387710452079773 | 0.4754296839237213 | 0.8489688765182186 | 0.7098620951417004\n",
      "> 66 | 0.33861827850341797 | 0.4756236672401428 | 0.8489372469635628 | 0.7097672064777328\n",
      "> 67 | 0.33847033977508545 | 0.47584646940231323 | 0.8490005060728745 | 0.7094825404858299\n",
      "> 68 | 0.3383268713951111 | 0.47604185342788696 | 0.8491586538461539 | 0.708976467611336\n",
      "> 69 | 0.33818742632865906 | 0.4762333333492279 | 0.849127024291498 | 0.7088499493927125\n",
      "> 70 | 0.338051974773407 | 0.4764332175254822 | 0.849127024291498 | 0.708502024291498\n",
      "> 71 | 0.3379209637641907 | 0.4766128659248352 | 0.8491586538461539 | 0.7085969129554656\n",
      "> 72 | 0.3377933204174042 | 0.47679752111434937 | 0.8490637651821862 | 0.7082173582995951\n",
      "> 73 | 0.337669312953949 | 0.47696271538734436 | 0.8490953947368421 | 0.7080908400809717\n",
      "> 74 | 0.33754897117614746 | 0.4771459102630615 | 0.8490637651821862 | 0.7076796558704453\n",
      "> 75 | 0.33743250370025635 | 0.477313756942749 | 0.8490637651821862 | 0.7074266194331984\n",
      "> 76 | 0.33731919527053833 | 0.4774715304374695 | 0.8490953947368421 | 0.7073317307692307\n",
      "> 77 | 0.33720898628234863 | 0.4776262640953064 | 0.8490637651821862 | 0.7071103238866396\n",
      "> 78 | 0.33710235357284546 | 0.477789044380188 | 0.8489688765182186 | 0.7070154352226721\n",
      "> 79 | 0.3369988799095154 | 0.47792690992355347 | 0.8490005060728745 | 0.7071419534412956\n",
      "> 80 | 0.3368980288505554 | 0.47808024287223816 | 0.8490321356275303 | 0.707268471659919\n",
      "> 81 | 0.3368004560470581 | 0.47823214530944824 | 0.8490953947368421 | 0.7069205465587044\n",
      "> 82 | 0.3367053270339966 | 0.47837018966674805 | 0.8492535425101214 | 0.7068889170040485\n",
      "> 83 | 0.3366132974624634 | 0.4785110354423523 | 0.8493168016194332 | 0.7069521761133604\n",
      "> 84 | 0.3365238904953003 | 0.4786338210105896 | 0.849380060728745 | 0.7068256578947368\n",
      "> 85 | 0.33643651008605957 | 0.47877925634384155 | 0.849601467611336 | 0.7069521761133604\n",
      "> 86 | 0.33635157346725464 | 0.47889262437820435 | 0.8495698380566802 | 0.706540991902834\n",
      "> 87 | 0.3362690210342407 | 0.4790322184562683 | 0.8495382085020243 | 0.7066358805668016\n",
      "> 88 | 0.3361891508102417 | 0.4791584610939026 | 0.849601467611336 | 0.7066675101214575\n",
      "> 89 | 0.33611106872558594 | 0.47927552461624146 | 0.8496647267206477 | 0.7065093623481782\n",
      "> 90 | 0.3360353708267212 | 0.4793948233127594 | 0.8497596153846154 | 0.7066042510121457\n",
      "> 91 | 0.335962176322937 | 0.4795069694519043 | 0.8497912449392713 | 0.706319585020243\n",
      "> 92 | 0.33589041233062744 | 0.4796209931373596 | 0.8495065789473685 | 0.7060032894736842\n",
      "> 93 | 0.3358209729194641 | 0.47972962260246277 | 0.8494749493927125 | 0.7057502530364372\n",
      "> 94 | 0.3357534408569336 | 0.47982391715049744 | 0.8495382085020243 | 0.7057818825910931\n",
      "> 95 | 0.33568790555000305 | 0.47994232177734375 | 0.849601467611336 | 0.7056553643724697\n",
      "> 96 | 0.3356238603591919 | 0.48004502058029175 | 0.8494433198380567 | 0.7057186234817814\n",
      "> 97 | 0.3355618119239807 | 0.48014938831329346 | 0.8495065789473685 | 0.7056237348178138\n",
      "> 98 | 0.33550122380256653 | 0.4802488684654236 | 0.849601467611336 | 0.7057502530364372\n",
      "> 99 | 0.33544182777404785 | 0.4803444743156433 | 0.8497279858299596 | 0.7055288461538461\n",
      "> 100 | 0.3353845477104187 | 0.48043036460876465 | 0.8497596153846154 | 0.7055288461538461\n",
      "> Evaluation\n",
      "> Class Acc = 0.8553021550178528\n",
      "> Adv Acc = 0.8553021550178528\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8100783824920654 | 0.9111517854034901 | 0.9000475704669952\n",
      "> Confusion Matrix \n",
      "TN: 9446.0 | FP: 698.0 \n",
      "FN: 1256.0 | TP: 2104.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3842.0 | FP: 83.0 \n",
      "FN: 229.0 | TP: 270.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5604.0 | FP: 615.0 \n",
      "FN: 1027.0 | TP: 1834.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.3585522174835205 | 0.6912503838539124 | 0.6993610829959515 | 0.34264296558704455\n",
      "> 2 | 0.28646308183670044 | 0.606864869594574 | 0.823728491902834 | 0.6386955971659919\n",
      "> 3 | 0.2633441686630249 | 0.57532799243927 | 0.8286310728744939 | 0.7272583502024291\n",
      "> 4 | 0.2544005811214447 | 0.5613281726837158 | 0.8316991396761133 | 0.7309273785425101\n",
      "> 5 | 0.2502884864807129 | 0.5538553595542908 | 0.834229504048583 | 0.7248861336032388\n",
      "> 6 | 0.24826841056346893 | 0.5490707159042358 | 0.836190536437247 | 0.7200151821862348\n",
      "> 7 | 0.2472095787525177 | 0.5456336736679077 | 0.8375506072874493 | 0.7197621457489879\n",
      "> 8 | 0.2466285675764084 | 0.5430158376693726 | 0.8387525303643725 | 0.7206477732793523\n",
      "> 9 | 0.24628417193889618 | 0.5409833788871765 | 0.8396381578947368 | 0.7228618421052632\n",
      "> 10 | 0.2460717260837555 | 0.5394275188446045 | 0.8406186740890689 | 0.7244433198380567\n",
      "> 11 | 0.2459167242050171 | 0.5382571220397949 | 0.8413777834008097 | 0.7248861336032388\n",
      "> 12 | 0.2457951307296753 | 0.5374302864074707 | 0.8413777834008097 | 0.7235260627530364\n",
      "> 13 | 0.24567671120166779 | 0.5368540287017822 | 0.8418205971659919 | 0.7240953947368421\n",
      "> 14 | 0.24555319547653198 | 0.5365201234817505 | 0.8425797064777328 | 0.7240953947368421\n",
      "> 15 | 0.24541091918945312 | 0.5363640785217285 | 0.8429908906882592 | 0.7251707995951417\n",
      "> 16 | 0.2452487200498581 | 0.5363330841064453 | 0.8435602226720648 | 0.7249493927125507\n",
      "> 17 | 0.24506570398807526 | 0.5364012122154236 | 0.8441928137651822 | 0.7247596153846154\n",
      "> 18 | 0.24486052989959717 | 0.5365215539932251 | 0.8445407388663968 | 0.7254870951417004\n",
      "> 19 | 0.2446354627609253 | 0.5367037653923035 | 0.8450784412955465 | 0.7252656882591093\n",
      "> 20 | 0.24439242482185364 | 0.5368991494178772 | 0.845457995951417 | 0.7253605769230769\n",
      "> 21 | 0.24413582682609558 | 0.5371149182319641 | 0.8456477732793523 | 0.7246647267206477\n",
      "> 22 | 0.2438669502735138 | 0.5373477339744568 | 0.845711032388664 | 0.7239056174089069\n",
      "> 23 | 0.24358883500099182 | 0.5375884771347046 | 0.8460589574898786 | 0.7232730263157895\n",
      "> 24 | 0.24330294132232666 | 0.5378085374832153 | 0.8462171052631579 | 0.723146508097166\n",
      "> 25 | 0.24301260709762573 | 0.5380221605300903 | 0.8463752530364372 | 0.7227036943319838\n",
      "> 26 | 0.24271830916404724 | 0.5382457375526428 | 0.8467231781376519 | 0.7223873987854251\n",
      "> 27 | 0.24242258071899414 | 0.5384514331817627 | 0.8465650303643725 | 0.722165991902834\n",
      "> 28 | 0.24212609231472015 | 0.5386615991592407 | 0.8465334008097166 | 0.7217231781376519\n",
      "> 29 | 0.2418307214975357 | 0.5388548374176025 | 0.8465650303643725 | 0.721185475708502\n",
      "> 30 | 0.24153612554073334 | 0.5390619039535522 | 0.84665991902834 | 0.7209008097165992\n",
      "> 31 | 0.24124348163604736 | 0.5392329692840576 | 0.84665991902834 | 0.7202365890688259\n",
      "> 32 | 0.24095381796360016 | 0.5394192934036255 | 0.846944585020243 | 0.7198570344129555\n",
      "> 33 | 0.2406677007675171 | 0.5395874381065369 | 0.8469762145748988 | 0.7193509615384616\n",
      "> 34 | 0.2403857409954071 | 0.5397627353668213 | 0.847165991902834 | 0.7187183704453441\n",
      "> 35 | 0.24010831117630005 | 0.5399136543273926 | 0.8472292510121457 | 0.7180857793522267\n",
      "> 36 | 0.23983527719974518 | 0.540075957775116 | 0.8477353238866396 | 0.7176745951417004\n",
      "> 37 | 0.23956768214702606 | 0.5402439832687378 | 0.8476720647773279 | 0.7173899291497976\n",
      "> 38 | 0.23930492997169495 | 0.5403778553009033 | 0.8479251012145749 | 0.7171368927125507\n",
      "> 39 | 0.23904764652252197 | 0.5405202507972717 | 0.8481781376518218 | 0.7169471153846154\n",
      "> 40 | 0.23879596590995789 | 0.5406566858291626 | 0.8483995445344129 | 0.7166940789473685\n",
      "> 41 | 0.2385503202676773 | 0.540805459022522 | 0.8486842105263158 | 0.7166308198380567\n",
      "> 42 | 0.2383100688457489 | 0.5409297943115234 | 0.8485260627530364 | 0.7161880060728745\n",
      "> 43 | 0.23807565867900848 | 0.541050136089325 | 0.8487158400809717 | 0.7158717105263158\n",
      "> 44 | 0.23784679174423218 | 0.5411761999130249 | 0.8487790991902834 | 0.715334008097166\n",
      "> 45 | 0.23762397468090057 | 0.5412999391555786 | 0.8489056174089069 | 0.7149544534412956\n",
      "> 46 | 0.2374066859483719 | 0.5414263010025024 | 0.8490321356275303 | 0.7147330465587044\n",
      "> 47 | 0.23719531297683716 | 0.541534423828125 | 0.8490637651821862 | 0.7144167510121457\n",
      "> 48 | 0.23698914051055908 | 0.5416535139083862 | 0.8490321356275303 | 0.7140688259109311\n",
      "> 49 | 0.23678919672966003 | 0.5417701601982117 | 0.8492219129554656 | 0.7139739372469636\n",
      "> 50 | 0.23659425973892212 | 0.5418680906295776 | 0.8492851720647774 | 0.7134678643724697\n",
      "> 51 | 0.2364048808813095 | 0.5419772863388062 | 0.8494116902834008 | 0.7132148279352226\n",
      "> 52 | 0.23622065782546997 | 0.5420805811882019 | 0.8496647267206477 | 0.7129301619433198\n",
      "> 53 | 0.23604154586791992 | 0.5421819090843201 | 0.849854504048583 | 0.7127720141700404\n",
      "> 54 | 0.23586755990982056 | 0.5422734618186951 | 0.8498861336032388 | 0.7122659412955465\n",
      "> 55 | 0.2356983721256256 | 0.5423744916915894 | 0.8498861336032388 | 0.7120761639676113\n",
      "> 56 | 0.23553399741649628 | 0.5424591302871704 | 0.8500126518218624 | 0.7118547570850202\n",
      "> 57 | 0.23537391424179077 | 0.5425461530685425 | 0.850328947368421 | 0.7115700910931174\n",
      "> 58 | 0.23521825671195984 | 0.5426329970359802 | 0.8503922064777328 | 0.7115700910931174\n",
      "> 59 | 0.23506703972816467 | 0.5427301526069641 | 0.8504238360323887 | 0.7110640182186235\n",
      "> 60 | 0.23492033779621124 | 0.5428067445755005 | 0.8503605769230769 | 0.7111272773279352\n",
      "> 61 | 0.2347775548696518 | 0.5428845286369324 | 0.850328947368421 | 0.7111272773279352\n",
      "> 62 | 0.23463892936706543 | 0.5429625511169434 | 0.8503605769230769 | 0.7110640182186235\n",
      "> 63 | 0.2345038801431656 | 0.5430397987365723 | 0.850328947368421 | 0.7105579453441295\n",
      "> 64 | 0.23437243700027466 | 0.5431270003318787 | 0.8503605769230769 | 0.7103049089068826\n",
      "> 65 | 0.2342449277639389 | 0.5431978702545166 | 0.8502340587044535 | 0.7100202429149798\n",
      "> 66 | 0.23412100970745087 | 0.5432723760604858 | 0.8502973178137652 | 0.709703947368421\n",
      "> 67 | 0.2340000718832016 | 0.5433387160301208 | 0.850328947368421 | 0.7093876518218624\n",
      "> 68 | 0.23388290405273438 | 0.54343581199646 | 0.8503605769230769 | 0.7090080971659919\n",
      "> 69 | 0.23376882076263428 | 0.5434861183166504 | 0.8504238360323887 | 0.7088815789473685\n",
      "> 70 | 0.23365776240825653 | 0.5435497164726257 | 0.8504238360323887 | 0.7086918016194332\n",
      "> 71 | 0.2335500717163086 | 0.5436219573020935 | 0.8504554655870445 | 0.708502024291498\n",
      "> 72 | 0.23344506323337555 | 0.5436877012252808 | 0.8504238360323887 | 0.7084071356275303\n",
      "> 73 | 0.23334261775016785 | 0.5437378883361816 | 0.8505187246963563 | 0.7084387651821862\n",
      "> 74 | 0.2332431972026825 | 0.5438110828399658 | 0.850581983805668 | 0.708248987854251\n",
      "> 75 | 0.2331463098526001 | 0.5438893437385559 | 0.8506452429149798 | 0.707995951417004\n",
      "> 76 | 0.23305220901966095 | 0.5439320802688599 | 0.8507085020242915 | 0.707995951417004\n",
      "> 77 | 0.23296062648296356 | 0.5439902544021606 | 0.8508666497975709 | 0.7079010627530364\n",
      "> 78 | 0.23287154734134674 | 0.5440573692321777 | 0.850835020242915 | 0.707521508097166\n",
      "> 79 | 0.23278498649597168 | 0.544100284576416 | 0.8510247975708503 | 0.7073633603238867\n",
      "> 80 | 0.23270051181316376 | 0.5441615581512451 | 0.8508982793522267 | 0.7072368421052632\n",
      "> 81 | 0.2326185703277588 | 0.5442177057266235 | 0.8508666497975709 | 0.7068572874493927\n",
      "> 82 | 0.23253847658634186 | 0.5442776679992676 | 0.8509615384615384 | 0.7064777327935222\n",
      "> 83 | 0.23246058821678162 | 0.5443193912506104 | 0.8510247975708503 | 0.706540991902834\n",
      "> 84 | 0.23238471150398254 | 0.5443796515464783 | 0.8509931680161943 | 0.706319585020243\n",
      "> 85 | 0.23231080174446106 | 0.5444272756576538 | 0.8510564271255061 | 0.70603491902834\n",
      "> 86 | 0.2322387844324112 | 0.5444762706756592 | 0.8510564271255061 | 0.7058451417004049\n",
      "> 87 | 0.23216873407363892 | 0.5445288419723511 | 0.851088056680162 | 0.7059716599190283\n",
      "> 88 | 0.23210009932518005 | 0.544602632522583 | 0.8511513157894737 | 0.7059084008097166\n",
      "> 89 | 0.2320336252450943 | 0.5446290969848633 | 0.8512462044534413 | 0.7057502530364372\n",
      "> 90 | 0.2319687306880951 | 0.5446727275848389 | 0.8512778340080972 | 0.7056237348178138\n",
      "> 91 | 0.23190532624721527 | 0.5447475910186768 | 0.8514043522267206 | 0.7052441801619433\n",
      "> 92 | 0.23184384405612946 | 0.5447769165039062 | 0.851309463562753 | 0.7052758097165992\n",
      "> 93 | 0.23178377747535706 | 0.5448266267776489 | 0.8512462044534413 | 0.7054023279352226\n",
      "> 94 | 0.23172485828399658 | 0.5448868274688721 | 0.8512778340080972 | 0.705307439271255\n",
      "> 95 | 0.2316676676273346 | 0.5449195504188538 | 0.8513727226720648 | 0.7052125506072875\n",
      "> 96 | 0.2316116839647293 | 0.5449807047843933 | 0.8513410931174089 | 0.705086032388664\n",
      "> 97 | 0.23155726492404938 | 0.5449994802474976 | 0.8514359817813765 | 0.7048646255060729\n",
      "> 98 | 0.23150384426116943 | 0.5450471639633179 | 0.8515625 | 0.7048962550607287\n",
      "> 99 | 0.23145177960395813 | 0.5450915098190308 | 0.8515941295546559 | 0.7051176619433198\n",
      "> 100 | 0.23140129446983337 | 0.5451355576515198 | 0.8515625 | 0.705086032388664\n",
      "> Evaluation\n",
      "> Class Acc = 0.850784957408905\n",
      "> Adv Acc = 0.850784957408905\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8130785822868347 | 0.8978505097329617 | 0.8686692714691162\n",
      "> Confusion Matrix \n",
      "TN: 9422.0 | FP: 688.0 \n",
      "FN: 1327.0 | TP: 2067.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3761.0 | FP: 88.0 \n",
      "FN: 251.0 | TP: 248.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5661.0 | FP: 600.0 \n",
      "FN: 1076.0 | TP: 1819.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.41511014103889465 | 0.713624119758606 | 0.697273532388664 | 0.34017586032388664\n",
      "> 2 | 0.35592299699783325 | 0.6003954410552979 | 0.8242661943319838 | 0.6392965587044535\n",
      "> 3 | 0.3366493582725525 | 0.5547621250152588 | 0.8292952935222672 | 0.7233995445344129\n",
      "> 4 | 0.3274792730808258 | 0.5341085195541382 | 0.8324898785425101 | 0.728744939271255\n",
      "> 5 | 0.32236286997795105 | 0.524114191532135 | 0.8355263157894737 | 0.7239056174089069\n",
      "> 6 | 0.3194344639778137 | 0.5192277431488037 | 0.8370129048582996 | 0.7173266700404858\n",
      "> 7 | 0.31780266761779785 | 0.5171859264373779 | 0.8384046052631579 | 0.7162196356275303\n",
      "> 8 | 0.3169628381729126 | 0.5169046521186829 | 0.8401126012145749 | 0.7185918522267206\n",
      "> 9 | 0.31659913063049316 | 0.5178248882293701 | 0.8413461538461539 | 0.7197937753036437\n",
      "> 10 | 0.3165145516395569 | 0.5195319652557373 | 0.841788967611336 | 0.7213752530364372\n",
      "> 11 | 0.3165816068649292 | 0.5217060446739197 | 0.8422317813765182 | 0.721185475708502\n",
      "> 12 | 0.3167242705821991 | 0.5241922736167908 | 0.8429276315789473 | 0.721691548582996\n",
      "> 13 | 0.3168947100639343 | 0.5267881155014038 | 0.8435602226720648 | 0.7225139170040485\n",
      "> 14 | 0.3170650005340576 | 0.5293669700622559 | 0.8441928137651822 | 0.7228302125506073\n",
      "> 15 | 0.3172195255756378 | 0.5318793654441833 | 0.8448570344129555 | 0.7229567307692307\n",
      "> 16 | 0.31734997034072876 | 0.534183144569397 | 0.8453314777327935 | 0.7231148785425101\n",
      "> 17 | 0.31745314598083496 | 0.5363335013389587 | 0.8457742914979757 | 0.7234311740890689\n",
      "> 18 | 0.31752848625183105 | 0.538294792175293 | 0.8463436234817814 | 0.7235576923076923\n",
      "> 19 | 0.31757813692092896 | 0.5400338172912598 | 0.8467864372469636 | 0.7227985829959515\n",
      "> 20 | 0.3176042437553406 | 0.5416062474250793 | 0.8474822874493927 | 0.7225771761133604\n",
      "> 21 | 0.31761056184768677 | 0.5430271625518799 | 0.8475771761133604 | 0.7223873987854251\n",
      "> 22 | 0.31759950518608093 | 0.5442692041397095 | 0.847893471659919 | 0.7219129554655871\n",
      "> 23 | 0.31757301092147827 | 0.5453835725784302 | 0.8486842105263158 | 0.7214068825910931\n",
      "> 24 | 0.31753331422805786 | 0.5463877320289612 | 0.849127024291498 | 0.7208691801619433\n",
      "> 25 | 0.3174816071987152 | 0.5472538471221924 | 0.8492851720647774 | 0.7207742914979757\n",
      "> 26 | 0.31741905212402344 | 0.5480881929397583 | 0.8494749493927125 | 0.7201417004048583\n",
      "> 27 | 0.31734776496887207 | 0.5487585067749023 | 0.8497279858299596 | 0.7197937753036437\n",
      "> 28 | 0.3172685205936432 | 0.5493875741958618 | 0.8498228744939271 | 0.7193509615384616\n",
      "> 29 | 0.3171825408935547 | 0.5499612092971802 | 0.8501391700404858 | 0.7188448886639676\n",
      "> 30 | 0.31709039211273193 | 0.5504919290542603 | 0.8504554655870445 | 0.7185918522267206\n",
      "> 31 | 0.3169940710067749 | 0.5509118437767029 | 0.850581983805668 | 0.7181806680161943\n",
      "> 32 | 0.3168944716453552 | 0.5513527393341064 | 0.8507085020242915 | 0.7178960020242915\n",
      "> 33 | 0.3167922794818878 | 0.5516930818557739 | 0.8506452429149798 | 0.7172634109311741\n",
      "> 34 | 0.3166883587837219 | 0.5520156025886536 | 0.8508033906882592 | 0.7171368927125507\n",
      "> 35 | 0.3165838122367859 | 0.5523340702056885 | 0.850835020242915 | 0.7167257085020243\n",
      "> 36 | 0.31647974252700806 | 0.5525978803634644 | 0.8508982793522267 | 0.7162196356275303\n",
      "> 37 | 0.31637588143348694 | 0.5528373122215271 | 0.8512778340080972 | 0.7158717105263158\n",
      "> 38 | 0.3162730932235718 | 0.5530816316604614 | 0.8514992408906883 | 0.7157451923076923\n",
      "> 39 | 0.3161717355251312 | 0.5532792210578918 | 0.8515625 | 0.7154921558704453\n",
      "> 40 | 0.31607258319854736 | 0.5534475445747375 | 0.8515625 | 0.7151126012145749\n",
      "> 41 | 0.31597527861595154 | 0.5536380410194397 | 0.8515308704453441 | 0.7144167510121457\n",
      "> 42 | 0.31588083505630493 | 0.553793728351593 | 0.8516257591093117 | 0.7140055668016194\n",
      "> 43 | 0.3157891631126404 | 0.5539387464523315 | 0.8515941295546559 | 0.7137209008097166\n",
      "> 44 | 0.3157007098197937 | 0.5540560483932495 | 0.8515625 | 0.7130883097165992\n",
      "> 45 | 0.3156152665615082 | 0.5541825890541077 | 0.8514043522267206 | 0.7126138663967612\n",
      "> 46 | 0.31553295254707336 | 0.554323673248291 | 0.8514359817813765 | 0.7122026821862348\n",
      "> 47 | 0.3154539465904236 | 0.5544081926345825 | 0.8515941295546559 | 0.7119496457489879\n",
      "> 48 | 0.31537777185440063 | 0.5545094013214111 | 0.8516890182186235 | 0.7117282388663968\n",
      "> 49 | 0.315305233001709 | 0.554620623588562 | 0.8517522773279352 | 0.7114435728744939\n",
      "> 50 | 0.31523627042770386 | 0.5547000169754028 | 0.8520685728744939 | 0.7113803137651822\n",
      "> 51 | 0.3151707053184509 | 0.5547975301742554 | 0.852289979757085 | 0.7111589068825911\n",
      "> 52 | 0.31510815024375916 | 0.5548937320709229 | 0.852543016194332 | 0.711411943319838\n",
      "> 53 | 0.3150487244129181 | 0.5549394488334656 | 0.8524797570850202 | 0.7113486842105263\n",
      "> 54 | 0.31499266624450684 | 0.555012047290802 | 0.8525113866396761 | 0.7113170546558705\n",
      "> 55 | 0.3149389624595642 | 0.5550891160964966 | 0.8529225708502024 | 0.7110956477732794\n",
      "> 56 | 0.31488871574401855 | 0.5551502704620361 | 0.8529542004048583 | 0.7110640182186235\n",
      "> 57 | 0.3148416578769684 | 0.5552283525466919 | 0.8530174595141701 | 0.7107160931174089\n",
      "> 58 | 0.31479740142822266 | 0.5552793741226196 | 0.8530490890688259 | 0.7108742408906883\n",
      "> 59 | 0.3147558867931366 | 0.5553673505783081 | 0.8530490890688259 | 0.7103681680161943\n",
      "> 60 | 0.31471723318099976 | 0.5554211139678955 | 0.8530174595141701 | 0.7101151315789473\n",
      "> 61 | 0.31468093395233154 | 0.555477499961853 | 0.8530174595141701 | 0.709703947368421\n",
      "> 62 | 0.3146468997001648 | 0.555504560470581 | 0.8529858299595142 | 0.7097355769230769\n",
      "> 63 | 0.3146153390407562 | 0.5555640459060669 | 0.8529858299595142 | 0.7095774291497976\n",
      "> 64 | 0.314586341381073 | 0.5556260347366333 | 0.8530807186234818 | 0.7096406882591093\n",
      "> 65 | 0.31455928087234497 | 0.5556766986846924 | 0.8529858299595142 | 0.709229504048583\n",
      "> 66 | 0.3145347833633423 | 0.5557174682617188 | 0.8530490890688259 | 0.7089132085020243\n",
      "> 67 | 0.31451231241226196 | 0.5557558536529541 | 0.8530807186234818 | 0.7086285425101214\n",
      "> 68 | 0.31449180841445923 | 0.5558248162269592 | 0.8530807186234818 | 0.708755060728745\n",
      "> 69 | 0.3144732117652893 | 0.5558542013168335 | 0.8530807186234818 | 0.708502024291498\n",
      "> 70 | 0.3144564628601074 | 0.5558984279632568 | 0.8531439777327935 | 0.7086285425101214\n",
      "> 71 | 0.314441442489624 | 0.5559427738189697 | 0.8531123481781376 | 0.7083438765182186\n",
      "> 72 | 0.31442806124687195 | 0.5559720396995544 | 0.8530490890688259 | 0.7081540991902834\n",
      "> 73 | 0.314416766166687 | 0.5560174584388733 | 0.8530174595141701 | 0.7082173582995951\n",
      "> 74 | 0.3144066333770752 | 0.5560430884361267 | 0.8531123481781376 | 0.7082173582995951\n",
      "> 75 | 0.3143981695175171 | 0.5560780167579651 | 0.8532072368421053 | 0.7079326923076923\n",
      "> 76 | 0.31439101696014404 | 0.5561186075210571 | 0.8532388663967612 | 0.7079010627530364\n",
      "> 77 | 0.3143853545188904 | 0.5561434030532837 | 0.853270495951417 | 0.7074266194331984\n",
      "> 78 | 0.3143809735774994 | 0.556190013885498 | 0.8533653846153846 | 0.7071103238866396\n",
      "> 79 | 0.31437817215919495 | 0.5562225580215454 | 0.8533970141700404 | 0.7069205465587044\n",
      "> 80 | 0.31437620520591736 | 0.5562484264373779 | 0.8534919028340081 | 0.7068889170040485\n",
      "> 81 | 0.3143758773803711 | 0.5562916994094849 | 0.853523532388664 | 0.7069838056680162\n",
      "> 82 | 0.3143766522407532 | 0.5563115477561951 | 0.8534919028340081 | 0.7068256578947368\n",
      "> 83 | 0.31437796354293823 | 0.5563430190086365 | 0.853744939271255 | 0.7067307692307693\n",
      "> 84 | 0.3143807649612427 | 0.5563691854476929 | 0.8536500506072875 | 0.7064777327935222\n",
      "> 85 | 0.31438446044921875 | 0.5564092397689819 | 0.8537133097165992 | 0.7066042510121457\n",
      "> 86 | 0.31438881158828735 | 0.5564247369766235 | 0.8536816801619433 | 0.7067307692307693\n",
      "> 87 | 0.31439417600631714 | 0.5564604997634888 | 0.8537765688259109 | 0.706540991902834\n",
      "> 88 | 0.31440016627311707 | 0.5565056204795837 | 0.8537765688259109 | 0.706319585020243\n",
      "> 89 | 0.3144073188304901 | 0.556526780128479 | 0.8538081983805668 | 0.7064144736842105\n",
      "> 90 | 0.3144150972366333 | 0.556525707244873 | 0.8538714574898786 | 0.7063512145748988\n",
      "> 91 | 0.31442323327064514 | 0.5565500259399414 | 0.8539663461538461 | 0.706319585020243\n",
      "> 92 | 0.3144316077232361 | 0.5565979480743408 | 0.8540612348178138 | 0.7061298076923077\n",
      "> 93 | 0.31444108486175537 | 0.5566046237945557 | 0.8541244939271255 | 0.7059400303643725\n",
      "> 94 | 0.31445077061653137 | 0.5566447973251343 | 0.8541877530364372 | 0.7056237348178138\n",
      "> 95 | 0.314460813999176 | 0.5566456317901611 | 0.8541244939271255 | 0.7056869939271255\n",
      "> 96 | 0.3144712448120117 | 0.5566808581352234 | 0.854251012145749 | 0.7054972165991903\n",
      "> 97 | 0.3144822120666504 | 0.5566960573196411 | 0.854251012145749 | 0.7054339574898786\n",
      "> 98 | 0.31449389457702637 | 0.5567152500152588 | 0.8541244939271255 | 0.7054972165991903\n",
      "> 99 | 0.314505398273468 | 0.5567392110824585 | 0.8541244939271255 | 0.7054972165991903\n",
      "> 100 | 0.3145170211791992 | 0.5567595958709717 | 0.8541877530364372 | 0.7054023279352226\n",
      "> Evaluation\n",
      "> Class Acc = 0.8473785519599915\n",
      "> Adv Acc = 0.8473785519599915\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.7991978526115417 | 0.8917143568396568 | 0.8675106167793274\n",
      "> Confusion Matrix \n",
      "TN: 9334.0 | FP: 758.0 \n",
      "FN: 1303.0 | TP: 2109.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3779.0 | FP: 90.0 \n",
      "FN: 237.0 | TP: 241.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5555.0 | FP: 668.0 \n",
      "FN: 1066.0 | TP: 1868.0\n"
     ]
    }
   ],
   "source": [
    "fairdef = 'EqOdds'\n",
    "\n",
    "for cv_seed in cv_seeds:\n",
    "    x_train, x_test, y_train, y_test, a_train, a_test = train_test_split(\n",
    "        x, y, a, test_size=0.3, random_state=cv_seed)\n",
    "\n",
    "    train_data = Dataset.from_tensor_slices((x_train, y_train, a_train))\n",
    "    train_data = train_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    test_data = Dataset.from_tensor_slices((x_test, y_test, a_test))\n",
    "    test_data = test_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    # train below\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    model = FairLogisticRegression(xdim, ydim, adim, batch_size, fairdef)\n",
    "    zhang_train(model, raw_data, train_data, epochs, opt)\n",
    "\n",
    "    Y, A, Y_hat, A_hat = fair_evaluation(model, test_data)\n",
    "    clas_acc, dp, deqodds, deqopp, confusion_matrix, metrics_a0, metrics_a1 = compute_metrics(Y, A, Y_hat, A_hat, adim)\n",
    "\n",
    "    fair_metrics = (dp, deqodds, deqopp)\n",
    "    tradeoff = []\n",
    "    for fair_metric in fair_metrics:\n",
    "        tradeoff.append(compute_tradeoff(clas_acc, fair_metric))\n",
    "\n",
    "    result = ['Zhang4EqOdds', cv_seed, clas_acc, dp, deqodds, deqopp, tradeoff[0], tradeoff[1], tradeoff[2]] + metrics_a0 + metrics_a1\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    del(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zhang for Eq Opp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.4167071282863617 | 0.1535322368144989 | 0.6865827429149798 | 0.3282831477732793\n",
      "> 2 | 0.36870408058166504 | 0.10809452831745148 | 0.8226530870445344 | 0.471185475708502\n",
      "> 3 | 0.3498004376888275 | 0.09275442361831665 | 0.8279035931174089 | 0.5763537449392713\n",
      "> 4 | 0.3390975296497345 | 0.08908288180828094 | 0.8314777327935222 | 0.6332553137651822\n",
      "> 5 | 0.3320850133895874 | 0.09034185111522675 | 0.8341029858299596 | 0.6704832995951417\n",
      "> 6 | 0.3272702097892761 | 0.09237869083881378 | 0.8366966093117408 | 0.6903782894736842\n",
      "> 7 | 0.32396677136421204 | 0.09400853514671326 | 0.8381515688259109 | 0.6930668016194332\n",
      "> 8 | 0.32160472869873047 | 0.09561667591333389 | 0.8394483805668016 | 0.6934779858299596\n",
      "> 9 | 0.31985610723495483 | 0.09700166434049606 | 0.8402707489878543 | 0.6925923582995951\n",
      "> 10 | 0.31851208209991455 | 0.09807877987623215 | 0.8406186740890689 | 0.6921811740890689\n",
      "> 11 | 0.3174431324005127 | 0.09891863167285919 | 0.8414410425101214 | 0.6905364372469636\n",
      "> 12 | 0.3165670931339264 | 0.09954789280891418 | 0.841788967611336 | 0.689461032388664\n",
      "> 13 | 0.31583279371261597 | 0.10004228353500366 | 0.8421368927125507 | 0.6891131072874493\n",
      "> 14 | 0.3152080178260803 | 0.10041457414627075 | 0.8428960020242915 | 0.6887651821862348\n",
      "> 15 | 0.31467223167419434 | 0.1007077693939209 | 0.8435285931174089 | 0.6889233299595142\n",
      "> 16 | 0.31421151757240295 | 0.10093243420124054 | 0.8438132591093117 | 0.6883223684210527\n",
      "> 17 | 0.31381553411483765 | 0.10111027210950851 | 0.8443509615384616 | 0.6877846659919028\n",
      "> 18 | 0.3134758472442627 | 0.10124138742685318 | 0.8446988866396761 | 0.6875\n",
      "> 19 | 0.3131846487522125 | 0.10133041441440582 | 0.8448570344129555 | 0.6875948886639676\n",
      "> 20 | 0.31293588876724243 | 0.10140718519687653 | 0.8450784412955465 | 0.6874683704453441\n",
      "> 21 | 0.31272321939468384 | 0.10145051777362823 | 0.8455845141700404 | 0.6876581477732794\n",
      "> 22 | 0.31254076957702637 | 0.10147148370742798 | 0.8455528846153846 | 0.6877846659919028\n",
      "> 23 | 0.31238478422164917 | 0.10148634761571884 | 0.8455212550607287 | 0.6875632591093117\n",
      "> 24 | 0.31225162744522095 | 0.10148868709802628 | 0.8456161437246964 | 0.6874051113360324\n",
      "> 25 | 0.3121386766433716 | 0.10148581862449646 | 0.846185475708502 | 0.6872153340080972\n",
      "> 26 | 0.31204408407211304 | 0.10147701948881149 | 0.8465334008097166 | 0.6873418522267206\n",
      "> 27 | 0.3119663596153259 | 0.10145212709903717 | 0.846691548582996 | 0.6869622975708503\n",
      "> 28 | 0.31190407276153564 | 0.10143554210662842 | 0.8469762145748988 | 0.6863297064777328\n",
      "> 29 | 0.31185653805732727 | 0.10140851140022278 | 0.847165991902834 | 0.686266447368421\n",
      "> 30 | 0.31182241439819336 | 0.1013769805431366 | 0.847165991902834 | 0.6860134109311741\n",
      "> 31 | 0.31180092692375183 | 0.10134464502334595 | 0.8472292510121457 | 0.6858552631578947\n",
      "> 32 | 0.3117913007736206 | 0.1013118177652359 | 0.847419028340081 | 0.6851910425101214\n",
      "> 33 | 0.31179285049438477 | 0.10127077996730804 | 0.8477669534412956 | 0.6850012651821862\n",
      "> 34 | 0.3118041753768921 | 0.10123506933450699 | 0.8480832489878543 | 0.684811487854251\n",
      "> 35 | 0.3118250370025635 | 0.10119153559207916 | 0.8481781376518218 | 0.6852226720647774\n",
      "> 36 | 0.31185483932495117 | 0.10115055739879608 | 0.8483995445344129 | 0.684811487854251\n",
      "> 37 | 0.31189286708831787 | 0.10112311691045761 | 0.8484944331983806 | 0.6849063765182186\n",
      "> 38 | 0.31193822622299194 | 0.10108426213264465 | 0.8484628036437247 | 0.6844951923076923\n",
      "> 39 | 0.3119908571243286 | 0.10104915499687195 | 0.848873987854251 | 0.6846849696356275\n",
      "> 40 | 0.3120501637458801 | 0.1010042354464531 | 0.8491902834008097 | 0.6848747469635628\n",
      "> 41 | 0.3121155798435211 | 0.10097615420818329 | 0.8493484311740891 | 0.6852543016194332\n",
      "> 42 | 0.31218692660331726 | 0.10093903541564941 | 0.8495382085020243 | 0.685317560728745\n",
      "> 43 | 0.312263548374176 | 0.1008990928530693 | 0.8497279858299596 | 0.6851910425101214\n",
      "> 44 | 0.3123452663421631 | 0.10086885094642639 | 0.8499493927125507 | 0.6852859311740891\n",
      "> 45 | 0.31243208050727844 | 0.1008332371711731 | 0.8499810222672065 | 0.6854440789473685\n",
      "> 46 | 0.3125230371952057 | 0.1007939949631691 | 0.8502656882591093 | 0.6855073380566802\n",
      "> 47 | 0.312618613243103 | 0.1007707417011261 | 0.8504238360323887 | 0.6857287449392713\n",
      "> 48 | 0.3127180337905884 | 0.10074563324451447 | 0.8504554655870445 | 0.6858552631578947\n",
      "> 49 | 0.3128216862678528 | 0.10071644186973572 | 0.8506452429149798 | 0.6862031882591093\n",
      "> 50 | 0.31292885541915894 | 0.10068370401859283 | 0.850581983805668 | 0.6862980769230769\n",
      "> 51 | 0.3130398094654083 | 0.10065991431474686 | 0.8507085020242915 | 0.6862348178137652\n",
      "> 52 | 0.3131539821624756 | 0.10063949227333069 | 0.8509615384615384 | 0.6861399291497976\n",
      "> 53 | 0.3132709860801697 | 0.10061703622341156 | 0.8509931680161943 | 0.6857603744939271\n",
      "> 54 | 0.3133908808231354 | 0.10059238225221634 | 0.8512778340080972 | 0.6856022267206477\n",
      "> 55 | 0.31351321935653687 | 0.10057225823402405 | 0.8512778340080972 | 0.6850012651821862\n",
      "> 56 | 0.3136383295059204 | 0.10055343061685562 | 0.8512778340080972 | 0.6854757085020243\n",
      "> 57 | 0.3137657046318054 | 0.10051627457141876 | 0.851309463562753 | 0.6856022267206477\n",
      "> 58 | 0.31389540433883667 | 0.10051995515823364 | 0.8514359817813765 | 0.6851910425101214\n",
      "> 59 | 0.3140268921852112 | 0.10049479454755783 | 0.8514676113360324 | 0.684558451417004\n",
      "> 60 | 0.31416040658950806 | 0.10047988593578339 | 0.8514992408906883 | 0.6846217105263158\n",
      "> 61 | 0.31429556012153625 | 0.1004645824432373 | 0.8515308704453441 | 0.6832616396761133\n",
      "> 62 | 0.3144319951534271 | 0.10046364367008209 | 0.8516573886639676 | 0.6831983805668016\n",
      "> 63 | 0.314569890499115 | 0.10044120997190475 | 0.8517206477732794 | 0.6836411943319838\n",
      "> 64 | 0.314708948135376 | 0.10044205188751221 | 0.8516257591093117 | 0.683356528340081\n",
      "> 65 | 0.31484881043434143 | 0.1004253476858139 | 0.8515308704453441 | 0.6835779352226721\n",
      "> 66 | 0.3149895668029785 | 0.10042884945869446 | 0.8516257591093117 | 0.6832616396761133\n",
      "> 67 | 0.31513091921806335 | 0.10041354596614838 | 0.8517522773279352 | 0.6832300101214575\n",
      "> 68 | 0.3152729272842407 | 0.10040261596441269 | 0.8517839068825911 | 0.6830718623481782\n",
      "> 69 | 0.3154154419898987 | 0.10040425509214401 | 0.851815536437247 | 0.6831667510121457\n",
      "> 70 | 0.3155577778816223 | 0.10039970278739929 | 0.851815536437247 | 0.682629048582996\n",
      "> 71 | 0.31570035219192505 | 0.10039574652910233 | 0.8518787955465587 | 0.6828504554655871\n",
      "> 72 | 0.3158431649208069 | 0.10039438307285309 | 0.8517522773279352 | 0.6827555668016194\n",
      "> 73 | 0.31598538160324097 | 0.10040103644132614 | 0.8519736842105263 | 0.6822178643724697\n",
      "> 74 | 0.3161274790763855 | 0.10039092600345612 | 0.8519420546558705 | 0.6819331983805668\n",
      "> 75 | 0.3162691593170166 | 0.10038921982049942 | 0.8520053137651822 | 0.6817117914979757\n",
      "> 76 | 0.31641072034835815 | 0.10040822625160217 | 0.8519736842105263 | 0.6810792004048583\n",
      "> 77 | 0.3165515065193176 | 0.10041194409132004 | 0.8521002024291497 | 0.6808894230769231\n",
      "> 78 | 0.31669166684150696 | 0.10038857161998749 | 0.8521318319838057 | 0.6803200910931174\n",
      "> 79 | 0.3168310523033142 | 0.10041634738445282 | 0.8521002024291497 | 0.6799721659919028\n",
      "> 80 | 0.31696951389312744 | 0.10041316598653793 | 0.8521002024291497 | 0.6799721659919028\n",
      "> 81 | 0.3171066641807556 | 0.10042759031057358 | 0.8521634615384616 | 0.6798772773279352\n",
      "> 82 | 0.31724295020103455 | 0.10041246563196182 | 0.8521950910931174 | 0.6796242408906883\n",
      "> 83 | 0.3173781633377075 | 0.10044502466917038 | 0.8521950910931174 | 0.6794028340080972\n",
      "> 84 | 0.31751227378845215 | 0.10045284032821655 | 0.8522583502024291 | 0.6796875\n",
      "> 85 | 0.3176450729370117 | 0.10044939815998077 | 0.8523848684210527 | 0.6796242408906883\n",
      "> 86 | 0.317776620388031 | 0.10046736896038055 | 0.8523532388663968 | 0.6794028340080972\n",
      "> 87 | 0.3179069459438324 | 0.10046575218439102 | 0.8523532388663968 | 0.6789916497975709\n",
      "> 88 | 0.3180358409881592 | 0.10047616809606552 | 0.8522267206477733 | 0.6793395748987854\n",
      "> 89 | 0.3181630074977875 | 0.10049965232610703 | 0.8521950910931174 | 0.6789916497975709\n",
      "> 90 | 0.31828904151916504 | 0.10050299763679504 | 0.8522267206477733 | 0.679434463562753\n",
      "> 91 | 0.3184136152267456 | 0.10051542520523071 | 0.8523848684210527 | 0.678960020242915\n",
      "> 92 | 0.3185367286205292 | 0.1005396693944931 | 0.852289979757085 | 0.6786753542510121\n",
      "> 93 | 0.3186579942703247 | 0.10054968297481537 | 0.852289979757085 | 0.6783274291497976\n",
      "> 94 | 0.31877774000167847 | 0.10055214166641235 | 0.8523532388663968 | 0.6781376518218624\n",
      "> 95 | 0.31889617443084717 | 0.10057644546031952 | 0.8523216093117408 | 0.6769357287449392\n",
      "> 96 | 0.3190130889415741 | 0.10059081017971039 | 0.8523216093117408 | 0.676745951417004\n",
      "> 97 | 0.31912854313850403 | 0.10060562193393707 | 0.8524164979757085 | 0.6766510627530364\n",
      "> 98 | 0.31924211978912354 | 0.10060988366603851 | 0.8524164979757085 | 0.676492914979757\n",
      "> 99 | 0.31935399770736694 | 0.10062757134437561 | 0.8523848684210527 | 0.676492914979757\n",
      "> 100 | 0.3194642663002014 | 0.1006406769156456 | 0.8524481275303644 | 0.6763347672064778\n",
      "> Evaluation\n",
      "> Class Acc = 0.8492298722267151\n",
      "> Adv Acc = 0.8492298722267151\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8132219910621643 | 0.9019728302955627 | 0.8848541975021362\n",
      "> Confusion Matrix \n",
      "TN: 9426.0 | FP: 732.0 \n",
      "FN: 1304.0 | TP: 2042.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3784.0 | FP: 85.0 \n",
      "FN: 249.0 | TP: 262.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5642.0 | FP: 647.0 \n",
      "FN: 1055.0 | TP: 1780.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.459043025970459 | 0.22437240183353424 | 0.6887019230769231 | 0.3283464068825911\n",
      "> 2 | 0.4321138858795166 | 0.1721515953540802 | 0.8240764170040485 | 0.47017332995951416\n",
      "> 3 | 0.4272047281265259 | 0.15829670429229736 | 0.8288841093117408 | 0.5781882591093117\n",
      "> 4 | 0.42411157488822937 | 0.15396687388420105 | 0.8316991396761133 | 0.6353744939271255\n",
      "> 5 | 0.4210243225097656 | 0.15171709656715393 | 0.8341978744939271 | 0.6714954453441295\n",
      "> 6 | 0.41781896352767944 | 0.15346764028072357 | 0.8362221659919028 | 0.690188512145749\n",
      "> 7 | 0.41466301679611206 | 0.15645602345466614 | 0.837645495951417 | 0.6901568825910931\n",
      "> 8 | 0.4117138981819153 | 0.1589268147945404 | 0.8388157894736842 | 0.6905048076923077\n",
      "> 9 | 0.40901464223861694 | 0.1607053279876709 | 0.8398279352226721 | 0.6895559210526315\n",
      "> 10 | 0.40656778216362 | 0.16200660169124603 | 0.8406503036437247 | 0.6887019230769231\n",
      "> 11 | 0.40435469150543213 | 0.16281428933143616 | 0.840808451417004 | 0.6876265182186235\n",
      "> 12 | 0.4023505747318268 | 0.1632937490940094 | 0.8413461538461539 | 0.6872153340080972\n",
      "> 13 | 0.40052926540374756 | 0.1635877788066864 | 0.8419471153846154 | 0.6867092611336032\n",
      "> 14 | 0.3988673686981201 | 0.16375067830085754 | 0.8422001518218624 | 0.6854440789473685\n",
      "> 15 | 0.3973466753959656 | 0.16383096575737 | 0.8427062246963563 | 0.68459008097166\n",
      "> 16 | 0.3959512412548065 | 0.16385558247566223 | 0.8434653340080972 | 0.6845268218623481\n",
      "> 17 | 0.3946685791015625 | 0.16384902596473694 | 0.844003036437247 | 0.6837993421052632\n",
      "> 18 | 0.39348629117012024 | 0.16382908821105957 | 0.8445407388663968 | 0.6827239372469636\n",
      "> 19 | 0.39239412546157837 | 0.1637381911277771 | 0.8447937753036437 | 0.6826923076923077\n",
      "> 20 | 0.3913826048374176 | 0.16365443170070648 | 0.8450784412955465 | 0.6825025303643725\n",
      "> 21 | 0.39044174551963806 | 0.16354861855506897 | 0.8452049595141701 | 0.6822811234817814\n",
      "> 22 | 0.3895641565322876 | 0.16342782974243164 | 0.8454896255060729 | 0.6812373481781376\n",
      "> 23 | 0.3887435793876648 | 0.16330191493034363 | 0.845711032388664 | 0.6811740890688259\n",
      "> 24 | 0.3879746198654175 | 0.16316816210746765 | 0.8456794028340081 | 0.681395495951417\n",
      "> 25 | 0.38725197315216064 | 0.16302326321601868 | 0.8459956983805668 | 0.6814271255060729\n",
      "> 26 | 0.3865717947483063 | 0.16287587583065033 | 0.8462171052631579 | 0.6811424595141701\n",
      "> 27 | 0.3859308362007141 | 0.16272415220737457 | 0.8460905870445344 | 0.6814271255060729\n",
      "> 28 | 0.38532572984695435 | 0.1625659316778183 | 0.846438512145749 | 0.6814271255060729\n",
      "> 29 | 0.3847537934780121 | 0.16240578889846802 | 0.8464068825910931 | 0.6815536437246964\n",
      "> 30 | 0.3842118978500366 | 0.162227064371109 | 0.8465966599190283 | 0.6819331983805668\n",
      "> 31 | 0.38369810581207275 | 0.1620679795742035 | 0.8467231781376519 | 0.682122975708502\n",
      "> 32 | 0.3832099735736847 | 0.16190344095230103 | 0.8468496963562753 | 0.6817750506072875\n",
      "> 33 | 0.38274529576301575 | 0.16172805428504944 | 0.8468496963562753 | 0.6820913461538461\n",
      "> 34 | 0.3823028802871704 | 0.16156655550003052 | 0.8470394736842105 | 0.6816169028340081\n",
      "> 35 | 0.3818805515766144 | 0.16138574481010437 | 0.8473557692307693 | 0.6816169028340081\n",
      "> 36 | 0.3814776539802551 | 0.16120924055576324 | 0.8476404352226721 | 0.6810159412955465\n",
      "> 37 | 0.3810920715332031 | 0.16108322143554688 | 0.8476404352226721 | 0.6806996457489879\n",
      "> 38 | 0.38072293996810913 | 0.1608564853668213 | 0.8479883603238867 | 0.6801935728744939\n",
      "> 39 | 0.3803690969944 | 0.16068565845489502 | 0.8482413967611336 | 0.6807312753036437\n",
      "> 40 | 0.3800291419029236 | 0.16050848364830017 | 0.848367914979757 | 0.680668016194332\n",
      "> 41 | 0.3797028362751007 | 0.16033414006233215 | 0.848367914979757 | 0.6811424595141701\n",
      "> 42 | 0.37938928604125977 | 0.16016116738319397 | 0.8485893218623481 | 0.6807629048582996\n",
      "> 43 | 0.379086971282959 | 0.15999063849449158 | 0.848873987854251 | 0.6811740890688259\n",
      "> 44 | 0.37879592180252075 | 0.1598181277513504 | 0.8490953947368421 | 0.6815852732793523\n",
      "> 45 | 0.3785153925418854 | 0.1596447229385376 | 0.8490953947368421 | 0.681648532388664\n",
      "> 46 | 0.37824487686157227 | 0.15947213768959045 | 0.849380060728745 | 0.6813006072874493\n",
      "> 47 | 0.37798357009887695 | 0.15930020809173584 | 0.849601467611336 | 0.6816169028340081\n",
      "> 48 | 0.37773147225379944 | 0.15913088619709015 | 0.8498228744939271 | 0.6813322368421053\n",
      "> 49 | 0.3774875998497009 | 0.1589621901512146 | 0.8499810222672065 | 0.6808577935222672\n",
      "> 50 | 0.37725168466567993 | 0.1587933599948883 | 0.8502024291497976 | 0.6804782388663968\n",
      "> 51 | 0.37702372670173645 | 0.15864475071430206 | 0.8502024291497976 | 0.6805414979757085\n",
      "> 52 | 0.37680333852767944 | 0.1584623157978058 | 0.8501707995951417 | 0.6806047570850202\n",
      "> 53 | 0.37658950686454773 | 0.15833604335784912 | 0.850328947368421 | 0.6806363866396761\n",
      "> 54 | 0.3763827383518219 | 0.1581372618675232 | 0.8503605769230769 | 0.6802568319838057\n",
      "> 55 | 0.3761819005012512 | 0.1580101102590561 | 0.850581983805668 | 0.6806996457489879\n",
      "> 56 | 0.3759877681732178 | 0.1578097939491272 | 0.8504870951417004 | 0.6809526821862348\n",
      "> 57 | 0.3757993280887604 | 0.15765030682086945 | 0.8505503542510121 | 0.6805414979757085\n",
      "> 58 | 0.3756163418292999 | 0.15753290057182312 | 0.8504870951417004 | 0.6808261639676113\n",
      "> 59 | 0.375438928604126 | 0.15733394026756287 | 0.8505187246963563 | 0.6807629048582996\n",
      "> 60 | 0.3752663731575012 | 0.15721705555915833 | 0.8503922064777328 | 0.6806363866396761\n",
      "> 61 | 0.3750993609428406 | 0.1570335477590561 | 0.8506452429149798 | 0.6806047570850202\n",
      "> 62 | 0.37493661046028137 | 0.15690147876739502 | 0.8508033906882592 | 0.6800037955465587\n",
      "> 63 | 0.3747786581516266 | 0.1567126214504242 | 0.8509931680161943 | 0.6796242408906883\n",
      "> 64 | 0.37462514638900757 | 0.1566014438867569 | 0.8510564271255061 | 0.6807945344129555\n",
      "> 65 | 0.3744760751724243 | 0.15641473233699799 | 0.8510564271255061 | 0.6811424595141701\n",
      "> 66 | 0.3743308186531067 | 0.1562751829624176 | 0.8511829453441295 | 0.6817117914979757\n",
      "> 67 | 0.3741891384124756 | 0.15611764788627625 | 0.8512145748987854 | 0.6814903846153846\n",
      "> 68 | 0.37405163049697876 | 0.15597234666347504 | 0.851309463562753 | 0.681395495951417\n",
      "> 69 | 0.3739176392555237 | 0.15582430362701416 | 0.8513727226720648 | 0.6816801619433198\n",
      "> 70 | 0.37378719449043274 | 0.15568773448467255 | 0.8514359817813765 | 0.6819015688259109\n",
      "> 71 | 0.37366050481796265 | 0.1555800884962082 | 0.8515941295546559 | 0.6817434210526315\n",
      "> 72 | 0.3735370337963104 | 0.15543946623802185 | 0.8516573886639676 | 0.6814271255060729\n",
      "> 73 | 0.3734164834022522 | 0.1552649438381195 | 0.8517206477732794 | 0.6809526821862348\n",
      "> 74 | 0.37329918146133423 | 0.1551567167043686 | 0.8517522773279352 | 0.6807629048582996\n",
      "> 75 | 0.373184472322464 | 0.1550319790840149 | 0.851815536437247 | 0.6809843117408907\n",
      "> 76 | 0.37307292222976685 | 0.15484288334846497 | 0.851815536437247 | 0.680668016194332\n",
      "> 77 | 0.3729638457298279 | 0.154705211520195 | 0.851815536437247 | 0.6807312753036437\n",
      "> 78 | 0.3728574514389038 | 0.15457764267921448 | 0.8517206477732794 | 0.6807945344129555\n",
      "> 79 | 0.3727540671825409 | 0.15444333851337433 | 0.8517206477732794 | 0.6807312753036437\n",
      "> 80 | 0.3726530075073242 | 0.15430277585983276 | 0.851815536437247 | 0.680414979757085\n",
      "> 81 | 0.3725540041923523 | 0.1541719138622284 | 0.8519104251012146 | 0.6796558704453441\n",
      "> 82 | 0.37245774269104004 | 0.1540824919939041 | 0.8519420546558705 | 0.6790549089068826\n",
      "> 83 | 0.3723636865615845 | 0.153952956199646 | 0.852036943319838 | 0.6790232793522267\n",
      "> 84 | 0.37227195501327515 | 0.15378472208976746 | 0.8520053137651822 | 0.6782957995951417\n",
      "> 85 | 0.3721820116043091 | 0.15366137027740479 | 0.8521002024291497 | 0.6788651315789473\n",
      "> 86 | 0.37209460139274597 | 0.15353435277938843 | 0.8520685728744939 | 0.6783274291497976\n",
      "> 87 | 0.3720092177391052 | 0.1534043252468109 | 0.8520685728744939 | 0.6781376518218624\n",
      "> 88 | 0.3719254732131958 | 0.15328115224838257 | 0.8520685728744939 | 0.6779162449392713\n",
      "> 89 | 0.37184369564056396 | 0.15315714478492737 | 0.8521002024291497 | 0.6775366902834008\n",
      "> 90 | 0.37176376581192017 | 0.15303419530391693 | 0.8521318319838057 | 0.6773152834008097\n",
      "> 91 | 0.37168556451797485 | 0.15291252732276917 | 0.8522267206477733 | 0.6769040991902834\n",
      "> 92 | 0.37160927057266235 | 0.15279212594032288 | 0.8521950910931174 | 0.6768092105263158\n",
      "> 93 | 0.3715343773365021 | 0.1526705026626587 | 0.8521950910931174 | 0.6769040991902834\n",
      "> 94 | 0.37146109342575073 | 0.15257155895233154 | 0.8520685728744939 | 0.6769357287449392\n",
      "> 95 | 0.3713895082473755 | 0.15243518352508545 | 0.8521002024291497 | 0.6768092105263158\n",
      "> 96 | 0.37131959199905396 | 0.15231896936893463 | 0.8520685728744939 | 0.6770306174089069\n",
      "> 97 | 0.3712511658668518 | 0.1522214263677597 | 0.8521634615384616 | 0.6767143218623481\n",
      "> 98 | 0.37118422985076904 | 0.15208867192268372 | 0.8521634615384616 | 0.6766510627530364\n",
      "> 99 | 0.3711183965206146 | 0.15197700262069702 | 0.8521634615384616 | 0.6763663967611336\n",
      "> 100 | 0.37105461955070496 | 0.15185727179050446 | 0.8521318319838057 | 0.676271508097166\n",
      "> Evaluation\n",
      "> Class Acc = 0.8501184582710266\n",
      "> Adv Acc = 0.8501184582710266\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8045460283756256 | 0.8917019069194794 | 0.8687836229801178\n",
      "> Confusion Matrix \n",
      "TN: 9400.0 | FP: 756.0 \n",
      "FN: 1268.0 | TP: 2080.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3794.0 | FP: 84.0 \n",
      "FN: 248.0 | TP: 258.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5606.0 | FP: 672.0 \n",
      "FN: 1020.0 | TP: 1822.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.44797655940055847 | 0.25668245553970337 | 0.6852543016194332 | 0.32739752024291496\n",
      "> 2 | 0.396808922290802 | 0.15770788490772247 | 0.8233489372469636 | 0.4722925101214575\n",
      "> 3 | 0.38095203042030334 | 0.11689899116754532 | 0.8285361842105263 | 0.5760058198380567\n",
      "> 4 | 0.37324294447898865 | 0.0976637601852417 | 0.831794028340081 | 0.6329390182186235\n",
      "> 5 | 0.36847740411758423 | 0.08702331781387329 | 0.8343560222672065 | 0.6683957489878543\n",
      "> 6 | 0.36507055163383484 | 0.0801302045583725 | 0.8365068319838057 | 0.6895875506072875\n",
      "> 7 | 0.3625195622444153 | 0.07608632743358612 | 0.8378036437246964 | 0.6922760627530364\n",
      "> 8 | 0.36060088872909546 | 0.07395457476377487 | 0.839132085020243 | 0.691643471659919\n",
      "> 9 | 0.35912057757377625 | 0.07303346693515778 | 0.8397963056680162 | 0.6905048076923077\n",
      "> 10 | 0.3579375743865967 | 0.07287054508924484 | 0.8402391194331984 | 0.6883539979757085\n",
      "> 11 | 0.35695067048072815 | 0.07314793765544891 | 0.8405870445344129 | 0.6865827429149798\n",
      "> 12 | 0.35608744621276855 | 0.07365373522043228 | 0.8410298582995951 | 0.6862980769230769\n",
      "> 13 | 0.35530081391334534 | 0.0742550641298294 | 0.8418205971659919 | 0.6853808198380567\n",
      "> 14 | 0.3545592427253723 | 0.07487433403730392 | 0.8424848178137652 | 0.6851910425101214\n",
      "> 15 | 0.3538438677787781 | 0.07547272741794586 | 0.8427062246963563 | 0.6848747469635628\n",
      "> 16 | 0.35314494371414185 | 0.0760301873087883 | 0.8429908906882592 | 0.6842737854251012\n",
      "> 17 | 0.3524574637413025 | 0.07654207944869995 | 0.8433704453441295 | 0.6839891194331984\n",
      "> 18 | 0.35177847743034363 | 0.07700817286968231 | 0.8433704453441295 | 0.683830971659919\n",
      "> 19 | 0.35110771656036377 | 0.07743217051029205 | 0.8432439271255061 | 0.6837993421052632\n",
      "> 20 | 0.3504464626312256 | 0.07781719416379929 | 0.8435602226720648 | 0.6848431174089069\n",
      "> 21 | 0.3497953712940216 | 0.07816851139068604 | 0.8438448886639676 | 0.6841788967611336\n",
      "> 22 | 0.34915608167648315 | 0.07848961651325226 | 0.844224443319838 | 0.6844003036437247\n",
      "> 23 | 0.3485294580459595 | 0.07878337800502777 | 0.8445407388663968 | 0.6848747469635628\n",
      "> 24 | 0.3479164242744446 | 0.07905466109514236 | 0.8445091093117408 | 0.6850012651821862\n",
      "> 25 | 0.3473173975944519 | 0.07930389046669006 | 0.8446039979757085 | 0.6850012651821862\n",
      "> 26 | 0.34673285484313965 | 0.07953545451164246 | 0.844730516194332 | 0.6849696356275303\n",
      "> 27 | 0.346163272857666 | 0.07975003123283386 | 0.8450151821862348 | 0.6849380060728745\n",
      "> 28 | 0.34560921788215637 | 0.07995228469371796 | 0.8452365890688259 | 0.6845268218623481\n",
      "> 29 | 0.3450707793235779 | 0.08014097064733505 | 0.8455212550607287 | 0.6844635627530364\n",
      "> 30 | 0.3445475101470947 | 0.08031836152076721 | 0.8456161437246964 | 0.6840523785425101\n",
      "> 31 | 0.3440389633178711 | 0.08048544079065323 | 0.8456794028340081 | 0.6842737854251012\n",
      "> 32 | 0.34354519844055176 | 0.08064249157905579 | 0.8456477732793523 | 0.6841472672064778\n",
      "> 33 | 0.3430662155151367 | 0.08079403638839722 | 0.8459640688259109 | 0.6842105263157895\n",
      "> 34 | 0.342602401971817 | 0.08093977719545364 | 0.8460589574898786 | 0.6840207489878543\n",
      "> 35 | 0.34215277433395386 | 0.08107472956180573 | 0.8461538461538461 | 0.6836411943319838\n",
      "> 36 | 0.3417171239852905 | 0.08120487630367279 | 0.846185475708502 | 0.6838942307692307\n",
      "> 37 | 0.3412945866584778 | 0.08133406192064285 | 0.8461538461538461 | 0.6841788967611336\n",
      "> 38 | 0.3408859372138977 | 0.0814538449048996 | 0.8461538461538461 | 0.6839891194331984\n",
      "> 39 | 0.3404899835586548 | 0.08156874775886536 | 0.8462171052631579 | 0.683830971659919\n",
      "> 40 | 0.34010693430900574 | 0.08168154209852219 | 0.8464701417004049 | 0.6836411943319838\n",
      "> 41 | 0.33973583579063416 | 0.08178789913654327 | 0.8467548076923077 | 0.684305414979757\n",
      "> 42 | 0.33937662839889526 | 0.08189348876476288 | 0.846944585020243 | 0.6846533400809717\n",
      "> 43 | 0.33902931213378906 | 0.08199414610862732 | 0.8470394736842105 | 0.6846217105263158\n",
      "> 44 | 0.3386930227279663 | 0.0820903480052948 | 0.847165991902834 | 0.685064524291498\n",
      "> 45 | 0.338367760181427 | 0.08218161761760712 | 0.8474822874493927 | 0.6855073380566802\n",
      "> 46 | 0.3380526900291443 | 0.08227206766605377 | 0.8475139170040485 | 0.6855073380566802\n",
      "> 47 | 0.3377480208873749 | 0.08235945552587509 | 0.8475139170040485 | 0.6855705971659919\n",
      "> 48 | 0.337453156709671 | 0.08244574069976807 | 0.8475771761133604 | 0.6850328947368421\n",
      "> 49 | 0.3371673822402954 | 0.08252691477537155 | 0.8476720647773279 | 0.6854757085020243\n",
      "> 50 | 0.33689090609550476 | 0.0826031044125557 | 0.8478618421052632 | 0.685792004048583\n",
      "> 51 | 0.33662331104278564 | 0.08267949521541595 | 0.8479883603238867 | 0.6858868927125507\n",
      "> 52 | 0.33636438846588135 | 0.08275363594293594 | 0.8479567307692307 | 0.6861399291497976\n",
      "> 53 | 0.33611392974853516 | 0.08282508701086044 | 0.8480199898785425 | 0.6863613360323887\n",
      "> 54 | 0.3358715772628784 | 0.08289391547441483 | 0.8480516194331984 | 0.6861715587044535\n",
      "> 55 | 0.33563679456710815 | 0.08296068012714386 | 0.8481781376518218 | 0.6858868927125507\n",
      "> 56 | 0.3354091942310333 | 0.08302468061447144 | 0.848367914979757 | 0.6856022267206477\n",
      "> 57 | 0.33518922328948975 | 0.08308608829975128 | 0.8484628036437247 | 0.6849063765182186\n",
      "> 58 | 0.33497604727745056 | 0.08314672112464905 | 0.8484311740890689 | 0.6835463056680162\n",
      "> 59 | 0.33476924896240234 | 0.08320571482181549 | 0.8484311740890689 | 0.6836095647773279\n",
      "> 60 | 0.3345687985420227 | 0.0832630842924118 | 0.8483995445344129 | 0.6828504554655871\n",
      "> 61 | 0.3343747854232788 | 0.08331415057182312 | 0.8482730263157895 | 0.6830718623481782\n",
      "> 62 | 0.33418676257133484 | 0.08336207270622253 | 0.8482730263157895 | 0.6825341599190283\n",
      "> 63 | 0.33400458097457886 | 0.08341161161661148 | 0.8482413967611336 | 0.6820913461538461\n",
      "> 64 | 0.33382803201675415 | 0.083463154733181 | 0.848367914979757 | 0.6819648279352226\n",
      "> 65 | 0.33365684747695923 | 0.08350770175457001 | 0.8483995445344129 | 0.6818383097165992\n",
      "> 66 | 0.3334908187389374 | 0.0835513100028038 | 0.8483995445344129 | 0.6821862348178138\n",
      "> 67 | 0.33332958817481995 | 0.08359210938215256 | 0.8483362854251012 | 0.6821862348178138\n",
      "> 68 | 0.33317363262176514 | 0.08363525569438934 | 0.8484311740890689 | 0.6828504554655871\n",
      "> 69 | 0.33302223682403564 | 0.08367589116096497 | 0.8485260627530364 | 0.6827239372469636\n",
      "> 70 | 0.3328755795955658 | 0.08370933681726456 | 0.8485576923076923 | 0.6829453441295547\n",
      "> 71 | 0.3327333629131317 | 0.08374742418527603 | 0.84865258097166 | 0.6827871963562753\n",
      "> 72 | 0.3325953483581543 | 0.08378035575151443 | 0.8484628036437247 | 0.6823443825910931\n",
      "> 73 | 0.332461416721344 | 0.08381883800029755 | 0.8484628036437247 | 0.6821862348178138\n",
      "> 74 | 0.3323313295841217 | 0.08384749293327332 | 0.8485893218623481 | 0.681395495951417\n",
      "> 75 | 0.3322054445743561 | 0.08387518674135208 | 0.8486842105263158 | 0.680921052631579\n",
      "> 76 | 0.33208292722702026 | 0.08390665799379349 | 0.8487474696356275 | 0.6811108299595142\n",
      "> 77 | 0.33196401596069336 | 0.08393559604883194 | 0.8489056174089069 | 0.6806996457489879\n",
      "> 78 | 0.3318485915660858 | 0.08396123349666595 | 0.8489056174089069 | 0.6806047570850202\n",
      "> 79 | 0.33173662424087524 | 0.08398278057575226 | 0.8489372469635628 | 0.6807629048582996\n",
      "> 80 | 0.33162784576416016 | 0.08400853723287582 | 0.8489056174089069 | 0.6811740890688259\n",
      "> 81 | 0.33152201771736145 | 0.08402770012617111 | 0.8490005060728745 | 0.6812373481781376\n",
      "> 82 | 0.33141952753067017 | 0.08405695855617523 | 0.8489688765182186 | 0.6813006072874493\n",
      "> 83 | 0.33131980895996094 | 0.08407531678676605 | 0.8490005060728745 | 0.6812689777327935\n",
      "> 84 | 0.3312229514122009 | 0.08409234881401062 | 0.849127024291498 | 0.6814903846153846\n",
      "> 85 | 0.3311289846897125 | 0.08411096781492233 | 0.8490953947368421 | 0.6815220141700404\n",
      "> 86 | 0.33103805780410767 | 0.0841277688741684 | 0.8490637651821862 | 0.6815536437246964\n",
      "> 87 | 0.3309495449066162 | 0.08414208143949509 | 0.849127024291498 | 0.6823127530364372\n",
      "> 88 | 0.33086350560188293 | 0.08415944874286652 | 0.8490953947368421 | 0.6815852732793523\n",
      "> 89 | 0.33077943325042725 | 0.08417386561632156 | 0.8490953947368421 | 0.6807629048582996\n",
      "> 90 | 0.33069801330566406 | 0.08418877422809601 | 0.8491902834008097 | 0.6810159412955465\n",
      "> 91 | 0.3306185007095337 | 0.08419698476791382 | 0.8492851720647774 | 0.680414979757085\n",
      "> 92 | 0.3305414617061615 | 0.08420827984809875 | 0.8493168016194332 | 0.6806047570850202\n",
      "> 93 | 0.33046647906303406 | 0.08421523869037628 | 0.8494749493927125 | 0.6806363866396761\n",
      "> 94 | 0.33039379119873047 | 0.08423084020614624 | 0.8495065789473685 | 0.6805098684210527\n",
      "> 95 | 0.3303227424621582 | 0.08423303067684174 | 0.8495382085020243 | 0.6805731275303644\n",
      "> 96 | 0.3302538990974426 | 0.08424405008554459 | 0.8495382085020243 | 0.6801303137651822\n",
      "> 97 | 0.33018672466278076 | 0.08425040543079376 | 0.8496647267206477 | 0.6802884615384616\n",
      "> 98 | 0.3301217555999756 | 0.08425433188676834 | 0.8496330971659919 | 0.6800986842105263\n",
      "> 99 | 0.33005839586257935 | 0.08426070213317871 | 0.8496647267206477 | 0.6801303137651822\n",
      "> 100 | 0.3299964368343353 | 0.08426836878061295 | 0.849601467611336 | 0.6795609817813765\n",
      "> Evaluation\n",
      "> Class Acc = 0.8534508347511292\n",
      "> Adv Acc = 0.8534508347511292\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8105709105730057 | 0.9122360348701477 | 0.9027506113052368\n",
      "> Confusion Matrix \n",
      "TN: 9422.0 | FP: 722.0 \n",
      "FN: 1257.0 | TP: 2103.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3834.0 | FP: 91.0 \n",
      "FN: 228.0 | TP: 271.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5588.0 | FP: 631.0 \n",
      "FN: 1029.0 | TP: 1832.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.3367428183555603 | 0.11126124858856201 | 0.6903150303643725 | 0.33030743927125505\n",
      "> 2 | 0.27861741185188293 | 0.07053421437740326 | 0.8251201923076923 | 0.4690662955465587\n",
      "> 3 | 0.2592087388038635 | 0.056573789566755295 | 0.829832995951417 | 0.5740764170040485\n",
      "> 4 | 0.25111594796180725 | 0.05192999914288521 | 0.8333755060728745 | 0.6386955971659919\n",
      "> 5 | 0.24751406908035278 | 0.05034739896655083 | 0.8353997975708503 | 0.6768724696356275\n",
      "> 6 | 0.2461177408695221 | 0.04953955486416817 | 0.8371077935222672 | 0.6921811740890689\n",
      "> 7 | 0.2455883026123047 | 0.04944197088479996 | 0.8384678643724697 | 0.6953125\n",
      "> 8 | 0.24544289708137512 | 0.0496603399515152 | 0.8398595647773279 | 0.6951543522267206\n",
      "> 9 | 0.24546685814857483 | 0.05000206455588341 | 0.840808451417004 | 0.6947115384615384\n",
      "> 10 | 0.24555593729019165 | 0.050375230610370636 | 0.8412512651821862 | 0.6937942813765182\n",
      "> 11 | 0.24565738439559937 | 0.050736501812934875 | 0.8416308198380567 | 0.692117914979757\n",
      "> 12 | 0.24574333429336548 | 0.051065124571323395 | 0.8420103744939271 | 0.691169028340081\n",
      "> 13 | 0.24579980969429016 | 0.051351990550756454 | 0.8422634109311741 | 0.6898722165991903\n",
      "> 14 | 0.24581940472126007 | 0.05160144716501236 | 0.8427378542510121 | 0.6893661437246964\n",
      "> 15 | 0.24579937756061554 | 0.05181077867746353 | 0.8428011133603239 | 0.6890814777327935\n",
      "> 16 | 0.24573981761932373 | 0.051989007741212845 | 0.8431174089068826 | 0.688480516194332\n",
      "> 17 | 0.24564294517040253 | 0.052134715020656586 | 0.8435285931174089 | 0.6881958502024291\n",
      "> 18 | 0.2455119490623474 | 0.05225689709186554 | 0.844003036437247 | 0.6880060728744939\n",
      "> 19 | 0.24535039067268372 | 0.05235924944281578 | 0.8442560728744939 | 0.6884488866396761\n",
      "> 20 | 0.24516256153583527 | 0.05244167894124985 | 0.8446988866396761 | 0.6884172570850202\n",
      "> 21 | 0.2449527382850647 | 0.05250653997063637 | 0.8448886639676113 | 0.6883856275303644\n",
      "> 22 | 0.24472488462924957 | 0.05256087705492973 | 0.8453947368421053 | 0.6882591093117408\n",
      "> 23 | 0.24448230862617493 | 0.052604466676712036 | 0.8459956983805668 | 0.6881642206477733\n",
      "> 24 | 0.24422915279865265 | 0.05263926833868027 | 0.8464701417004049 | 0.6880060728744939\n",
      "> 25 | 0.24396680295467377 | 0.05266367271542549 | 0.8466282894736842 | 0.688227479757085\n",
      "> 26 | 0.24369864165782928 | 0.052685752511024475 | 0.8468813259109311 | 0.6884172570850202\n",
      "> 27 | 0.24342629313468933 | 0.05269937962293625 | 0.8468813259109311 | 0.687974443319838\n",
      "> 28 | 0.24315181374549866 | 0.05270909145474434 | 0.8469762145748988 | 0.6883539979757085\n",
      "> 29 | 0.2428761124610901 | 0.0527149997651577 | 0.8470394736842105 | 0.6883856275303644\n",
      "> 30 | 0.24260056018829346 | 0.052717290818691254 | 0.8469762145748988 | 0.6883539979757085\n",
      "> 31 | 0.24232622981071472 | 0.05271780490875244 | 0.8469129554655871 | 0.6887651821862348\n",
      "> 32 | 0.24205408990383148 | 0.05271574854850769 | 0.847165991902834 | 0.6881958502024291\n",
      "> 33 | 0.24178433418273926 | 0.05271390080451965 | 0.8471976214574899 | 0.6874367408906883\n",
      "> 34 | 0.24151822924613953 | 0.052707571536302567 | 0.8471976214574899 | 0.6876581477732794\n",
      "> 35 | 0.2412562519311905 | 0.05270214378833771 | 0.8471343623481782 | 0.6872153340080972\n",
      "> 36 | 0.24099865555763245 | 0.05269497260451317 | 0.8473557692307693 | 0.6870571862348178\n",
      "> 37 | 0.2407456934452057 | 0.05268685892224312 | 0.8477353238866396 | 0.6868674089068826\n",
      "> 38 | 0.24049758911132812 | 0.052677255123853683 | 0.8479567307692307 | 0.6866460020242915\n",
      "> 39 | 0.2402549535036087 | 0.05266857147216797 | 0.848146508097166 | 0.6862980769230769\n",
      "> 40 | 0.24001774191856384 | 0.05265912413597107 | 0.8482730263157895 | 0.6856654858299596\n",
      "> 41 | 0.2397863268852234 | 0.05264990031719208 | 0.8485893218623481 | 0.6857287449392713\n",
      "> 42 | 0.2395603358745575 | 0.052640076726675034 | 0.8486842105263158 | 0.6854124493927125\n",
      "> 43 | 0.23934021592140198 | 0.05263073742389679 | 0.8489688765182186 | 0.6856654858299596\n",
      "> 44 | 0.23912587761878967 | 0.05261988565325737 | 0.8490637651821862 | 0.6857603744939271\n",
      "> 45 | 0.23891735076904297 | 0.05261031538248062 | 0.8490321356275303 | 0.6852859311740891\n",
      "> 46 | 0.2387145459651947 | 0.052600108087062836 | 0.8491902834008097 | 0.6850012651821862\n",
      "> 47 | 0.2385176122188568 | 0.05258956551551819 | 0.8493484311740891 | 0.6842105263157895\n",
      "> 48 | 0.23832622170448303 | 0.05257948487997055 | 0.8495382085020243 | 0.6839574898785425\n",
      "> 49 | 0.2381405234336853 | 0.052569445222616196 | 0.8496963562753036 | 0.6834514170040485\n",
      "> 50 | 0.23796038329601288 | 0.052561163902282715 | 0.8499493927125507 | 0.6829137145748988\n",
      "> 51 | 0.2377854883670807 | 0.05255042761564255 | 0.8501391700404858 | 0.6834197874493927\n",
      "> 52 | 0.23761612176895142 | 0.05254114419221878 | 0.850328947368421 | 0.6824076417004049\n",
      "> 53 | 0.2374517023563385 | 0.05253123492002487 | 0.8503922064777328 | 0.6821862348178138\n",
      "> 54 | 0.23729242384433746 | 0.05252184346318245 | 0.850328947368421 | 0.6820280870445344\n",
      "> 55 | 0.23713792860507965 | 0.052513785660266876 | 0.850581983805668 | 0.681648532388664\n",
      "> 56 | 0.23698826134204865 | 0.0525035485625267 | 0.8504554655870445 | 0.6817434210526315\n",
      "> 57 | 0.23684339225292206 | 0.05249513313174248 | 0.8505187246963563 | 0.6821862348178138\n",
      "> 58 | 0.23670271039009094 | 0.052485186606645584 | 0.850581983805668 | 0.681648532388664\n",
      "> 59 | 0.236566424369812 | 0.05247664451599121 | 0.8507085020242915 | 0.6812689777327935\n",
      "> 60 | 0.2364344298839569 | 0.052467793226242065 | 0.8507717611336032 | 0.6813638663967612\n",
      "> 61 | 0.2363063395023346 | 0.05245833843946457 | 0.8509931680161943 | 0.6817117914979757\n",
      "> 62 | 0.23618227243423462 | 0.05245007947087288 | 0.8510564271255061 | 0.6810792004048583\n",
      "> 63 | 0.23606228828430176 | 0.052441004663705826 | 0.8511829453441295 | 0.6808894230769231\n",
      "> 64 | 0.23594558238983154 | 0.05243244394659996 | 0.8513727226720648 | 0.6812373481781376\n",
      "> 65 | 0.2358325868844986 | 0.05242903158068657 | 0.8512778340080972 | 0.6811740890688259\n",
      "> 66 | 0.23572313785552979 | 0.05241551250219345 | 0.8513410931174089 | 0.6806996457489879\n",
      "> 67 | 0.2356167733669281 | 0.05240699648857117 | 0.8514992408906883 | 0.6798772773279352\n",
      "> 68 | 0.2355135977268219 | 0.05239880084991455 | 0.8514992408906883 | 0.6799721659919028\n",
      "> 69 | 0.2354135662317276 | 0.0523906908929348 | 0.8515308704453441 | 0.6796558704453441\n",
      "> 70 | 0.23531630635261536 | 0.05238126963376999 | 0.8515308704453441 | 0.6798456477732794\n",
      "> 71 | 0.2352222204208374 | 0.05237305909395218 | 0.8515308704453441 | 0.6799089068825911\n",
      "> 72 | 0.23513081669807434 | 0.052365608513355255 | 0.8516890182186235 | 0.6795609817813765\n",
      "> 73 | 0.23504194617271423 | 0.05235712602734566 | 0.8516573886639676 | 0.6796242408906883\n",
      "> 74 | 0.23495586216449738 | 0.05235147103667259 | 0.8516890182186235 | 0.6798456477732794\n",
      "> 75 | 0.23487204313278198 | 0.05233979597687721 | 0.8516890182186235 | 0.6796558704453441\n",
      "> 76 | 0.23479077219963074 | 0.0523315966129303 | 0.8518471659919028 | 0.6800037955465587\n",
      "> 77 | 0.23471176624298096 | 0.0523279532790184 | 0.8519104251012146 | 0.6795926113360324\n",
      "> 78 | 0.2346349060535431 | 0.052317988127470016 | 0.8519104251012146 | 0.6791181680161943\n",
      "> 79 | 0.23456038534641266 | 0.05230727791786194 | 0.8519104251012146 | 0.6788335020242915\n",
      "> 80 | 0.23448792099952698 | 0.05229852721095085 | 0.8519104251012146 | 0.6791181680161943\n",
      "> 81 | 0.23441742360591888 | 0.05229567736387253 | 0.8518787955465587 | 0.678960020242915\n",
      "> 82 | 0.2343490868806839 | 0.05228300020098686 | 0.851815536437247 | 0.6793079453441295\n",
      "> 83 | 0.23428243398666382 | 0.05227390676736832 | 0.8519104251012146 | 0.6790549089068826\n",
      "> 84 | 0.23421767354011536 | 0.052265919744968414 | 0.8519420546558705 | 0.6782957995951417\n",
      "> 85 | 0.23415476083755493 | 0.05225786194205284 | 0.8518787955465587 | 0.6781692813765182\n",
      "> 86 | 0.23409341275691986 | 0.05224895104765892 | 0.852036943319838 | 0.6778529858299596\n",
      "> 87 | 0.23403394222259521 | 0.0522453635931015 | 0.8519736842105263 | 0.6785488360323887\n",
      "> 88 | 0.23397591710090637 | 0.05223682522773743 | 0.8520685728744939 | 0.6784223178137652\n",
      "> 89 | 0.23391951620578766 | 0.052224718034267426 | 0.8520685728744939 | 0.6778846153846154\n",
      "> 90 | 0.2338646650314331 | 0.0522163026034832 | 0.852036943319838 | 0.6777897267206477\n",
      "> 91 | 0.2338111400604248 | 0.05220859497785568 | 0.8519736842105263 | 0.6778846153846154\n",
      "> 92 | 0.23375914990901947 | 0.05220076069235802 | 0.8519420546558705 | 0.6778213562753036\n",
      "> 93 | 0.23370851576328278 | 0.052192412316799164 | 0.8518787955465587 | 0.6774418016194332\n",
      "> 94 | 0.2336587905883789 | 0.052186913788318634 | 0.8519420546558705 | 0.6771255060728745\n",
      "> 95 | 0.23361071944236755 | 0.052175749093294144 | 0.8518787955465587 | 0.6770622469635628\n",
      "> 96 | 0.23356382548809052 | 0.05216909199953079 | 0.8518787955465587 | 0.6768724696356275\n",
      "> 97 | 0.23351815342903137 | 0.052159857004880905 | 0.8519104251012146 | 0.6771255060728745\n",
      "> 98 | 0.23347389698028564 | 0.052151456475257874 | 0.8518471659919028 | 0.6768408400809717\n",
      "> 99 | 0.23343032598495483 | 0.0521463081240654 | 0.8519104251012146 | 0.6765878036437247\n",
      "> 100 | 0.23338797688484192 | 0.052135102450847626 | 0.8519736842105263 | 0.6765245445344129\n",
      "> Evaluation\n",
      "> Class Acc = 0.8498222827911377\n",
      "> Adv Acc = 0.8498222827911377\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8137916624546051 | 0.9002962186932564 | 0.8740590214729309\n",
      "> Confusion Matrix \n",
      "TN: 9411.0 | FP: 699.0 \n",
      "FN: 1329.0 | TP: 2065.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3758.0 | FP: 91.0 \n",
      "FN: 249.0 | TP: 250.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5653.0 | FP: 608.0 \n",
      "FN: 1080.0 | TP: 1815.0\n",
      "> Epoch | Class Loss | Adv Loss | Class Acc | Adv Acc\n",
      "> 1 | 0.40620964765548706 | 0.17353758215904236 | 0.686266447368421 | 0.32869433198380565\n",
      "> 2 | 0.3536408245563507 | 0.10572684556245804 | 0.8248671558704453 | 0.46602985829959515\n",
      "> 3 | 0.33525335788726807 | 0.07629603147506714 | 0.830560475708502 | 0.5723051619433198\n",
      "> 4 | 0.3263337016105652 | 0.06190123409032822 | 0.8331540991902834 | 0.6287322874493927\n",
      "> 5 | 0.32158076763153076 | 0.05371370539069176 | 0.8366966093117408 | 0.66896508097166\n",
      "> 6 | 0.31898921728134155 | 0.048143431544303894 | 0.8378669028340081 | 0.6840523785425101\n",
      "> 7 | 0.317518949508667 | 0.044813353568315506 | 0.8396381578947368 | 0.6855073380566802\n",
      "> 8 | 0.3167341351509094 | 0.04297362267971039 | 0.8408717105263158 | 0.6858552631578947\n",
      "> 9 | 0.3163618743419647 | 0.042105257511138916 | 0.842516447368421 | 0.6853491902834008\n",
      "> 10 | 0.31622207164764404 | 0.04184410348534584 | 0.8428960020242915 | 0.6844635627530364\n",
      "> 11 | 0.31619930267333984 | 0.04193303734064102 | 0.8436867408906883 | 0.6841472672064778\n",
      "> 12 | 0.3162241280078888 | 0.042198702692985535 | 0.8442560728744939 | 0.682882085020243\n",
      "> 13 | 0.3162563741207123 | 0.04253218322992325 | 0.8441611842105263 | 0.6824076417004049\n",
      "> 14 | 0.316275417804718 | 0.04287920147180557 | 0.8448254048582996 | 0.6817434210526315\n",
      "> 15 | 0.316271036863327 | 0.04320430010557175 | 0.8456161437246964 | 0.6814271255060729\n",
      "> 16 | 0.316241055727005 | 0.04350990802049637 | 0.8462171052631579 | 0.6812057186234818\n",
      "> 17 | 0.3161866068840027 | 0.04378269612789154 | 0.8465966599190283 | 0.6809526821862348\n",
      "> 18 | 0.31611064076423645 | 0.04402725026011467 | 0.8471343623481782 | 0.6805731275303644\n",
      "> 19 | 0.3160173296928406 | 0.04425244778394699 | 0.8476088056680162 | 0.6805414979757085\n",
      "> 20 | 0.31591105461120605 | 0.04445122182369232 | 0.8477036943319838 | 0.680161943319838\n",
      "> 21 | 0.31579530239105225 | 0.04464051127433777 | 0.8482097672064778 | 0.6806363866396761\n",
      "> 22 | 0.31567347049713135 | 0.044812049716711044 | 0.8485576923076923 | 0.6801303137651822\n",
      "> 23 | 0.3155478239059448 | 0.04497168958187103 | 0.8489056174089069 | 0.6799721659919028\n",
      "> 24 | 0.31541964411735535 | 0.04511754959821701 | 0.8491586538461539 | 0.6800986842105263\n",
      "> 25 | 0.3152901530265808 | 0.04526441544294357 | 0.8492535425101214 | 0.679434463562753\n",
      "> 26 | 0.315159410238266 | 0.045394204556941986 | 0.8496330971659919 | 0.6793395748987854\n",
      "> 27 | 0.31502851843833923 | 0.04552430659532547 | 0.849601467611336 | 0.6791497975708503\n",
      "> 28 | 0.31489723920822144 | 0.045652009546756744 | 0.8497279858299596 | 0.6785488360323887\n",
      "> 29 | 0.3147664964199066 | 0.04577251151204109 | 0.8497596153846154 | 0.6789916497975709\n",
      "> 30 | 0.3146366477012634 | 0.0458889901638031 | 0.8500442813765182 | 0.6791814271255061\n",
      "> 31 | 0.31450825929641724 | 0.046002596616744995 | 0.8504554655870445 | 0.679940536437247\n",
      "> 32 | 0.314381867647171 | 0.04611032456159592 | 0.8502973178137652 | 0.6797823886639676\n",
      "> 33 | 0.31425783038139343 | 0.04621967673301697 | 0.8504870951417004 | 0.6797191295546559\n",
      "> 34 | 0.3141363561153412 | 0.04632776975631714 | 0.8506136133603239 | 0.6794660931174089\n",
      "> 35 | 0.3140178918838501 | 0.046429045498371124 | 0.8506768724696356 | 0.6799721659919028\n",
      "> 36 | 0.3139028251171112 | 0.04653194546699524 | 0.8507401315789473 | 0.6800037955465587\n",
      "> 37 | 0.3137914538383484 | 0.04663722589612007 | 0.8509931680161943 | 0.6807312753036437\n",
      "> 38 | 0.3136836290359497 | 0.04673685133457184 | 0.8512462044534413 | 0.6808577935222672\n",
      "> 39 | 0.3135799765586853 | 0.046835724264383316 | 0.8513410931174089 | 0.6813006072874493\n",
      "> 40 | 0.3134806752204895 | 0.046932607889175415 | 0.8514043522267206 | 0.6816801619433198\n",
      "> 41 | 0.3133850693702698 | 0.047027818858623505 | 0.8514992408906883 | 0.6819648279352226\n",
      "> 42 | 0.3132938742637634 | 0.047123827040195465 | 0.8514359817813765 | 0.6820913461538461\n",
      "> 43 | 0.3132069408893585 | 0.047217391431331635 | 0.8515941295546559 | 0.6825025303643725\n",
      "> 44 | 0.313123881816864 | 0.047309525310993195 | 0.8516890182186235 | 0.6827555668016194\n",
      "> 45 | 0.3130453824996948 | 0.04740067198872566 | 0.8515941295546559 | 0.6830086032388664\n",
      "> 46 | 0.3129710555076599 | 0.047490835189819336 | 0.8520053137651822 | 0.682882085020243\n",
      "> 47 | 0.3129008412361145 | 0.047580063343048096 | 0.8519736842105263 | 0.6835463056680162\n",
      "> 48 | 0.3128345310688019 | 0.047667477279901505 | 0.8520053137651822 | 0.684084008097166\n",
      "> 49 | 0.31277239322662354 | 0.04775610566139221 | 0.8520685728744939 | 0.6843370445344129\n",
      "> 50 | 0.31271377205848694 | 0.04784064739942551 | 0.8521002024291497 | 0.6844319331983806\n",
      "> 51 | 0.31265926361083984 | 0.04792548716068268 | 0.852289979757085 | 0.6838942307692307\n",
      "> 52 | 0.31260836124420166 | 0.04800690710544586 | 0.8523216093117408 | 0.683356528340081\n",
      "> 53 | 0.3125605881214142 | 0.0480903796851635 | 0.8523848684210527 | 0.6829769736842105\n",
      "> 54 | 0.3125167489051819 | 0.04817166179418564 | 0.8524164979757085 | 0.682629048582996\n",
      "> 55 | 0.31247586011886597 | 0.04824930429458618 | 0.8524797570850202 | 0.6825341599190283\n",
      "> 56 | 0.31243836879730225 | 0.04833178594708443 | 0.8527011639676113 | 0.6827871963562753\n",
      "> 57 | 0.31240391731262207 | 0.04840592294931412 | 0.8528909412955465 | 0.6819015688259109\n",
      "> 58 | 0.31237274408340454 | 0.048485711216926575 | 0.8530490890688259 | 0.6820597165991903\n",
      "> 59 | 0.3123442530632019 | 0.04856199771165848 | 0.8530490890688259 | 0.6814903846153846\n",
      "> 60 | 0.3123184144496918 | 0.048638321459293365 | 0.8531123481781376 | 0.6814903846153846\n",
      "> 61 | 0.31229519844055176 | 0.04871094226837158 | 0.8530807186234818 | 0.6820280870445344\n",
      "> 62 | 0.312274694442749 | 0.048785679042339325 | 0.8531756072874493 | 0.6820280870445344\n",
      "> 63 | 0.31225648522377014 | 0.04885243624448776 | 0.8530490890688259 | 0.6822494939271255\n",
      "> 64 | 0.3122406303882599 | 0.048923835158348083 | 0.8532072368421053 | 0.6817434210526315\n",
      "> 65 | 0.3122269809246063 | 0.04899652302265167 | 0.8533337550607287 | 0.6806996457489879\n",
      "> 66 | 0.31221532821655273 | 0.049065157771110535 | 0.8533970141700404 | 0.6808894230769231\n",
      "> 67 | 0.3122057616710663 | 0.049132850021123886 | 0.8533337550607287 | 0.6811740890688259\n",
      "> 68 | 0.3121977150440216 | 0.04919552057981491 | 0.8533021255060729 | 0.6809526821862348\n",
      "> 69 | 0.31219178438186646 | 0.04926144331693649 | 0.8531123481781376 | 0.6813638663967612\n",
      "> 70 | 0.3121873736381531 | 0.04932644963264465 | 0.8531756072874493 | 0.6810792004048583\n",
      "> 71 | 0.3121846318244934 | 0.04939202591776848 | 0.8533970141700404 | 0.680921052631579\n",
      "> 72 | 0.31218335032463074 | 0.049451638013124466 | 0.853523532388664 | 0.6807945344129555\n",
      "> 73 | 0.3121833801269531 | 0.04951418936252594 | 0.8534286437246964 | 0.680414979757085\n",
      "> 74 | 0.3121846616268158 | 0.049577850848436356 | 0.8535551619433198 | 0.6798140182186235\n",
      "> 75 | 0.3121870756149292 | 0.049632728099823 | 0.8535867914979757 | 0.6794977226720648\n",
      "> 76 | 0.31219080090522766 | 0.04969128966331482 | 0.8536500506072875 | 0.6800354251012146\n",
      "> 77 | 0.3121953010559082 | 0.04975166171789169 | 0.8536500506072875 | 0.6794028340080972\n",
      "> 78 | 0.31220078468322754 | 0.04980773851275444 | 0.8536184210526315 | 0.6792446862348178\n",
      "> 79 | 0.3122071623802185 | 0.04986109584569931 | 0.8536816801619433 | 0.6789283906882592\n",
      "> 80 | 0.31221461296081543 | 0.04991738498210907 | 0.8536500506072875 | 0.6791497975708503\n",
      "> 81 | 0.31222325563430786 | 0.04997061938047409 | 0.8538081983805668 | 0.6796242408906883\n",
      "> 82 | 0.31223222613334656 | 0.05002385750412941 | 0.8539663461538461 | 0.6796242408906883\n",
      "> 83 | 0.31224173307418823 | 0.050080686807632446 | 0.8539663461538461 | 0.6797191295546559\n",
      "> 84 | 0.312252014875412 | 0.05012842267751694 | 0.8540296052631579 | 0.6794028340080972\n",
      "> 85 | 0.3122628331184387 | 0.050178565084934235 | 0.8540612348178138 | 0.678960020242915\n",
      "> 86 | 0.3122742772102356 | 0.05022796615958214 | 0.8539663461538461 | 0.6786753542510121\n",
      "> 87 | 0.3122860789299011 | 0.050276681780815125 | 0.8540296052631579 | 0.6789283906882592\n",
      "> 88 | 0.3122985363006592 | 0.05032762512564659 | 0.8540612348178138 | 0.6784855769230769\n",
      "> 89 | 0.31231123208999634 | 0.05037114396691322 | 0.8541244939271255 | 0.6774101720647774\n",
      "> 90 | 0.31232428550720215 | 0.050416458398103714 | 0.854251012145749 | 0.6773469129554656\n",
      "> 91 | 0.3123379349708557 | 0.050465237349271774 | 0.8542826417004049 | 0.6771571356275303\n",
      "> 92 | 0.3123520016670227 | 0.050508107990026474 | 0.854251012145749 | 0.6764612854251012\n",
      "> 93 | 0.31236642599105835 | 0.050553638488054276 | 0.854251012145749 | 0.6768408400809717\n",
      "> 94 | 0.3123807907104492 | 0.05060124024748802 | 0.8542826417004049 | 0.6766826923076923\n",
      "> 95 | 0.31239521503448486 | 0.05064019188284874 | 0.8543775303643725 | 0.6758603238866396\n",
      "> 96 | 0.31241005659103394 | 0.05068165808916092 | 0.85447241902834 | 0.6757338056680162\n",
      "> 97 | 0.312424898147583 | 0.05072686821222305 | 0.854504048582996 | 0.6745951417004049\n",
      "> 98 | 0.31244003772735596 | 0.05076616257429123 | 0.854504048582996 | 0.674563512145749\n",
      "> 99 | 0.31245505809783936 | 0.05080724507570267 | 0.854504048582996 | 0.6743421052631579\n",
      "> 100 | 0.3124704957008362 | 0.05084717273712158 | 0.854504048582996 | 0.6743421052631579\n",
      "> Evaluation\n",
      "> Class Acc = 0.8475266695022583\n",
      "> Adv Acc = 0.8475266695022583\n",
      "> DP | DEqOdds | DEqOpp\n",
      "> 0.8013309240341187 | 0.8941805809736252 | 0.8702843487262726\n",
      "> Confusion Matrix \n",
      "TN: 9337.0 | FP: 755.0 \n",
      "FN: 1304.0 | TP: 2108.0\n",
      "> Confusion Matrix for A = 0 \n",
      "TN: 3775.0 | FP: 94.0 \n",
      "FN: 236.0 | TP: 242.0\n",
      "> Confusion Matrix for A = 1 \n",
      "TN: 5562.0 | FP: 661.0 \n",
      "FN: 1068.0 | TP: 1866.0\n"
     ]
    }
   ],
   "source": [
    "fairdef = 'EqOpp'\n",
    "\n",
    "for cv_seed in cv_seeds:\n",
    "    x_train, x_test, y_train, y_test, a_train, a_test = train_test_split(\n",
    "        x, y, a, test_size=0.3, random_state=cv_seed)\n",
    "\n",
    "    train_data = Dataset.from_tensor_slices((x_train, y_train, a_train))\n",
    "    train_data = train_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    test_data = Dataset.from_tensor_slices((x_test, y_test, a_test))\n",
    "    test_data = test_data.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "    # train below\n",
    "\n",
    "    opt = Adam(learning_rate=lr)\n",
    "\n",
    "    model = FairLogisticRegression(xdim, ydim, adim, batch_size, fairdef)\n",
    "    zhang_train(model, raw_data, train_data, epochs, opt)\n",
    "\n",
    "    Y, A, Y_hat, A_hat = fair_evaluation(model, test_data)\n",
    "    clas_acc, dp, deqodds, deqopp, confusion_matrix, metrics_a0, metrics_a1 = compute_metrics(Y, A, Y_hat, A_hat, adim)\n",
    "\n",
    "    fair_metrics = (dp, deqodds, deqopp)\n",
    "    tradeoff = []\n",
    "    for fair_metric in fair_metrics:\n",
    "        tradeoff.append(compute_tradeoff(clas_acc, fair_metric))\n",
    "\n",
    "    result = ['Zhang4EqOpp', cv_seed, clas_acc, dp, deqodds, deqopp, tradeoff[0], tradeoff[1], tradeoff[2]] + metrics_a0 + metrics_a1\n",
    "\n",
    "    results.append(result)\n",
    "\n",
    "    del(opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving into DF then CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>cv_seed</th>\n",
       "      <th>clas_acc</th>\n",
       "      <th>dp</th>\n",
       "      <th>deqodds</th>\n",
       "      <th>deqopp</th>\n",
       "      <th>trade_dp</th>\n",
       "      <th>trade_deqodds</th>\n",
       "      <th>trade_deqopp</th>\n",
       "      <th>TN_a0</th>\n",
       "      <th>FP_a0</th>\n",
       "      <th>FN_a0</th>\n",
       "      <th>TP_a0</th>\n",
       "      <th>TN_a1</th>\n",
       "      <th>FP_a1</th>\n",
       "      <th>FN_a1</th>\n",
       "      <th>TP_a1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>13</td>\n",
       "      <td>0.849378</td>\n",
       "      <td>0.811971</td>\n",
       "      <td>0.898506</td>\n",
       "      <td>0.878278</td>\n",
       "      <td>0.830253</td>\n",
       "      <td>0.873251</td>\n",
       "      <td>0.863586</td>\n",
       "      <td>3786.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>252.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>5643.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>1053.0</td>\n",
       "      <td>1782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>29</td>\n",
       "      <td>0.850267</td>\n",
       "      <td>0.804985</td>\n",
       "      <td>0.894028</td>\n",
       "      <td>0.873792</td>\n",
       "      <td>0.827006</td>\n",
       "      <td>0.871598</td>\n",
       "      <td>0.861869</td>\n",
       "      <td>3796.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>5607.0</td>\n",
       "      <td>671.0</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>1819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>42</td>\n",
       "      <td>0.855450</td>\n",
       "      <td>0.810959</td>\n",
       "      <td>0.911109</td>\n",
       "      <td>0.898743</td>\n",
       "      <td>0.832611</td>\n",
       "      <td>0.882403</td>\n",
       "      <td>0.876562</td>\n",
       "      <td>3841.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>5610.0</td>\n",
       "      <td>609.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>55</td>\n",
       "      <td>0.850637</td>\n",
       "      <td>0.813102</td>\n",
       "      <td>0.899535</td>\n",
       "      <td>0.872677</td>\n",
       "      <td>0.831446</td>\n",
       "      <td>0.874403</td>\n",
       "      <td>0.861516</td>\n",
       "      <td>3761.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5657.0</td>\n",
       "      <td>604.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>1819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zhang4DP</td>\n",
       "      <td>73</td>\n",
       "      <td>0.847675</td>\n",
       "      <td>0.799658</td>\n",
       "      <td>0.893716</td>\n",
       "      <td>0.871354</td>\n",
       "      <td>0.822967</td>\n",
       "      <td>0.870087</td>\n",
       "      <td>0.859351</td>\n",
       "      <td>3779.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>5556.0</td>\n",
       "      <td>667.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>1869.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>13</td>\n",
       "      <td>0.849970</td>\n",
       "      <td>0.811158</td>\n",
       "      <td>0.897152</td>\n",
       "      <td>0.875968</td>\n",
       "      <td>0.830111</td>\n",
       "      <td>0.872924</td>\n",
       "      <td>0.862774</td>\n",
       "      <td>3790.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>5647.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>1783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>29</td>\n",
       "      <td>0.849896</td>\n",
       "      <td>0.803761</td>\n",
       "      <td>0.892257</td>\n",
       "      <td>0.871464</td>\n",
       "      <td>0.826185</td>\n",
       "      <td>0.870562</td>\n",
       "      <td>0.860545</td>\n",
       "      <td>3797.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>5601.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>1820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>42</td>\n",
       "      <td>0.855302</td>\n",
       "      <td>0.810078</td>\n",
       "      <td>0.911152</td>\n",
       "      <td>0.900048</td>\n",
       "      <td>0.832076</td>\n",
       "      <td>0.882344</td>\n",
       "      <td>0.877105</td>\n",
       "      <td>3842.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>5604.0</td>\n",
       "      <td>615.0</td>\n",
       "      <td>1027.0</td>\n",
       "      <td>1834.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>55</td>\n",
       "      <td>0.850785</td>\n",
       "      <td>0.813079</td>\n",
       "      <td>0.897851</td>\n",
       "      <td>0.868669</td>\n",
       "      <td>0.831505</td>\n",
       "      <td>0.873684</td>\n",
       "      <td>0.859634</td>\n",
       "      <td>3761.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>5661.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>1076.0</td>\n",
       "      <td>1819.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zhang4EqOdds</td>\n",
       "      <td>73</td>\n",
       "      <td>0.847379</td>\n",
       "      <td>0.799198</td>\n",
       "      <td>0.891714</td>\n",
       "      <td>0.867511</td>\n",
       "      <td>0.822583</td>\n",
       "      <td>0.868981</td>\n",
       "      <td>0.857326</td>\n",
       "      <td>3779.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5555.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>1066.0</td>\n",
       "      <td>1868.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>13</td>\n",
       "      <td>0.849230</td>\n",
       "      <td>0.813222</td>\n",
       "      <td>0.901973</td>\n",
       "      <td>0.884854</td>\n",
       "      <td>0.830836</td>\n",
       "      <td>0.874807</td>\n",
       "      <td>0.866676</td>\n",
       "      <td>3784.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>262.0</td>\n",
       "      <td>5642.0</td>\n",
       "      <td>647.0</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>1780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>29</td>\n",
       "      <td>0.850118</td>\n",
       "      <td>0.804546</td>\n",
       "      <td>0.891702</td>\n",
       "      <td>0.868784</td>\n",
       "      <td>0.826705</td>\n",
       "      <td>0.870414</td>\n",
       "      <td>0.859350</td>\n",
       "      <td>3794.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>5606.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1822.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>42</td>\n",
       "      <td>0.853451</td>\n",
       "      <td>0.810571</td>\n",
       "      <td>0.912236</td>\n",
       "      <td>0.902751</td>\n",
       "      <td>0.831458</td>\n",
       "      <td>0.881865</td>\n",
       "      <td>0.877409</td>\n",
       "      <td>3834.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>271.0</td>\n",
       "      <td>5588.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>1832.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>55</td>\n",
       "      <td>0.849822</td>\n",
       "      <td>0.813792</td>\n",
       "      <td>0.900296</td>\n",
       "      <td>0.874059</td>\n",
       "      <td>0.831417</td>\n",
       "      <td>0.874331</td>\n",
       "      <td>0.861770</td>\n",
       "      <td>3758.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>5653.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1815.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zhang4EqOpp</td>\n",
       "      <td>73</td>\n",
       "      <td>0.847527</td>\n",
       "      <td>0.801331</td>\n",
       "      <td>0.894181</td>\n",
       "      <td>0.870284</td>\n",
       "      <td>0.823782</td>\n",
       "      <td>0.870229</td>\n",
       "      <td>0.858755</td>\n",
       "      <td>3775.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>5562.0</td>\n",
       "      <td>661.0</td>\n",
       "      <td>1068.0</td>\n",
       "      <td>1866.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model_name  cv_seed  clas_acc        dp   deqodds    deqopp  trade_dp  \\\n",
       "0       Zhang4DP       13  0.849378  0.811971  0.898506  0.878278  0.830253   \n",
       "1       Zhang4DP       29  0.850267  0.804985  0.894028  0.873792  0.827006   \n",
       "2       Zhang4DP       42  0.855450  0.810959  0.911109  0.898743  0.832611   \n",
       "3       Zhang4DP       55  0.850637  0.813102  0.899535  0.872677  0.831446   \n",
       "4       Zhang4DP       73  0.847675  0.799658  0.893716  0.871354  0.822967   \n",
       "5   Zhang4EqOdds       13  0.849970  0.811158  0.897152  0.875968  0.830111   \n",
       "6   Zhang4EqOdds       29  0.849896  0.803761  0.892257  0.871464  0.826185   \n",
       "7   Zhang4EqOdds       42  0.855302  0.810078  0.911152  0.900048  0.832076   \n",
       "8   Zhang4EqOdds       55  0.850785  0.813079  0.897851  0.868669  0.831505   \n",
       "9   Zhang4EqOdds       73  0.847379  0.799198  0.891714  0.867511  0.822583   \n",
       "10   Zhang4EqOpp       13  0.849230  0.813222  0.901973  0.884854  0.830836   \n",
       "11   Zhang4EqOpp       29  0.850118  0.804546  0.891702  0.868784  0.826705   \n",
       "12   Zhang4EqOpp       42  0.853451  0.810571  0.912236  0.902751  0.831458   \n",
       "13   Zhang4EqOpp       55  0.849822  0.813792  0.900296  0.874059  0.831417   \n",
       "14   Zhang4EqOpp       73  0.847527  0.801331  0.894181  0.870284  0.823782   \n",
       "\n",
       "    trade_deqodds  trade_deqopp   TN_a0  FP_a0  FN_a0  TP_a0   TN_a1  FP_a1  \\\n",
       "0        0.873251      0.863586  3786.0   83.0  252.0  259.0  5643.0  646.0   \n",
       "1        0.871598      0.861869  3796.0   82.0  246.0  260.0  5607.0  671.0   \n",
       "2        0.882403      0.876562  3841.0   84.0  230.0  269.0  5610.0  609.0   \n",
       "3        0.874403      0.861516  3761.0   88.0  249.0  250.0  5657.0  604.0   \n",
       "4        0.870087      0.859351  3779.0   90.0  235.0  243.0  5556.0  667.0   \n",
       "5        0.872924      0.862774  3790.0   79.0  253.0  258.0  5647.0  642.0   \n",
       "6        0.870562      0.860545  3797.0   81.0  247.0  259.0  5601.0  677.0   \n",
       "7        0.882344      0.877105  3842.0   83.0  229.0  270.0  5604.0  615.0   \n",
       "8        0.873684      0.859634  3761.0   88.0  251.0  248.0  5661.0  600.0   \n",
       "9        0.868981      0.857326  3779.0   90.0  237.0  241.0  5555.0  668.0   \n",
       "10       0.874807      0.866676  3784.0   85.0  249.0  262.0  5642.0  647.0   \n",
       "11       0.870414      0.859350  3794.0   84.0  248.0  258.0  5606.0  672.0   \n",
       "12       0.881865      0.877409  3834.0   91.0  228.0  271.0  5588.0  631.0   \n",
       "13       0.874331      0.861770  3758.0   91.0  249.0  250.0  5653.0  608.0   \n",
       "14       0.870229      0.858755  3775.0   94.0  236.0  242.0  5562.0  661.0   \n",
       "\n",
       "     FN_a1   TP_a1  \n",
       "0   1053.0  1782.0  \n",
       "1   1023.0  1819.0  \n",
       "2   1029.0  1832.0  \n",
       "3   1076.0  1819.0  \n",
       "4   1065.0  1869.0  \n",
       "5   1052.0  1783.0  \n",
       "6   1022.0  1820.0  \n",
       "7   1027.0  1834.0  \n",
       "8   1076.0  1819.0  \n",
       "9   1066.0  1868.0  \n",
       "10  1055.0  1780.0  \n",
       "11  1020.0  1822.0  \n",
       "12  1029.0  1832.0  \n",
       "13  1080.0  1815.0  \n",
       "14  1068.0  1866.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = pd.DataFrame(results, columns=header)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(f'{data_name}-result/zhang-{epochs}.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "41359ec383f887151a607ad1e28cb7dbc05f61385692c63e2bb2f343bf03f280"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('falsb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
